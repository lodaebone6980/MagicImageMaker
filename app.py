import streamlit as st
import requests
import json
import time
import os
import re
import shutil
import zipfile
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from PIL import Image
from google import genai
from google.genai import types

# [NEW] ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from pydub import AudioSegment
from pydub.silence import detect_silence

# [NEW] ë™ì˜ìƒ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° íš¨ê³¼ ì¶”ê°€
try:
    # VideoFileClip, concatenate_videoclips ì¶”ê°€ (ì˜ìƒ ë³‘í•©ìš©)
    from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, VideoFileClip, concatenate_videoclips
    import numpy as np 
except ImportError:
    st.error("âš ï¸ 'moviepy' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì— 'pip install moviepy numpy'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì´ë¯¸ì§€ ìƒì„±ê¸°", layout="wide", page_icon="ğŸ¨")

# íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
BASE_PATH = "./web_result_files"
IMAGE_OUTPUT_DIR = os.path.join(BASE_PATH, "output_images")
AUDIO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_audio")
VIDEO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_video") 

# í…ìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •
GEMINI_TEXT_MODEL_NAME = "gemini-2.5-pro" 

# [ê¸°ë³¸ê°’] ë¬¸ì„œì— ëª…ì‹œëœ ì •í™•í•œ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ
DEFAULT_SUPERTONE_URL = "https://supertoneapi.com"
DEFAULT_VOICE_ID = "ff700760946618e1dcf7bd" 

# ==========================================
# [í•¨ìˆ˜] 0. TTSìš© í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì/ê¸°í˜¸ -> í•œê¸€)
# ==========================================
def num_to_kor(num_str):
    """ìˆ«ì ë¬¸ìì—´ì„ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 1,500 -> ì²œì˜¤ë°±)"""
    try:
        num_str = num_str.replace(',', '')
        if not num_str.isdigit(): return num_str
        
        num = int(num_str)
        if num == 0: return "ì˜"
        
        units = ['', 'ì‹­', 'ë°±', 'ì²œ']
        big_units = ['', 'ë§Œ', 'ì–µ', 'ì¡°', 'ê²½']
        num_chars = ['', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
        
        result = []
        big_idx = 0
        
        while num > 0:
            small_part = num % 10000
            if small_part > 0:
                small_res = []
                small_idx = 0
                while small_part > 0:
                    digit = small_part % 10
                    if digit > 0:
                        unit = units[small_idx]
                        char = num_chars[digit]
                        if digit == 1 and small_idx > 0:
                            char = ""
                        small_res.append(char + unit)
                    small_part //= 10
                    small_idx += 1
                result.append("".join(reversed(small_res)) + big_units[big_idx])
            num //= 10000
            big_idx += 1
            
        return "".join(reversed(result))
    except:
        return num_str

def normalize_text_for_tts(text):
    """TTS ë°œìŒì„ ìœ„í•´ íŠ¹ìˆ˜ë¬¸ìì™€ ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜"""
    text = text.replace("%", " í¼ì„¼íŠ¸")
    
    def replace_decimal(match):
        return f"{match.group(1)} ì  {match.group(2)}"
    text = re.sub(r'(\d+)\.(\d+)', replace_decimal, text)

    def replace_number(match):
        return num_to_kor(match.group())
    
    text = re.sub(r'\d+(?:,\d+)*', replace_number, text)
    
    return text

# ==========================================
# [í•¨ìˆ˜] 1. ëŒ€ë³¸ êµ¬ì¡°í™” ë¡œì§
# ==========================================
def generate_structure(client, full_script):
    """Geminië¥¼ ì´ìš©í•´ ëŒ€ë³¸ êµ¬ì¡°í™”"""
    prompt = f"""
    [Role]
    You are a professional YouTube Content Editor and Scriptwriter.

    [Task]
    Analyze the provided transcript (script).
    Restructure the content into a highly detailed, list-style format suitable for a blog post or a new video plan.
      
    [Output Format]
    1. **Video Theme/Title**: (Extract or suggest a catchy title based on the whole script)
    2. **Intro**: (Hook and background, no music) Approve specific channel names, The intro hooks the overall topic (ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ ê°™ì€ ì¸ì‚¬ ê¸ˆì§€)
    3. **Chapter 1** to **Chapter 8**: (Divide the main content into logical sections. Use detailed bullet points for each chapter.)
    4. **Epilogue**: (Conclusion and Subscribe Like Comments that make you anticipate the next specific content)

    [Constraint]
    - Analyze the entire context deeply.
    - Write the output in **Korean**.
    - Make the content rich and detailed.
    - If the original script has a channel name, remove it.

    [Transcript]
    {full_script}
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 2. ì„¹ì…˜ë³„ ëŒ€ë³¸ ìƒì„± (ìˆ˜ì • ë²„ì „)
# ==========================================
def generate_section(client, section_title, full_structure, duration_type="fixed", custom_instruction=""):
    # 1. ë¶„ëŸ‰ì— ë”°ë¥¸ ê¸€ììˆ˜ ë° ì§€ì¹¨ ì„¤ì •
    if duration_type == "2min":
        target_chars = "ì•½ 1,000ì (ê³µë°± í¬í•¨)"
        detail_level = "í•µì‹¬ ë‚´ìš© ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ë˜, ë„ˆë¬´ ì§§ì§€ ì•Šê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "3min":
        target_chars = "ì•½ 1,500ì (ê³µë°± í¬í•¨)"
        detail_level = "ì¶©ë¶„í•œ ì˜ˆì‹œì™€ ì„¤ëª…ì„ ê³ë“¤ì—¬ ìƒì„¸í•˜ê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "4min":
        target_chars = "ì•½ 2,000ì ì´ìƒ (ê³µë°± í¬í•¨)"
        detail_level = "í˜„ë¯¸ê²½ìœ¼ë¡œ ë“¤ì—¬ë‹¤ë³´ë“¯ ì•„ì£¼ ê¹Šì´ ìˆê³  ë””í…Œì¼í•˜ê²Œ ë¬˜ì‚¬í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
    else: # Intro / Epilogue (Fixed)
        target_chars = "ì•½ 400ë‹¨ì–´ (ì•½ 1,400ì)"
        detail_level = "ì‹œì²­ìë¥¼ ì‚¬ë¡œì¡ëŠ” ê°•ë ¥í•œ í›„í‚¹ê³¼ ì—¬ìš´ì„ ì£¼ëŠ” ë§ˆë¬´ë¦¬ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì•ˆë…• ì¸ì‚¬ëŠ” í•˜ì§€ ì•ŠëŠ”ë‹¤"

    user_guide_prompt = ""
    if custom_instruction:
        user_guide_prompt = f"""
    [User's Special Direction]
    The user has provided specific instructions for the tone/style. You MUST follow this:
    ğŸ‘‰ "{custom_instruction}"
        """

    prompt = f"""
    [Role]
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìœ íŠœë¸Œ ë‹¤íë©˜í„°ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.

    [Task]
    ì „ì²´ ëŒ€ë³¸ êµ¬ì¡° ì¤‘ ì˜¤ì§ **"{section_title}"** ë¶€ë¶„ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
      
    [Context (Overall Structure)]
    {full_structure}
    {user_guide_prompt}

    [Target Section]
    **{section_title}**

    [Length Constraints]
    - **ëª©í‘œ ë¶„ëŸ‰: {target_chars}** - **ì‘ì„± ì§€ì¹¨:** {detail_level}
      
    [Style Guidelines - ë§¤ìš° ì¤‘ìš”]
    1. 'ìŠµë‹ˆë‹¤' ì²´ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤íë©˜í„°ë¦¬ íŠ¹ìœ ì˜ ì§„ì§€í•˜ê³  ëª°ì…ê° ìˆëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    2. ì•ë’¤ ë¬¸ë§¥(ì´ì „ ì±•í„°, ë‹¤ìŒ ì±•í„°)ì„ ê³ ë ¤í•˜ë˜, ì´ íŒŒíŠ¸ì˜ ë‚´ìš©ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.
    3. (ì§€ë¬¸), (íš¨ê³¼ìŒ) ê°™ì€ ì—°ì¶œ ì§€ì‹œì–´ëŠ” ì œì™¸í•˜ê³  **ì˜¤ì§ ë‚˜ë ˆì´ì…˜ ëŒ€ì‚¬ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
    4. ì„œë‘ì— "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤" ê°™ì€ ì¡ë‹´ì„ í•˜ì§€ ë§ê³  ë°”ë¡œ ëŒ€ë³¸ ë‚´ìš©ì„ ì‹œì‘í•˜ì„¸ìš”.
    5. ì˜ë¬¸ ë³‘ê¸°(ê´„í˜¸)ëŠ” í•˜ì§€ ë§ˆì„¸ìš”. ê¹”ë”í•˜ê²Œ í•œê¸€ë§Œ.
    6. ì‰¼í‘œì™€ ì ‘ì†ì–´ ë“±ì„ ì‚¬ìš©í•˜ì—¬, ë¦¬ë“¬ì´ ìˆì§€ë§Œ ë„ˆë¬´ ëŠê¸°ì§€ ì•ŠëŠ” íë¦„ì„ ë§Œë“¤ ê²ƒ.
    
    # [ìˆ˜ì •ë¨] íë¦„ ëŠê¹€ ë°©ì§€ í•µì‹¬ ì§€ì¹¨ --------------------------
    7. **[ê¸ˆì§€ì‚¬í•­]** ê¸€ì˜ ë§ˆì§€ë§‰ì— "ë‹¤ìŒ ì¥ì—ì„œëŠ”...", "ì´ì–´ì„œ...", "ì´ì œ ~ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤" ê°™ì€ **ì˜ˆê³ ì„± ë©˜íŠ¸ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    8. **[ê¸ˆì§€ì‚¬í•­]** "ì§€ê¸ˆê¹Œì§€ ~ë¥¼ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤" ê°™ì€ **ì¤‘ê°„ ì •ë¦¬ ë©˜íŠ¸ë„ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    9. ì´ í…ìŠ¤íŠ¸ë“¤ì€ ë‚˜ì¤‘ì— í•˜ë‚˜ë¡œ í•©ì³ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ **ê·¸ëƒ¥ ì„¤ëª…í•˜ë‹¤ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥(ë§ˆì¹¨í‘œ)ìœ¼ë¡œ ëë‚´ì‹­ì‹œì˜¤.** ë’·ë‚´ìš©ì€ ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë°›ìŠµë‹ˆë‹¤.
    10. ì±•í„° ë²ˆí˜¸ë‚˜ ì†Œì œëª©ì„ ë³¸ë¬¸ì— ë‹¤ì‹œ ì ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ë‚´ìš©ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
    ---------------------------------------------------------

    [Output]
    (ì§€ê¸ˆ ë°”ë¡œ {section_title}ì˜ ì›ê³ ë¥¼ ì‘ì„± ì‹œì‘í•˜ì„¸ìš”)
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(
                max_output_tokens=8192,
                temperature=0.75 
            )
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 3. ì´ë¯¸ì§€ ìƒì„± ê´€ë ¨ ë¡œì§
# ==========================================

def init_folders():
    for path in [IMAGE_OUTPUT_DIR, AUDIO_OUTPUT_DIR, VIDEO_OUTPUT_DIR]:
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)

def split_script_by_time(script, chars_per_chunk=100):
    temp_sentences = script.replace(".", ".|").replace("?", "?|").replace("!", "!|").split("|")
    chunks = []
    current_chunk = ""
    for sentence in temp_sentences:
        sentence = sentence.strip()
        if not sentence: continue
        if len(current_chunk) + len(sentence) < chars_per_chunk:
            current_chunk += " " + sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def parse_numbered_script(script):
    """
    ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ì„ íŒŒì‹±í•˜ì—¬ ì”¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    ì¤„ë°”ê¿ˆì„ ì œê±°í•˜ê³  ë¬¸ì¥ì„ ì¡°í™”ë¡­ê²Œ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    import re

    scenes = []
    lines = script.strip().split('\n')
    current_scene_lines = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # ìƒˆë¡œìš´ ì”¬ ì‹œì‘ì¸ì§€ í™•ì¸ (ìˆ«ì + ì ìœ¼ë¡œ ì‹œì‘)
        match = re.match(r'^(\d+)\.(.*)$', line)
        if match:
            # ì´ì „ ì”¬ì´ ìˆìœ¼ë©´ ì €ì¥
            if current_scene_lines:
                scene_text = ' '.join(current_scene_lines)
                # ì—°ì† ê³µë°± ì œê±°
                scene_text = re.sub(r'\s+', ' ', scene_text).strip()
                if scene_text:
                    scenes.append(scene_text)

            # ìƒˆ ì”¬ ì‹œì‘ (ë²ˆí˜¸ ë’¤ì˜ ë‚´ìš©)
            rest = match.group(2).strip()
            current_scene_lines = [rest] if rest else []
        else:
            # í˜„ì¬ ì”¬ì— ë¼ì¸ ì¶”ê°€
            current_scene_lines.append(line)

    # ë§ˆì§€ë§‰ ì”¬ ì €ì¥
    if current_scene_lines:
        scene_text = ' '.join(current_scene_lines)
        scene_text = re.sub(r'\s+', ' ', scene_text).strip()
        if scene_text:
            scenes.append(scene_text)

    return scenes

# ==========================================
# [UPGRADE] í•¨ìˆ˜: AI ê¸°ë°˜ ëŒ€ë³¸ ë§¥ë½ ë¶„í•  (ê¸€ììˆ˜ ì œí•œ ì—„ê²©í™”)
# ==========================================
def split_text_automatically(client, full_text, target_chars=370):
    """
    Geminië¥¼ ì´ìš©í•´ ë¬¸ë§¥(Context)ì„ íŒŒì•…í•˜ê³ ,
    ì‹œê°ì  ì¥ë©´ ì „í™˜ì´ í•„ìš”í•œ ì§€ì ë§ˆë‹¤ ëŒ€ë³¸ì„ ë¶„í• í•©ë‹ˆë‹¤.
    ê° ì”¬ì€ ë°˜ë“œì‹œ target_chars ì´í•˜ë¡œ ì œí•œë©ë‹ˆë‹¤.
    """
    prompt = f"""
    [Role] Video Storyboard Editor
    [Task] Split the [Script] into multiple "Scenes".
    [Rules]
    1. **STRICT LIMIT:** Each scene MUST be under {target_chars} characters.
    2. **NEVER MERGE:** Even if only 100 characters remain at the end, make it a SEPARATE scene. NEVER create a chunk longer than {target_chars} characters.
    3. **Context:** Split where the visual topic changes, but prioritize the length limit.
    4. **Output:** Return ONLY a raw JSON list of strings.

    [Script]
    {full_text}
    """

    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )
        scenes = json.loads(response.text)
        if isinstance(scenes, list):
            return [s.strip() for s in scenes if s.strip()]
        else:
            return split_script_by_time(full_text, chars_per_chunk=target_chars)
    except Exception as e:
        print(f"AI Split Error: {e}")
        return split_script_by_time(full_text, chars_per_chunk=target_chars)


# [NEW] ê·œì¹™ ê¸°ë°˜ ë¶„í•  í•¨ìˆ˜ (370ì ê¸°ì¤€ ì—„ê²© ë¶„í• )
def split_script_by_time(script, chars_per_chunk=370):
    """370ì ê¸°ì¤€ ì—„ê²© ë¶„í• : ë§ˆì§€ë§‰ ë‚¨ì€ ê¸€ìë„ ë¬´ì¡°ê±´ ë³„ë„ ì”¬ìœ¼ë¡œ ë¶„í• """
    sentences = re.split(r'(?<=[.?!])\s+', script.strip())
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if not sentence.strip():
            continue

        # í˜„ì¬ ë¬¸ì¥ì´ ì œí•œì„ ë„˜ëŠ” ê²½ìš° (ê°•ì œ ì ˆë‹¨)
        if len(sentence) > chars_per_chunk:
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = ""
            temp = sentence
            while len(temp) > chars_per_chunk:
                chunks.append(temp[:chars_per_chunk].strip())
                temp = temp[chars_per_chunk:]
            current_chunk = temp
            continue

        # ê¸€ììˆ˜ ì²´í¬ (í•©ì³¤ì„ ë•Œ ì œí•œì„ ë„˜ìœ¼ë©´ í˜„ì¬ê¹Œì§€ë¥¼ ì”¬ìœ¼ë¡œ í™•ì •)
        if len(current_chunk) + len(sentence) + 1 > chars_per_chunk:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
        else:
            current_chunk = (current_chunk + " " + sentence).strip() if current_chunk else sentence

    # [í•µì‹¬] ë§ˆì§€ë§‰ ë‚¨ì€ ë¬¸ì¥ì´ 500ìë“  10ìë“  ë¬´ì¡°ê±´ ë³„ê°œ ì”¬ìœ¼ë¡œ ì¶”ê°€
    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


# ==========================================
# [NEW] ë„ì…ë¶€ ë¶„í•  í•¨ìˆ˜ (24~48ì, ì˜ë¯¸ ê¸°ì¤€ ë¶„í• )
# ==========================================
def split_intro_by_meaning(client, intro_text, min_chars=24, max_chars=48):
    """
    ë„ì…ë¶€ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    ê° ì”¬ì€ 4~8ì´ˆ(ì•½ 24~48ì) ë²”ìœ„ë¡œ ì œí•œë©ë‹ˆë‹¤.
    """
    if not intro_text or not intro_text.strip():
        return []

    prompt = f"""
[Role] Short-form Video Editor (ìˆí¼ ì˜ìƒ í¸ì§‘ì)

[Task]
ì•„ë˜ [ë„ì…ë¶€ ëŒ€ë³¸]ì„ **ì˜ë¯¸ ë‹¨ìœ„**ë¡œ ë‚˜ëˆ„ì–´ ì§§ì€ ì”¬ë“¤ë¡œ ë¶„í• í•˜ì„¸ìš”.
ê° ì”¬ì€ 4~8ì´ˆë¡œ ì½ì„ ìˆ˜ ìˆëŠ” ë¶„ëŸ‰ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

[Rules]
1. **ê¸€ììˆ˜ ë²”ìœ„:** ê° ì”¬ì€ **{min_chars}ì ~ {max_chars}ì** ë²”ìœ„ê°€ ì´ìƒì ì…ë‹ˆë‹¤.
2. **ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• :** ë¬¸ì¥ì„ ì–µì§€ë¡œ ìë¥´ì§€ ë§ê³ , ì˜ë¯¸ê°€ ì™„ê²°ë˜ëŠ” ì§€ì ì—ì„œ ë‚˜ëˆ„ì„¸ìš”.
3. **ì§§ì€ ì„íŒ©íŠ¸:** "ë°”ë¡œ ì‚¼ì„±ì…ë‹ˆë‹¤" ê°™ì€ ì§§ì€ ë¬¸ì¥(24ì ë¯¸ë§Œ)ë„ ê·¸ ìì²´ë¡œ í•˜ë‚˜ì˜ ì”¬ì´ ë©ë‹ˆë‹¤.
4. **ìì—°ìŠ¤ëŸ¬ìš´ ëŠê¹€:** ì‰¼í‘œ(,)ë‚˜ ë¬¸ì¥ êµ¬ì¡°ë¥¼ í™œìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„í• í•˜ì„¸ìš”.
5. **ë„ˆë¬´ ê¸¸ë©´ ë¶„í• :** {max_chars}ìë¥¼ í¬ê²Œ ì´ˆê³¼í•˜ë©´ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì„¸ìš”.

[ì˜ˆì‹œ]
ì…ë ¥: "í•œ ê¸°ì—…ì´ ì‚¼ì‹­ë…„ ë§Œì— ìë™ì°¨ ì‹œì¥ì— ë‹¤ì‹œ ë°œì„ ë“¤ì˜€ìŠµë‹ˆë‹¤. ë°”ë¡œ ì‚¼ì„±ì…ë‹ˆë‹¤."
ì¶œë ¥: ["í•œ ê¸°ì—…ì´ 30ë…„ ë§Œì— ìë™ì°¨ ì‹œì¥ì— ë‹¤ì‹œ ë°œì„ ë“¤ì˜€ìŠµë‹ˆë‹¤", "ë°”ë¡œ ì‚¼ì„±ì…ë‹ˆë‹¤"]

[ë„ì…ë¶€ ëŒ€ë³¸]
{intro_text}

[Output]
- JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª… ì—†ì´ ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""

    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )
        scenes = json.loads(response.text)
        if isinstance(scenes, list):
            return [s.strip() for s in scenes if s.strip()]
        else:
            return split_intro_fallback(intro_text, max_chars)
    except Exception as e:
        print(f"Intro Split Error: {e}")
        return split_intro_fallback(intro_text, max_chars)


def split_intro_fallback(intro_text, max_chars=48):
    """ë„ì…ë¶€ ë¶„í•  í´ë°±: ë¬¸ì¥ ë¶€í˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  (4~8ì´ˆ ê¸°ì¤€)"""
    # ë§ˆì¹¨í‘œ, ì‰¼í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
    parts = re.split(r'(?<=[.,?!])\s*', intro_text.strip())
    chunks = []
    current = ""

    for part in parts:
        if not part.strip():
            continue
        if len(part) <= max_chars:
            chunks.append(part.strip())
        elif len(current) + len(part) + 1 <= max_chars:
            current = (current + " " + part).strip() if current else part
        else:
            if current:
                chunks.append(current.strip())
            # ê¸´ ë¬¸ì¥ì€ ê°•ì œ ë¶„í• 
            while len(part) > max_chars:
                chunks.append(part[:max_chars].strip())
                part = part[max_chars:]
            current = part

    if current:
        chunks.append(current.strip())

    return chunks


def make_filename(scene_num, text_chunk):
    clean_line = text_chunk.replace("\n", " ").strip()
    clean_line = re.sub(r'[\\/:*?"<>|]', "", clean_line)
    words = clean_line.split()
    
    if len(words) <= 6:
        summary = " ".join(words)
    else:
        start_part = " ".join(words[:3])
        end_part = " ".join(words[-3:])
        summary = f"{start_part}...{end_part}"
    
    filename = f"S{scene_num:03d}_{summary}.png"
    return filename

# ==========================================
# [ë§ˆìŠ¤í„° ì—…ê·¸ë ˆì´ë“œ] í•¨ìˆ˜: í”„ë¡¬í”„íŠ¸ ìƒì„± (ë²”ìš© ì›”ë“œë¹Œë”© + í™˜ê²½ì  ì¼ì¹˜ + ìŠ¤í† ë¦¬ ì „ê°œ)
# ==========================================
def generate_prompt(api_key, index, text_chunk, style_instruction, video_title, target_language="Korean"):
    """[ìµœì¢… ë§ˆìŠ¤í„° ë²„ì „] ë²”ìš© ë§¥ë½ ì¸ì§€í˜• ì›”ë“œë¹Œë”© + í™˜ê²½ì  ì¼ì¹˜ + ìºë¦­í„° í–‰ë™ ì—°ì¶œ"""
    scene_num = index + 1
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_TEXT_MODEL_NAME}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}

    lang_guide = f"í™”ë©´ ì† í…ìŠ¤íŠ¸ëŠ” ë°˜ë“œì‹œ '{target_language}'(ìœ¼)ë¡œë§Œ ì •í™•íˆ í‘œê¸°í•˜ì‹­ì‹œì˜¤."

    # [í•µì‹¬] ìŠ¤íƒ€ì¼ ì§€ì¹¨: 3D ì œê±°, ìƒí•˜ì˜ ì°©ì¥, ìºë¦­í„° ëˆˆ, í™˜ê²½ í†µí•©
    style_suffix = (
        ", **High-quality 2D flat animation style with subtle cell shading**. "
        "Strictly NO 3D, NO rendering. "
        "The white stickman MUST be fully dressed (vibrant colorful top and trousers). "
        "Character's eyes: large white sclera with small black pupils (cartoon expressive eyes). "
        "**ONE SINGLE UNIFIED SCENE. NO split screens. NO generic square boxes or TV screens.** "
        "**ENVIRONMENTAL INTEGRATION**: Text and data must be part of the world (e.g., as neon signs, massive stone monuments, or physical landscapes). "
        "Text must have a thick high-pixel black outline."
    )

    full_instruction = f"""
[Role] 2D ì• ë‹ˆë©”ì´ì…˜ ì›”ë“œë¹Œë”© ë””ë ‰í„° (World-Building Director)

[Style Guide]
{style_instruction}

[Overall Context]
- ì „ì²´ ì˜ìƒ ì œëª©: "{video_title}"
- í˜„ì¬ ì¥ë©´ ìˆœì„œ: {scene_num}ë²ˆì§¸ ì¥ë©´
- ì „ì²´ì ì¸ íë¦„ì„ ê³ ë ¤í•˜ì—¬, ë‹¨ìˆœíˆ ì •ë³´ë¥¼ ë‚˜ì—´í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ëŒ€ë³¸ì˜ ìƒí™©ì´ 'ë¬¼ë¦¬ì ì¸ ì„¸ê³„'ì—ì„œ ë²Œì–´ì§€ëŠ” ê²ƒì²˜ëŸ¼ ì—°ì¶œí•˜ì‹­ì‹œì˜¤.

[Visual Task: ëŒ€ë³¸ê³¼ í™˜ê²½ì˜ ì¼ì¹˜]
1. **ë°•ìŠ¤í˜• ì—°ì¶œ ê¸ˆì§€:** í…ìŠ¤íŠ¸ë‚˜ ë°ì´í„°ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ë„¤ëª¨ë‚œ ìŠ¤í¬ë¦°, TV, ì¹ íŒì„ ë°°ê²½ì— ë‘ì§€ ë§ˆì‹­ì‹œì˜¤. ëŒ€ì‹  ê·¸ ì •ë³´ë“¤ì´ ë°°ê²½ì˜ 'ì¼ë¶€'ê°€ ë˜ê²Œ í•˜ì‹­ì‹œì˜¤.
   - ì˜ˆ: ì¤‘ìš”í•œ ìˆ«ì/ê¸ˆì•¡ -> ê±°ëŒ€í•œ ë„¤ì˜¨ì‚¬ì¸ì´ë‚˜ í•˜ëŠ˜ì— ë–  ìˆëŠ” í™€ë¡œê·¸ë¨ì²˜ëŸ¼ í‘œí˜„
   - ì˜ˆ: ë„ì „/ì„±ì¥ -> ìºë¦­í„°ê°€ ê°€íŒŒë¥¸ ì‚°ì„ ì˜¤ë¥´ê±°ë‚˜ ë„“ì€ ë°”ë‹¤ë¥¼ í•­í•´í•˜ëŠ” ëª¨ìŠµ
   - ì˜ˆ: ìœ„ê¸°/ë³€í™” -> ê±´ë¬¼ì´ ë³€í˜•ë˜ê±°ë‚˜ í’ê²½ì´ ê·¹ì ìœ¼ë¡œ ë°”ë€ŒëŠ” ëª¨ìŠµ
2. **ë°°ê²½ì˜ êµ¬ì²´í™”:** ì‚¬ë¬´ì‹¤ì„ ë²—ì–´ë‚˜ì‹­ì‹œì˜¤. í™œê¸°ì°¬ ë„ì‹œ, ê´‘í™œí•œ ìì—°, ë¯¸ë˜ì ì¸ ê³µê°„, ì—­ë™ì ì¸ í˜„ì¥ ë“± ëŒ€ë³¸ì˜ 'ê°ì •ê³¼ ì£¼ì œ'ì— ë§ëŠ” ì¥ì†Œë¥¼ ì„ íƒí•˜ì‹­ì‹œì˜¤.
3. **ìºë¦­í„°ì˜ ì—°ê¸°:** ìŠ¤í‹±ë§¨ì€ ë‹¨ìˆœíˆ ì„œ ìˆì§€ ì•Šê³ , ë°°ê²½ì˜ ìƒí™©ì— ì§ì ‘ ë°˜ì‘í•´ì•¼ í•©ë‹ˆë‹¤. (ë‹¬ë¦¬ê¸°, ì í”„, ë†€ëŒ, í™˜í˜¸, ê³ ë¯¼ ë“± ìƒí™©ì— ë§ëŠ” ë™ì‘)
4. **ì „ê°œì„±:** ì´ì „ ì¥ë©´ë“¤ê³¼ ì´ì–´ì§€ëŠ” í•˜ë‚˜ì˜ 'ì´ì•¼ê¸°'ì²˜ëŸ¼ ëŠê»´ì§€ë„ë¡ í’ê²½ì˜ ë””í…Œì¼ì„ ì„¤ì •í•˜ì‹­ì‹œì˜¤.

[ìºë¦­í„° ë° í…ìŠ¤íŠ¸ ê¸°ìˆ  ì§€ì¹¨]
- **ëˆˆ:** í•˜ì–€ ëˆˆììœ„ ì•ˆì— ì‘ì€ ê²€ì€ìƒ‰ ëˆˆë™ì (ë†€ëŒ, ìŠ¬í””, ê¸°ì¨ ë“± ê°ì • í‘œí˜„).
- **ì˜ìƒ:** ìƒí•˜ì˜ë¥¼ ê°–ì¶° ì…ì€ ì»¬ëŸ¬í’€í•œ ì˜ìƒ.
- **í…ìŠ¤íŠ¸:** {lang_guide} (ì‚¬ë¬¼ ìœ„ë‚˜ ë§í’ì„ ì— ë°°ì¹˜í•˜ë˜ ë‘êº¼ìš´ ì™¸ê³½ì„  ì‚¬ìš©).
- **ë‹¨ì¼ ì¥ë©´:** í™”ë©´ ë¶„í• ì´ë‚˜ ë²ˆí˜¸ ë§¤ê¸°ê¸° ì ˆëŒ€ ê¸ˆì§€.
- **ë°ì€ í†¤:** ì–´ë‘ìš´ ì£¼ì œë¼ë„ ë°ì€ ì¡°ëª…ì„ ìœ ì§€í•˜ê³  ì‹œê°ì  ìƒì§•ë¬¼ë¡œ í‘œí˜„.

[í˜„ì¬ ëŒ€ë³¸ ì¡°ê°]
"{text_chunk}"

[Output]
- ë²ˆí˜¸ ì—†ì´, ìºë¦­í„°ì˜ í–‰ë™ê³¼ ë°°ê²½ì˜ ìƒí˜¸ì‘ìš©ì´ ë‹ë³´ì´ëŠ” í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ ë¬¸ë‹¨ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
"""

    payload = {"contents": [{"parts": [{"text": full_instruction}]}]}

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            generated_text = response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
            # ì•ˆì „ì¥ì¹˜: SCENE ë²ˆí˜¸ë‚˜ ë¶„í•  ë‹¨ì–´ ì œê±°
            generated_text = re.sub(r'#+\s*SCENE\s*\d+|ì¥ë©´\s*\d+|ì”¬\s*\d+', '', generated_text, flags=re.IGNORECASE)

            final_prompt = f"{generated_text.rstrip('.')}{style_suffix}"
            return (scene_num, final_prompt)
        else:
            return (scene_num, f"Error: {response.status_code}")
    except Exception as e:
        return (scene_num, f"Error: {e}")

# ==========================================
# [ìˆ˜ì •ë¨] generate_image: API ì œí•œ(429) ì™„ë²½ ëŒ€ì‘ + ì¬ì‹œë„ ê°•í™”
# ==========================================
def generate_image(client, prompt, filename, output_dir, selected_model_name):
    full_path = os.path.join(output_dir, filename)
    
    # [ìˆ˜ì • 1] ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 10íšŒë¡œ ëŠ˜ë ¤ì„œ ì ˆëŒ€ í¬ê¸°í•˜ì§€ ì•Šê²Œ í•¨
    max_retries = 10
    
    # [ìˆ˜ì • 2] ì•ˆì „ í•„í„° (ê¸°ì¡´ ìœ ì§€)
    safety_settings = [
        types.SafetySetting(
            category="HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HARASSMENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HATE_SPEECH",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold="BLOCK_ONLY_HIGH"
        ),
    ]

    for attempt in range(1, max_retries + 1):
        try:
            response = client.models.generate_content(
                model=selected_model_name,
                contents=[prompt],
                config=types.GenerateContentConfig(
                    image_config=types.ImageConfig(aspect_ratio="16:9"),
                    safety_settings=safety_settings 
                )
            )
            
            if response.parts:
                for part in response.parts:
                    if part.inline_data:
                        img_data = part.inline_data.data
                        image = Image.open(BytesIO(img_data))
                        image.save(full_path)
                        return full_path
            
            # ì‘ë‹µì€ ì™”ìœ¼ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° (í•„í„°ë§ ë“±)
            print(f"âš ï¸ [ì‹œë„ {attempt}/{max_retries}] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ. ì¬ì‹œë„... ({filename})")
            time.sleep(2)
            
        except Exception as e:
            error_msg = str(e)
            # [ìƒì„¸ ì—ëŸ¬ ë¡œê¹… ì¶”ê°€]
            print(f"=" * 50)
            print(f"ğŸ”´ [ì—ëŸ¬ ìƒì„¸] {filename}")
            print(f"   ì‹œë„: {attempt}/{max_retries}")
            print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            print(f"   ì—ëŸ¬ ë©”ì‹œì§€: {error_msg}")
            print(f"=" * 50)

            # [í•µì‹¬ ìˆ˜ì •] 429 (Too Many Requests) ë˜ëŠ” 429 Resource Exhausted ì—ëŸ¬ ë°œìƒ ì‹œ
            if "429" in error_msg or "ResourceExhausted" in error_msg:
                wait_time = 30  # 30ì´ˆ ë™ì•ˆ ë©ˆì·„ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„ (ë¶„ë‹¹ ì œí•œ ì´ˆê¸°í™” ëŒ€ê¸°)
                print(f"ğŸ›‘ [API ì œí•œ ê°ì§€] {filename} - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                time.sleep(wait_time)
            elif "400" in error_msg or "InvalidArgument" in error_msg or "SAFETY" in error_msg.upper():
                # 400 ì—ëŸ¬ ë˜ëŠ” ì•ˆì „ í•„í„° - ìƒì„¸ ë¡œê¹…
                print(f"ğŸš« [ì»¨í…ì¸  ê±°ë¶€] {filename} - í”„ë¡¬í”„íŠ¸ê°€ ê±°ë¶€ë¨. 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(5)
            else:
                # ì¼ë°˜ ì—ëŸ¬ëŠ” 5ì´ˆ ëŒ€ê¸°
                print(f"âš ï¸ [ê¸°íƒ€ ì—ëŸ¬] {filename} - 5ì´ˆ ëŒ€ê¸°")
                time.sleep(5)
            
    # [ìµœì¢… ì‹¤íŒ¨]
    print(f"âŒ [ìµœì¢… ì‹¤íŒ¨] {filename} - ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")
    return None

def create_zip_buffer(source_dir):
    buffer = BytesIO()
    with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                zip_file.write(file_path, os.path.basename(file_path))
    buffer.seek(0)
    return buffer

# ==========================================
# [í•¨ìˆ˜] 4. Supertone TTS ë° ì˜¤ë””ì˜¤ í›„ì²˜ë¦¬ (Noise Cut - Micro Fade)
# ==========================================
def check_connection_and_get_voices(api_key, base_url):
    """ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ëª©ì†Œë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/voices"
    headers = {"x-sup-api-key": api_key}
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            voices = []
            if isinstance(data, dict) and "items" in data:
                voices = data["items"]
            elif isinstance(data, list):
                voices = data
            else:
                return False, [], f"ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. (items í‚¤ ì—†ìŒ: {list(data.keys())})"
            
            return True, voices, "âœ… ì—°ê²° ì„±ê³µ!"
            
        elif response.status_code == 401:
            return False, [], "âŒ API Keyê°€ í‹€ë ¸ìŠµë‹ˆë‹¤ (401)"
        elif response.status_code == 404:
            return False, [], f"âŒ ì£¼ì†Œ(URL) ì˜¤ë¥˜ (404). {base_url} ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        else:
            return False, [], f"âŒ ì„œë²„ ì˜¤ë¥˜ ({response.status_code}): {response.text}"
            
    except Exception as e:
        return False, [], f"âŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {str(e)}"

def generate_supertone_tts(api_key, voice_id, text, scene_num, base_url, speed=1.0, pitch=0):
    """Supertone APIë¥¼ ì‚¬ìš©í•´ TTS ì˜¤ë””ì˜¤ ìƒì„± ë° ì €ì¥"""
    
    # 1. í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì -> í•œê¸€)
    normalized_text = normalize_text_for_tts(text)

    # 2. ë§ˆì¹¨í‘œê°€ ìˆë“  ì—†ë“  ë¬´ì¡°ê±´ ë§ˆì¹¨í‘œ í•˜ë‚˜ ë” ì¶”ê°€í•˜ì—¬ í™•ì‹¤í•œ ëë§ºìŒ ìœ ë„
    normalized_text = normalized_text.strip() + "."

    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/text-to-speech/{voice_id}"
    
    headers = {
        "x-sup-api-key": api_key,
        "Content-Type": "application/json"
    }
    
    safe_text = normalized_text[:500] 
    
    payload = {
        "text": safe_text,
        "language": "ko",
        "model": "sona_speech_1",
        "voice_settings": {
            "speed": float(speed),
            "pitch_shift": int(pitch),
            "pitch_variance": 1
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, stream=True)
        
        if response.status_code == 200:
            filename = f"S{scene_num:03d}_audio.wav"
            full_path = os.path.join(AUDIO_OUTPUT_DIR, filename)
            
            # íŒŒì¼ ì €ì¥
            with open(full_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            
            # [KEY FIX] ë§ˆì´í¬ë¡œ í˜ì´ë“œ (Micro-Fade): ë 30msë§Œ ì‚´ì§ ì¤„ì—¬ì„œ íŠ€ëŠ” ì†Œë¦¬ ì œê±°
            try:
                saved_audio = AudioSegment.from_wav(full_path)
                
                if len(saved_audio) > 100:
                    # 0.03ì´ˆ(30ms)ë§Œ í˜ì´ë“œ ì•„ì›ƒ -> ë§ëì€ ì‚´ë¦¬ê³ , ê¸°ê³„ìŒ 'í‹±' ì†Œë¦¬ë§Œ ì œê±°
                    saved_audio = saved_audio.fade_out(30)
                    saved_audio.export(full_path, format="wav")
            except Exception as e:
                print(f"Audio tail fix error: {e}")

            return full_path
        elif response.status_code == 404:
            return "VOICE_NOT_FOUND"
        else:
            return f"Error ({response.status_code}): {response.text}"
            
    except Exception as e:
        return f"System Error: {e}"

def smart_shorten_silence(file_path, max_allowed_silence_ms=300, min_silence_len=100, silence_thresh=-40):
    try:
        audio = AudioSegment.from_wav(file_path)
        silence_ranges = detect_silence(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh
        )

        if not silence_ranges:
            return True, "ë¬´ìŒ êµ¬ê°„ ì—†ìŒ"

        output_audio = AudioSegment.empty()
        last_pos = 0

        for start, end in silence_ranges:
            output_audio += audio[last_pos:start]
            silence_duration = end - start
            if silence_duration > max_allowed_silence_ms:
                output_audio += AudioSegment.silent(duration=max_allowed_silence_ms)
            else:
                output_audio += audio[start:end]
            last_pos = end

        output_audio += audio[last_pos:]
        output_audio.export(file_path, format="wav")
        return True, "ì„±ê³µ"

    except Exception as e:
        return False, str(e)

def process_single_tts_task(api_key, voice_id, text, scene_num, base_url, speed, pitch, apply_silence_trim):
    audio_res = generate_supertone_tts(
        api_key, voice_id, text, scene_num, base_url, speed, pitch
    )
    if "Error" not in str(audio_res) and "VOICE_NOT_FOUND" not in str(audio_res):
        if apply_silence_trim:
            smart_shorten_silence(audio_res, max_allowed_silence_ms=300)
    return audio_res

# ==========================================
# [í•¨ìˆ˜] 5. ë¹„ë””ì˜¤ ìƒì„± (MoviePy - ê³ í™”ì§ˆ ì„¤ì •)
# ==========================================
def create_video_with_zoom(image_path, audio_path, output_dir, scene_num, is_zoom_in=True):
    """
    ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ í•©ì³ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì¤Œ íš¨ê³¼ ë¹„ë””ì˜¤ ìƒì„±.
    [ê³ í™”ì§ˆ ì„¤ì • ì ìš© ì™„ë£Œ]
    """
    try:
        output_filename = f"S{scene_num:03d}_video_zoom.mp4"
        output_path = os.path.join(output_dir, output_filename)
        
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        
        original_pil = Image.open(image_path).convert("RGB")
        W, H = original_pil.size
        
        if W % 2 != 0: W -= 1
        if H % 2 != 0: H -= 1
        if original_pil.size != (W, H):
            original_pil = original_pil.resize((W, H), Image.LANCZOS)

        max_crop_ratio = 0.85 
        
        def effect(get_frame, t):
            progress = t / duration
            if is_zoom_in:
                current_ratio = 1.0 - (1.0 - max_crop_ratio) * progress
            else:
                current_ratio = max_crop_ratio + (1.0 - max_crop_ratio) * progress
            
            roi_w = W * current_ratio
            roi_h = H * current_ratio
            
            x0 = (W - roi_w) / 2
            y0 = (H - roi_h) / 2
            x1 = x0 + roi_w
            y1 = y0 + roi_h
            
            transformed_img = original_pil.transform(
                (W, H), 
                Image.EXTENT, 
                (x0, y0, x1, y1), 
                Image.BICUBIC 
            )
            return np.array(transformed_img)

        video = ImageClip(np.array(original_pil)).set_duration(duration).set_fps(30)
        video = video.fl(effect)
        video = video.set_audio(audio_clip)
        
        # [KEY FIX] ê³ í™”ì§ˆ ë Œë”ë§ ì„¤ì • (ë¹„íŠ¸ë ˆì´íŠ¸ 8000k, ì˜¤ë””ì˜¤ 192k, preset=slow)
        video.write_videofile(
            output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",        # ì˜ìƒ í™”ì§ˆ ëŒ€í­ í–¥ìƒ
            audio_bitrate="192k",   # ì˜¤ë””ì˜¤ ìŒì§ˆ í–¥ìƒ
            preset="slow",          # ì¸ì½”ë”© í’ˆì§ˆ í–¥ìƒ (ì†ë„ëŠ” ì¡°ê¸ˆ ëŠë ¤ì§)
            logger=None
        )
        
        return output_path
        
    except Exception as e:
        return f"Error: {e}"

def process_single_video_task(item, output_dir, is_zoom_in):
    if item.get('audio_path') and os.path.exists(item['audio_path']):
        return create_video_with_zoom(
            item['path'], 
            item['audio_path'], 
            output_dir, 
            item['scene'], 
            is_zoom_in=is_zoom_in
        )
    return None

def merge_all_videos(video_paths, output_dir):
    try:
        clips = []
        for path in video_paths:
            if path and os.path.exists(path):
                clips.append(VideoFileClip(path))
        
        if not clips:
            return "No clips to merge"

        final_clip = concatenate_videoclips(clips, method="compose")
        final_output_path = os.path.join(output_dir, "FINAL_FULL_VIDEO.mp4")
        
        # [KEY FIX] ë³‘í•© ì‹œì—ë„ ê³ í™”ì§ˆ ìœ ì§€
        final_clip.write_videofile(
            final_output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",
            audio_bitrate="192k",
            preset="slow",
            logger=None
        )
        return final_output_path
    except Exception as e:
        return f"Merge Error: {e}"

# ==========================================
# [UI] ì‚¬ì´ë“œë°” (ìë™ ë¡œê·¸ì¸ + ì¥ë¥´ ì„ íƒ ì ìš©)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")

    # 1. Google API Key ì„¤ì • (ë©€í‹° API ì§€ì›)
    st.subheader("ğŸ”‘ API í‚¤ ì„¤ì •")

    # API í‚¤ ê°œìˆ˜ ì„ íƒ ë“œë¡­ë°•ìŠ¤
    num_api_keys = st.selectbox(
        "API í‚¤ ê°œìˆ˜",
        options=[1, 2, 3, 4],
        index=0,
        help="ì—¬ëŸ¬ API í‚¤ë¥¼ ì‚¬ìš©í•˜ë©´ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë” ë¹ ë¥´ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í‚¤ë‹¹ ë¶„ë‹¹ 20ê°œ)"
    )

    # API í‚¤ ì…ë ¥ í•„ë“œë“¤
    api_keys = []

    # secrets.tomlì—ì„œ ìë™ ë¡œë“œ ì‹œë„
    for i in range(num_api_keys):
        secret_key = f"google_api_key_{i+1}" if i > 0 else "google_api_key"

        if "general" in st.secrets and secret_key in st.secrets["general"]:
            key = st.secrets["general"][secret_key]
            st.success(f"ğŸ”‘ API Key {i+1} ë¡œë“œë¨")
            api_keys.append(key)
        else:
            key = st.text_input(
                f"ğŸ”‘ Google API Key {i+1}" if num_api_keys > 1 else "ğŸ”‘ Google API Key",
                type="password",
                key=f"api_key_{i}",
                help=f"API í‚¤ {i+1}ë²ˆì„ ì…ë ¥í•˜ì„¸ìš”."
            )
            if key:
                api_keys.append(key)

    # í˜¸í™˜ì„±ì„ ìœ„í•´ ì²« ë²ˆì§¸ í‚¤ë¥¼ api_keyë¡œë„ ì €ì¥
    api_key = api_keys[0] if api_keys else ""

    if num_api_keys > 1 and len(api_keys) == num_api_keys:
        st.info(f"âœ… {num_api_keys}ê°œ API í‚¤ ì„¤ì •ë¨ â†’ ë¶„ë‹¹ ìµœëŒ€ {num_api_keys * 20}ê°œ ìƒì„± ê°€ëŠ¥")

    st.markdown("---")
    
    st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ")
    model_choice = st.radio("ì‚¬ìš©í•  AI ëª¨ë¸:", ("Premium (Gemini 3 Pro)", "Fast (Gemini-2.5-pro)"), index=0)
    
    if "Gemini 3 Pro" in model_choice:
        SELECTED_IMAGE_MODEL = "gemini-3-pro-image-preview" 
    else:
        SELECTED_IMAGE_MODEL = "gemini-2.5-pro"

    st.info(f"âœ… ì„ íƒ ëª¨ë¸: `{SELECTED_IMAGE_MODEL}`")
    
    st.markdown("---")
    st.subheader("ğŸ“ ëŒ€ë³¸ ë¶„í•  ì•ˆë‚´")
    st.info("ëŒ€ë³¸ì„ ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• í•´ì„œ ì…ë ¥í•˜ì„¸ìš”. ê° ë²ˆí˜¸ê°€ í•˜ë‚˜ì˜ ì”¬ì´ ë©ë‹ˆë‹¤.") 
    
    st.markdown("---")

    # [NEW] ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ì–¸ì–´ ì„ íƒ
    st.subheader("ğŸŒ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì–¸ì–´")
    target_language = st.selectbox(
        "ì´ë¯¸ì§€ ì†ì— ë“¤ì–´ê°ˆ ê¸€ì ì–¸ì–´:",
        ("Korean", "English", "Japanese"),
        index=0,
        help="ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ì—°ì¶œë  ë•Œ ì–´ë–¤ ì–¸ì–´ë¡œ ì ì„ì§€ ì„ íƒí•©ë‹ˆë‹¤."
    )

    st.markdown("---")

    # ==========================================
    # [NEW] ì»¨ì…‰ë³„ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ
    # ==========================================
    # [ìˆ˜ì •ë¨] Gems ìŠ¤íƒ€ì¼ + Context-Aware Visual Guide
    STYLE_PRESETS = {
        "ê²½ì œí•™": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Success/Business:* "Bright White Studio", "Sunny Day", "Warm Golden Light".
    - *Crisis/Sadness:* "Grey Cloudy Daylight", "Dim Indoor Light" (NOT pitch black), "Cold Blue Tint" (keep it bright enough to see).
    - *News:* "Bright TV Studio Lighting".

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: Business/Partnership (e.g., M&A, Deals)**
   - **Background:** Bright conference room, stage with handshake, modern office.
   - **Extras:** A few other stickmen (reporters, investors) in the background.
   - **Text Integration:** Place text on **podiums**, **company flags**, **shirt labels**, or **large presentation screens**.

2. **Scenario: Economic Crisis/Failure (e.g., Collapse, Despair)**
   - **Background:** Grey cloudy city, dim office, rainy street (NOT pitch black).
   - **Extras:** Usually solo, or with a few sad figures in the distance.
   - **Text Integration:** Place text on **broken neon signs**, **cracked walls**, **graffiti**, or **scattered papers**.

3. **Scenario: Market/Public Reaction (e.g., Trends, Opinions)**
   - **Background:** Public spaces like streets, stock market floors, or online communities.
   - **Extras:** **Crowd of anonymous stickmen** showing reactions (angry, confused, cheering).
   - **Text Integration:** Text on **protest signs**, **thought bubbles above crowds**, **stock ticker boards**.

4. **Scenario: News/Announcement**
   - **Background:** Cozy living room with TV, or a bright news studio desk.
   - **Extras:** None (focus on TV) or a news anchor.
   - **Text Integration:** Text inside a **"Breaking News" banner on a TV screen**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on TV Screen, Presentation Slide, Labels on Shirt, Neon Sign with clean border.

[Costume & Role]
- CEO: ë„¤ì´ë¹„ ì •ì¥, ë¹¨ê°„ ë„¥íƒ€ì´ / ê°€ë‚œí•œ ì‚¬ëŒ: ë‚¡ì€ íšŒìƒ‰ ê°€ë””ê±´
- ì§ì¥ì¸: ì™€ì´ì…”ì¸ , ë¸”ë¼ìš°ìŠ¤ / ë¶€ì: ê¸ˆìƒ‰ ì•¡ì„¸ì„œë¦¬

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
""",
        "ì—­ì‚¬": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Victory/Coronation:* "Bright Golden Sunlight", "Warm Throne Room Light".
    - *Battle/War:* "Smoky but Visible Daylight", "Orange Firelight" (NOT pitch black).
    - *Tragedy:* "Grey Cloudy Sky", "Dim Candlelight" (keep it bright enough to see).

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: War/Battle**
   - **Background:** Smoky battlefield with visible sky, siege walls, army camps.
   - **Extras:** **Army of stickmen soldiers** in the background, fallen warriors.
   - **Text Integration:** Text on **war flags**, **shield emblems**, **banners**.

2. **Scenario: Royal/Palace**
   - **Background:** Bright throne room with golden decorations, sunny royal garden.
   - **Extras:** Servants, guards, nobles in the background.
   - **Text Integration:** Text on **royal seals**, **scrolls**, **throne inscriptions**.

3. **Scenario: Revolution/Uprising**
   - **Background:** Town square at dusk (visible), palace gates with torchlight.
   - **Extras:** **Angry crowd of stickmen** with torches and pitchforks.
   - **Text Integration:** Text on **protest banners**, **wanted posters**, **graffiti on walls**.

4. **Scenario: Historical Event/Moment**
   - **Background:** Iconic historical setting with clear lighting (signing ceremony, coronation).
   - **Extras:** Witnesses, historians, important figures.
   - **Text Integration:** Text on **documents**, **stone tablets**, **flags**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on Banners, Royal Seals, Stone Tablets, War Flags.

[Costume & Role - ì—­ì‚¬ ì˜ìƒ]
- ì¡°ì„ : í•œë³µ, ê°“ / ë¡œë§ˆ: í† ê°€, ê°‘ì˜· / ì¤‘ì„¸: ê°‘ì˜·, ì™•ê´€, ë“œë ˆìŠ¤
- ì™•ì¡±: ê¸ˆìƒ‰ ì¥ì‹, ì™•ê´€ / ë†ë¯¼: ì†Œë°•í•œ ì˜· / ì „ì‚¬: ë¬´ê¸°ì™€ ê°‘ì˜·

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
""",
        "ê³¼í•™": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Lab/Research:* "Bright White Lab Lighting", "Clean Fluorescent Light".
    - *Space:* "Starry but Visible Space", "Bright Spaceship Interior" (NOT pitch black void).
    - *Disaster:* "Red Warning Lights with Visible Background", "Smoky but Lit Lab".

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: Discovery/Breakthrough**
   - **Background:** Bright clean laboratory, research facility, eureka moment setting.
   - **Extras:** Research team stickmen celebrating or observing.
   - **Text Integration:** Text on **computer monitors**, **hologram displays**, **scientific charts**.

2. **Scenario: Space/Exploration**
   - **Background:** Starry cosmos with visible elements, bright spaceship interior, alien planet with clear sky.
   - **Extras:** Astronaut crew, mission control stickmen on screens.
   - **Text Integration:** Text on **spaceship consoles**, **mission patches**, **floating HUD**.

3. **Scenario: Disaster/Failure**
   - **Background:** Lab with warning lights (visible), malfunctioning equipment, smoky but lit scene.
   - **Extras:** Panicking scientists, evacuation scenes.
   - **Text Integration:** Text on **warning signs**, **error screens**, **scattered papers**.

4. **Scenario: Future/Technology**
   - **Background:** Bright futuristic city, glowing cyber world, well-lit high-tech facility.
   - **Extras:** Robots, AI interfaces, holographic beings.
   - **Text Integration:** Text as **hologram UI**, **laser projections**, **digital billboards**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on Computer Monitors, Hologram UI, Digital Billboards, Warning Signs.

[Costume & Role - ê³¼í•™ ì˜ìƒ]
- ê³¼í•™ì: í° ê°€ìš´, ë³´ì•ˆê²½ / ì˜ì‚¬: ìˆ˜ìˆ ë³µ, ì²­ì§„ê¸°
- ìš°ì£¼ë¹„í–‰ì‚¬: ìš°ì£¼ë³µ / ì—”ì§€ë‹ˆì–´: ì‘ì—…ë³µ, ì•ˆì „ëª¨

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
""",
        "ì»¤ìŠ¤í…€ (ì§ì ‘ ì…ë ¥)": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Positive/Success:* "Bright White Studio", "Sunny Day", "Warm Golden Light".
    - *Negative/Sad:* "Grey Cloudy Daylight", "Dim Indoor Light" (NOT pitch black).
    - *News:* "Bright TV Studio Lighting".

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: Business/Partnership**
   - **Background:** Bright conference room, stage, modern office.
   - **Extras:** Other stickmen (reporters, investors) in the background.
   - **Text Integration:** Text on **podiums**, **flags**, **shirt labels**, **screens**.

2. **Scenario: Crisis/Failure**
   - **Background:** Grey cloudy scene, dim office, rainy street (NOT pitch black).
   - **Extras:** Solo, or with sad figures in the distance.
   - **Text Integration:** Text on **broken signs**, **cracked walls**, **graffiti**.

3. **Scenario: Public Reaction**
   - **Background:** Bright public spaces, streets, gathering places.
   - **Extras:** **Crowd of stickmen** showing reactions.
   - **Text Integration:** Text on **signs**, **thought bubbles**, **ticker boards**.

4. **Scenario: News/Announcement**
   - **Background:** Bright living room with TV, or well-lit news studio.
   - **Extras:** None or news anchor.
   - **Text Integration:** Text on **TV screen banner**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on TV Screen, Signs, Banners, Shirt Labels.

[Costume & Role]
- ê° ìºë¦­í„°ì˜ ì§ì—…/ì—­í• ì— ë§ëŠ” ì»¬ëŸ¬í’€í•˜ê³  íŠ¹ì§•ì ì¸ ì˜ìƒ

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
"""
    }

    st.subheader("ğŸ¨ ì»¨ì…‰ ì„ íƒ")

    # ì»¨ì…‰ ì„ íƒ ë“œë¡­ë°•ìŠ¤
    selected_style_version = st.selectbox(
        "ì»¨ì…‰ í”„ë¦¬ì…‹",
        list(STYLE_PRESETS.keys()),
        index=0,
        help="ì»¨ì…‰ë³„ë¡œ ìµœì í™”ëœ ìŠ¤íƒ€ì¼ì´ ì ìš©ë©ë‹ˆë‹¤."
    )

    # ì„ íƒëœ í”„ë¦¬ì…‹ ê°€ì ¸ì˜¤ê¸°
    default_style = STYLE_PRESETS[selected_style_version]

    style_instruction = st.text_area("AIì—ê²Œ ì§€ì‹œí•  ê·¸ë¦¼ ìŠ¤íƒ€ì¼", value=default_style.strip(), height=150)
    st.markdown("---")

    max_workers = st.slider("ì‘ì—… ì†ë„(ë³‘ë ¬ ìˆ˜)", 1, 10, 5)

    # [TTS ë¹„í™œì„±í™”] Supertone TTS ì„¤ì • ì œê±°ë¨ - ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹„í™œì„±í™”
    supertone_api_key = ""
    supertone_base_url = DEFAULT_SUPERTONE_URL
    selected_voice_id = ""
    tts_speed = 1.0
    tts_pitch = 0

# ==========================================
# [ìˆ˜ì •ëœ UI] ë©”ì¸ í™”ë©´: ì´ë¯¸ì§€ ìƒì„±
# ==========================================
st.divider()
st.title("ğŸ–¼ï¸ ì”¬ë³„ ì´ë¯¸ì§€ ìƒì„±")
st.caption(f"ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ì„ ë„£ìœ¼ë©´ ê° ì”¬ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. | ğŸ¨ Model: {SELECTED_IMAGE_MODEL}")

st.subheader("ğŸ“Œ ì „ì²´ ì˜ìƒ í…Œë§ˆ(ì œëª©) ì„¤ì •")
st.caption("ì´ë¯¸ì§€ ìƒì„± ì‹œ ì´ ì œëª©ì´ 'ì „ì²´ì ì¸ ë¶„ìœ„ê¸° ê¸°ì¤€'ì´ ë©ë‹ˆë‹¤.")

if 'video_title' not in st.session_state:
    st.session_state['video_title'] = ""
if 'title_candidates' not in st.session_state:
    st.session_state['title_candidates'] = []

col_title_input, col_title_btn = st.columns([4, 1])

# [ìˆ˜ì •ë¨] ë²„íŠ¼ ë¡œì§: ì œëª© ì…ë ¥ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ
with col_title_btn:
    st.write("")
    st.write("")
    if st.button("ğŸ’¡ ì œëª© 5ê°œ ì¶”ì²œ", help="ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.", use_container_width=True):
        current_user_title = st.session_state.get('video_title', "").strip()

        if not api_key:
            st.error("API Key í•„ìš”")
        elif not current_user_title:
            st.warning("âš ï¸ ë¨¼ì € 'ì£¼ì œ'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            client = genai.Client(api_key=api_key)
            with st.spinner("AIê°€ ìµœì ì˜ ì œëª©ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
                title_prompt = f"""
                [Role] You are a YouTube viral marketing expert.
                [Target Topic]
                "{current_user_title}"
                [Task]
                Generate 5 click-bait YouTube video titles based on the Target Topic above.
                ì‚¬ìš©ìê°€ ì…ë ¥í•œê±°ë‘ ìµœëŒ€í•œ ë¹„ìŠ·í•œ ì œëª©ìœ¼ë¡œ ì¶”ì²œ, 'ëª°ë½'ì´ ë“¤ì–´ê°„ ê²½ìš° ë§¨ ë’¤ì— ëª°ë½ìœ¼ë¡œ ëë‚˜ê²Œ í•œë‹¤.

                [Output Format]
                - Output ONLY the list of 5 titles.
                - No numbering (1., 2.), just 5 lines of text.
                - Language: Korean
                """

                try:
                    resp = client.models.generate_content(
                        model=GEMINI_TEXT_MODEL_NAME,
                        contents=title_prompt
                    )
                    candidates = [line.strip() for line in resp.text.split('\n') if line.strip()]
                    clean_candidates = []
                    import re
                    for c in candidates:
                        clean = re.sub(r'^\d+\.\s*', '', c).replace('*', '').replace('"', '').strip()
                        if clean: clean_candidates.append(clean)

                    st.session_state['title_candidates'] = clean_candidates[:5]
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

with col_title_input:
    st.text_input(
        "ì˜ìƒ ì œëª© (ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìš°ì¸¡ ë²„íŠ¼ìœ¼ë¡œ ì¶”ì²œë°›ìœ¼ì„¸ìš”)",
        key="video_title", 
        placeholder="ì œëª© í˜¹ì€ ë§Œë“¤ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¶€ìë“¤ì˜ ìŠµê´€)"
    )

if st.session_state['title_candidates']:
    st.info("ğŸ‘‡ AIê°€ ì¶”ì²œí•œ ì œëª©ì…ë‹ˆë‹¤. í´ë¦­í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤.")

    def apply_title(new_title):
        st.session_state['video_title'] = new_title
        st.session_state['title_candidates'] = [] 

    for idx, title in enumerate(st.session_state['title_candidates']):
        col_c1, col_c2 = st.columns([4, 1])
        with col_c1:
            st.markdown(f"**{idx+1}. {title}**")
        with col_c2:
            st.button(
                "âœ… ì„ íƒ", 
                key=f"sel_title_{idx}", 
                on_click=apply_title, 
                args=(title,), 
                use_container_width=True
            )
    
    if st.button("âŒ ëª©ë¡ ë‹«ê¸°"):
        st.session_state['title_candidates'] = []

if 'section_scripts' in st.session_state and st.session_state['section_scripts']:
    intro_text_acc = ""
    main_text_acc = ""
    for title_key, text in st.session_state['section_scripts'].items():
        if "Intro" in title_key or "ë„ì…ë¶€" in title_key:
            intro_text_acc += text + "\n\n"
        else:
            main_text_acc += text + "\n\n"
            
    st.write("ğŸ‘‡ **ìƒì„±ëœ ëŒ€ë³¸ ê°€ì ¸ì˜¤ê¸° (í´ë¦­ ì‹œ ì•„ë˜ ì…ë ¥ì°½ì— ì±„ì›Œì§‘ë‹ˆë‹¤)**")
    
    col_get1, col_get2 = st.columns(2)
    if "image_gen_input" not in st.session_state:
        st.session_state["image_gen_input"] = ""

    with col_get1:
        if st.button("ğŸ“¥ ì¸íŠ¸ë¡œ(Intro)ë§Œ ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = intro_text_acc.strip()
            st.rerun()
    with col_get2:
        if st.button("ğŸ“¥ ë³¸ë¡ (Chapters) + ê²°ë¡ (Epilogue) ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = main_text_acc.strip()
            st.rerun()

# ==========================================
# [UI] ë©”ì¸ í™”ë©´: ëŒ€ë³¸ ì…ë ¥ (ë„ì…ë¶€ + ë³¸ë¬¸ ë¶„ë¦¬)
# ==========================================
st.divider()
st.subheader("ğŸ“œ ëŒ€ë³¸ ì…ë ¥ (ë„ì…ë¶€ / ë³¸ë¬¸ ë¶„ë¦¬)")

# ë„ì…ë¶€ ì…ë ¥
st.markdown("### ğŸ¬ ë„ì…ë¶€ (ì¸íŠ¸ë¡œ)")
st.caption("ë„ì…ë¶€ëŠ” **4~8ì´ˆ(24~48ì)** ë‹¨ìœ„ë¡œ ì˜ë¯¸ ê¸°ì¤€ ë¶„í• ë©ë‹ˆë‹¤. ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë¬¸ì¥ë“¤ë¡œ êµ¬ì„±í•˜ì„¸ìš”.")
intro_input = st.text_area(
    "ë„ì…ë¶€ ëŒ€ë³¸",
    height=120,
    placeholder="ì˜ˆì‹œ:\ní•œ ê¸°ì—…ì´ ì‚¼ì‹­ë…„ ë§Œì— ìë™ì°¨ ì‹œì¥ì— ë‹¤ì‹œ ë°œì„ ë“¤ì˜€ìŠµë‹ˆë‹¤. ë°”ë¡œ ì‚¼ì„±ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ë²ˆì—” SM5 ê°™ì€ ì°¨ë¥¼ ë§Œë“¤ê² ë‹¤ëŠ” ê²Œ ì•„ë‹™ë‹ˆë‹¤.",
    key="intro_input"
)

st.markdown("---")

# ë³¸ë¬¸ ì…ë ¥
st.markdown("### ğŸ“ ë³¸ë¬¸")
col_input_opt, col_input_txt = st.columns([1, 3])

with col_input_opt:
    st.info("â±ï¸ ë³¸ë¬¸ ì”¬ ë¶„í•  ì„¤ì •")
    scene_duration = st.slider(
        "í•œ ì”¬ë‹¹ ëª©í‘œ ê¸€ììˆ˜",
        min_value=100,
        max_value=500,
        value=370,
        step=10,
        help="ë³¸ë¬¸ì˜ ê° ì”¬ì€ ì´ ê¸€ììˆ˜ ì´í•˜ë¡œ ë¶„í• ë©ë‹ˆë‹¤."
    )
    st.caption(f"ì•½ {scene_duration}ì â‰ˆ {scene_duration // 6}ì´ˆ ë¶„ëŸ‰")

with col_input_txt:
    script_input = st.text_area(
        "ë³¸ë¬¸ ëŒ€ë³¸",
        height=250,
        placeholder="ë³¸ë¬¸ ëŒ€ë³¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”. AIê°€ ë¬¸ë§¥ì„ íŒŒì•…í•´ ìë™ìœ¼ë¡œ ì”¬ì„ ë‚˜ëˆ•ë‹ˆë‹¤.\n\nì˜ˆì‹œ:\nì‚¼ì„±ì´ ë…¸ë¦¬ëŠ” ê±´ ìë™ì°¨ì˜ ê»ë°ê¸°ê°€ ì•„ë‹ˆë¼ ì˜í˜¼ì…ë‹ˆë‹¤. 2ì¡° 6ì²œì–µ ì›, ì›¬ë§Œí•œ ëŒ€ê¸°ì—… ì‹œê°€ì´ì•¡ì— ë§ë¨¹ëŠ” ëˆì„ ë² íŒ…í–ˆìŠµë‹ˆë‹¤...",
        key="image_gen_input"
    )

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'generated_results' not in st.session_state:
    st.session_state['generated_results'] = []
if 'is_processing' not in st.session_state:
    st.session_state['is_processing'] = False
if 'split_scenes' not in st.session_state:
    st.session_state['split_scenes'] = []

# ==========================================
# [NEW] ì”¬ ë¶„í•  ë¯¸ë¦¬ë³´ê¸° (ì´ë¯¸ì§€ ìƒì„± ì „ í™•ì¸)
# ==========================================
col_split_btn, col_gen_btn = st.columns(2)

with col_split_btn:
    split_btn = st.button("âœ‚ï¸ ì”¬ ë¶„í•  ë¯¸ë¦¬ë³´ê¸°", type="secondary", use_container_width=True)

with col_gen_btn:
    def clear_generated_results():
        st.session_state['generated_results'] = []
    start_btn = st.button("ğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘", type="primary", use_container_width=True, on_click=clear_generated_results)

# [ì”¬ ë¶„í•  ë¯¸ë¦¬ë³´ê¸° ì²˜ë¦¬] - ë„ì…ë¶€ + ë³¸ë¬¸ í†µí•©
if split_btn:
    if not api_key:
        st.error("âš ï¸ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not intro_input and not script_input:
        st.warning("âš ï¸ ë„ì…ë¶€ ë˜ëŠ” ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ğŸ§  AIê°€ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì”¬ì„ ë‚˜ëˆ„ëŠ” ì¤‘..."):
            preview_client = genai.Client(api_key=api_key)
            all_scenes = []

            # 1. ë„ì…ë¶€ ë¶„í•  (24~48ì, ì˜ë¯¸ ê¸°ì¤€)
            if intro_input and intro_input.strip():
                intro_scenes = split_intro_by_meaning(preview_client, intro_input)
                all_scenes.extend(intro_scenes)
                st.info(f"ğŸ¬ ë„ì…ë¶€: {len(intro_scenes)}ê°œ ì”¬ (4~8ì´ˆ)")

            # 2. ë³¸ë¬¸ ë¶„í•  (370ì ê¸°ì¤€)
            if script_input and script_input.strip():
                main_scenes = split_text_automatically(preview_client, script_input, target_chars=scene_duration)
                all_scenes.extend(main_scenes)
                st.info(f"ğŸ“ ë³¸ë¬¸: {len(main_scenes)}ê°œ ì”¬")

            st.session_state['split_scenes'] = all_scenes
        st.success(f"âœ… ì´ {len(st.session_state['split_scenes'])}ê°œ ì”¬ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤. (ë„ì…ë¶€ + ë³¸ë¬¸)")

# [ë¶„í• ëœ ì”¬ í‘œì‹œ] - ë‹¨ì¼ ë“œë¡­ë°•ìŠ¤ ì•ˆì— ê°œë³„ ë°•ìŠ¤ë¡œ í‘œì‹œ (ì´ë¯¸ì§€ ìƒì„± ì „ì—ë§Œ í‘œì‹œ)
if st.session_state.get('split_scenes') and not st.session_state.get('generated_results'):
    with st.expander(f"ğŸ¬ ì”¬ ë¶„í•  ê²°ê³¼ ({len(st.session_state['split_scenes'])}ê°œ)", expanded=True):
        for idx, scene_text in enumerate(st.session_state['split_scenes']):
            st.markdown(f"""
            <div style="background-color: #f0f2f6; border-radius: 10px; padding: 15px; margin-bottom: 10px; border-left: 4px solid #4CAF50;">
                <strong style="color: #1f77b4;">ì”¬ {idx + 1}</strong> <span style="color: #666;">({len(scene_text)}ì)</span>
                <p style="margin-top: 8px; color: #333; white-space: pre-wrap;">{scene_text}</p>
            </div>
            """, unsafe_allow_html=True)

st.divider()

# [ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬] - ë„ì…ë¶€ + ë³¸ë¬¸ í†µí•©
if start_btn:
    if not api_key:
        st.error("âš ï¸ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not intro_input and not script_input:
        st.warning("âš ï¸ ë„ì…ë¶€ ë˜ëŠ” ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # ê¸°ì¡´ ê²°ê³¼ ì´ˆê¸°í™”
        st.session_state['generated_results'] = []
        st.session_state['is_processing'] = True

        # ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚­ì œ
        if os.path.exists(IMAGE_OUTPUT_DIR):
            shutil.rmtree(IMAGE_OUTPUT_DIR)
        init_folders()

        # [ë©€í‹° API ì§€ì›] ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        clients = []
        for key in api_keys:
            clients.append(genai.Client(api_key=key))

        # ë©”ì¸ í´ë¼ì´ì–¸íŠ¸ (AI ë¶„í• ìš©)
        client = clients[0] if clients else genai.Client(api_key=api_key)

        status_box = st.status("ì‘ì—… ì§„í–‰ ì¤‘...", expanded=True)
        progress_bar = st.progress(0)

        # -------------------------------------------------------
        # [í•µì‹¬] ë„ì…ë¶€ + ë³¸ë¬¸ ë¶„í• 
        # -------------------------------------------------------
        chunks = []

        # 1. ë„ì…ë¶€ ë¶„í•  (24~48ì, ì˜ë¯¸ ê¸°ì¤€)
        if intro_input and intro_input.strip():
            status_box.write("ğŸ¬ ë„ì…ë¶€ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” ì¤‘... (4~8ì´ˆ)")
            intro_chunks = split_intro_by_meaning(client, intro_input)
            chunks.extend(intro_chunks)
            status_box.write(f"âœ… ë„ì…ë¶€: {len(intro_chunks)}ê°œ ì”¬")

        # 2. ë³¸ë¬¸ ë¶„í•  (370ì ê¸°ì¤€)
        if script_input and script_input.strip():
            status_box.write(f"ğŸ“ ë³¸ë¬¸ì„ ë¶„í• í•˜ëŠ” ì¤‘... (ê¸°ì¤€: ì•½ {scene_duration}ì)")
            main_chunks = split_text_automatically(client, script_input, target_chars=scene_duration)
            chunks.extend(main_chunks)
            status_box.write(f"âœ… ë³¸ë¬¸: {len(main_chunks)}ê°œ ì”¬")

        total_scenes = len(chunks)

        if total_scenes == 0:
            status_box.update(label="âš ï¸ ë¶„í•  ì‹¤íŒ¨.", state="error")
            st.stop()

        status_box.write(f"âœ… AI ë¶„ì„ ì™„ë£Œ: ì´ {total_scenes}ê°œì˜ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # [ì¤‘ìš”] ë¶„í• ëœ ì”¬ì„ session_stateì— ì €ì¥ (ê²°ê³¼ë¬¼ ìœ„ì— í‘œì‹œí•˜ê¸° ìœ„í•´)
        st.session_state['split_scenes'] = chunks

        # [ë§¥ë½ ì£¼ì…] ì˜ìƒ ì œëª©ì´ ì—†ë‹¤ë©´ ì²« ë¬¸ì¥ìœ¼ë¡œ ëŒ€ì²´
        current_video_title = st.session_state.get('video_title', "").strip()
        if not current_video_title:
            # ë„ì…ë¶€ ë˜ëŠ” ë³¸ë¬¸ì—ì„œ ë§¥ë½ ì¶”ì¶œ
            context_text = intro_input if intro_input else script_input
            current_video_title = f"Context: {context_text[:200]}..."

        # -------------------------------------------------------
        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± (ë³‘ë ¬) - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        # -------------------------------------------------------
        status_box.write(f"ğŸ“ ì”¬ë³„ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì¤‘ ({GEMINI_TEXT_MODEL_NAME})...")
        prompts = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []

            for i, chunk in enumerate(chunks):
                futures.append(executor.submit(
                    generate_prompt,
                    api_key,
                    i,
                    chunk,
                    style_instruction,
                    current_video_title,
                    target_language
                ))

            for i, future in enumerate(as_completed(futures)):
                prompts.append(future.result())
                progress_bar.progress((i + 1) / (total_scenes * 2))

        prompts.sort(key=lambda x: x[0])

        # 3. ì´ë¯¸ì§€ ìƒì„± (ë©€í‹° API ë³‘ë ¬ ì²˜ë¦¬)
        num_clients = len(clients)
        total_rate_limit = num_clients * 20  # ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜ (í‚¤ë‹¹ 20ê°œ)

        if num_clients > 1:
            status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL}) - {num_clients}ê°œ API ë³‘ë ¬ ì²˜ë¦¬ (ë¶„ë‹¹ ìµœëŒ€ {total_rate_limit}ê°œ)")
        else:
            status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL})... (API ë³´í˜¸ë¥¼ ìœ„í•´ ì²œì²œíˆ ì§„í–‰ë©ë‹ˆë‹¤)")

        results = []

        # [ë©€í‹° API] API í‚¤ ê°œìˆ˜ì— ë”°ë¼ worker ìˆ˜ì™€ ëŒ€ê¸° ì‹œê°„ ì¡°ì ˆ (ì•ˆì •ì„± ê°•í™”)
        # í‚¤ 1ê°œ: 4ì´ˆ ê°„ê²© (ë¶„ë‹¹ 15ê°œ, ì•ˆì „ ë§ˆì§„)
        # í‚¤ 2ê°œ: 3ì´ˆ ê°„ê²© (ë¶„ë‹¹ 20ê°œ x 2 = 40ê°œ ê°€ëŠ¥í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ)
        # í‚¤ 3ê°œ: 2ì´ˆ ê°„ê²©
        # í‚¤ 4ê°œ: 1.5ì´ˆ ê°„ê²©
        sleep_interval = max(4.0 / num_clients, 1.5)  # ìµœì†Œ 1.5ì´ˆ ë³´ì¥
        adjusted_workers = min(max_workers, num_clients * 3)  # API í‚¤ë‹¹ 3ê°œ workerë¡œ ì¶•ì†Œ

        with ThreadPoolExecutor(max_workers=adjusted_workers) as executor:
            future_to_meta = {}
            request_count = 0

            for s_num, prompt_text in prompts:
                idx = s_num - 1
                orig_text = chunks[idx]
                fname = make_filename(s_num, orig_text)

                # [ë¼ìš´ë“œ ë¡œë¹ˆ] í´ë¼ì´ì–¸íŠ¸ ìˆœí™˜ ë°°ì •
                current_client = clients[request_count % num_clients]

                # [ì†ë„ ì¡°ì ˆ] API í‚¤ ê°œìˆ˜ì— ë§ì¶° ëŒ€ê¸°
                time.sleep(sleep_interval)

                # [80ê°œ ì œí•œ] ë©€í‹° API ì‚¬ìš© ì‹œ 80ê°œë§ˆë‹¤ 1ë¶„ ëŒ€ê¸°
                if num_clients > 1 and request_count > 0 and request_count % total_rate_limit == 0:
                    status_box.write(f"â³ API ì œí•œ ë³´í˜¸: {request_count}ê°œ ì™„ë£Œ, 60ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(60)

                future = executor.submit(generate_image, current_client, prompt_text, fname, IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL)
                future_to_meta[future] = (s_num, fname, orig_text, prompt_text)
                request_count += 1
            
            # ê²°ê³¼ ìˆ˜ì§‘
            completed_cnt = 0
            for future in as_completed(future_to_meta):
                s_num, fname, orig_text, p_text = future_to_meta[future]
                path = future.result()
                
                # [í•µì‹¬] ì‹¤íŒ¨(None)í•˜ë”ë¼ë„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ë„£ì–´ì„œ ìˆœì„œê°€ ë°€ë¦¬ì§€ ì•Šê²Œ í•¨ (ì›í•œë‹¤ë©´ ì—ëŸ¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥)
                if path:
                    results.append({
                        "scene": s_num,
                        "path": path,
                        "filename": fname,
                        "script": orig_text,
                        "prompt": p_text,
                        "audio_path": None,
                        "video_path": None 
                    })
                else:
                    # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë„˜ì–´ê°€ê±°ë‚˜, ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì„ ìˆ˜ë„ ìˆìŒ
                    st.error(f"Scene {s_num} ì´ë¯¸ì§€ ìƒì„± ìµœì¢… ì‹¤íŒ¨.")

                completed_cnt += 1
                progress_bar.progress(0.5 + (completed_cnt / total_scenes * 0.5))
        
        results.sort(key=lambda x: x['scene'])
        st.session_state['generated_results'] = results
        
        status_box.update(label="âœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", state="complete", expanded=False)
        st.session_state['is_processing'] = False
        
# ==========================================
# [ìˆ˜ì •ë¨] ê²°ê³¼ì°½ ë° ê°œë³„ ì¬ìƒì„± ê¸°ëŠ¥ ì¶”ê°€
# ==========================================
if st.session_state['generated_results']:
    st.divider()

    # [NEW] ê²°ê³¼ë¬¼ ìœ„ì— ì”¬ ë¶„í•  ê²°ê³¼ í‘œì‹œ - ë‹¨ì¼ ë“œë¡­ë°•ìŠ¤ ì•ˆì— ê°œë³„ ë°•ìŠ¤
    if st.session_state.get('split_scenes'):
        with st.expander(f"ğŸ“‹ ì”¬ ë¶„í•  ê²°ê³¼ ({len(st.session_state['split_scenes'])}ê°œ)", expanded=False):
            for idx, scene_text in enumerate(st.session_state['split_scenes']):
                st.markdown(f"""
                <div style="background-color: #f0f2f6; border-radius: 10px; padding: 15px; margin-bottom: 10px; border-left: 4px solid #4CAF50;">
                    <strong style="color: #1f77b4;">ì”¬ {idx + 1}</strong> <span style="color: #666;">({len(scene_text)}ì)</span>
                    <p style="margin-top: 8px; color: #333; white-space: pre-wrap;">{scene_text}</p>
                </div>
                """, unsafe_allow_html=True)
        st.divider()

    st.header(f"ğŸ“¸ ê²°ê³¼ë¬¼ ({len(st.session_state['generated_results'])}ì¥)")
    
    # ------------------------------------------------
    # 1. ì¼ê´„ ì‘ì—… ë²„íŠ¼ ì˜ì—­
    # ------------------------------------------------
    st.write("---")
    zip_data = create_zip_buffer(IMAGE_OUTPUT_DIR)
    st.download_button("ğŸ“¦ ì „ì²´ ì´ë¯¸ì§€ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_data, file_name="all_images.zip", mime="application/zip", use_container_width=True)

    # ------------------------------------------------
    # 2. ê°œë³„ ë¦¬ìŠ¤íŠ¸ ë° [ì¬ìƒì„±] ê¸°ëŠ¥
    # ------------------------------------------------
    for index, item in enumerate(st.session_state['generated_results']):
        with st.container(border=True):
            cols = st.columns([1, 2])
            
            # [ì™¼ìª½] ì´ë¯¸ì§€ ë° ì¬ìƒì„± ë²„íŠ¼
            with cols[0]:
                try: st.image(item['path'], use_container_width=True)
                except: st.error("ì´ë¯¸ì§€ ì—†ìŒ")
                
                # [NEW] ì´ë¯¸ì§€ ê°œë³„ ì¬ìƒì„± ë²„íŠ¼
                if st.button(f"ğŸ”„ ì´ ì¥ë©´ë§Œ ì´ë¯¸ì§€ ë‹¤ì‹œ ìƒì„±", key=f"regen_img_{index}", use_container_width=True):
                    if not api_key:
                        st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        with st.spinner(f"Scene {item['scene']} ë‹¤ì‹œ ê·¸ë¦¬ëŠ” ì¤‘..."):
                            client = genai.Client(api_key=api_key)
                            
                            # 1. í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ìƒì„± (í˜„ì¬ ëŒ€ë³¸ê³¼ ìŠ¤íƒ€ì¼ ë°˜ì˜)
                            current_title = st.session_state.get('video_title', '')
                            # ëŒ€ë³¸ì´ ìˆ˜ì •ë˜ì—ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ item['script'] ì‚¬ìš©
                            _, new_prompt = generate_prompt(
                                api_key, index, item['script'], style_instruction,
                                current_title, target_language
                            )
                            
                            # 2. ì´ë¯¸ì§€ ìƒì„±
                            new_path = generate_image(
                                client, new_prompt, item['filename'], 
                                IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL
                            )
                            
                            if new_path:
                                # 3. ê²°ê³¼ ì—…ë°ì´íŠ¸
                                st.session_state['generated_results'][index]['path'] = new_path
                                st.session_state['generated_results'][index]['prompt'] = new_prompt
                                # ì´ë¯¸ì§€ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ê¸°ì¡´ ë¹„ë””ì˜¤ëŠ” ë¬´íš¨í™”
                                st.session_state['generated_results'][index]['video_path'] = None
                                st.success("ì´ë¯¸ì§€ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                time.sleep(0.5)
                                st.rerun()
                            else:
                                st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            # [ì˜¤ë¥¸ìª½] ì •ë³´
            with cols[1]:
                st.subheader(f"Scene {item['scene']:02d}")
                st.caption(f"íŒŒì¼ëª…: {item['filename']}")
                st.write(f"**ëŒ€ë³¸:** {item['script']}")

                with st.expander("í”„ë¡¬í”„íŠ¸ í™•ì¸"):
                    st.text(item['prompt'])
                try:
                    with open(item['path'], "rb") as file:
                        st.download_button("â¬‡ï¸ ì´ë¯¸ì§€ ì €ì¥", data=file, file_name=item['filename'], mime="image/png", key=f"btn_down_{item['scene']}")
                except: pass



