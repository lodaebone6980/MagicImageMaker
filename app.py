import streamlit as st
import requests
import json
import time
import os
import re
import shutil
import zipfile
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from PIL import Image
from google import genai
from google.genai import types

# [NEW] ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from pydub import AudioSegment
from pydub.silence import detect_silence

# [NEW] ë™ì˜ìƒ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° íš¨ê³¼ ì¶”ê°€
try:
    # VideoFileClip, concatenate_videoclips ì¶”ê°€ (ì˜ìƒ ë³‘í•©ìš©)
    from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, VideoFileClip, concatenate_videoclips
    import numpy as np 
except ImportError:
    st.error("âš ï¸ 'moviepy' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì— 'pip install moviepy numpy'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì´ë¯¸ì§€ ìƒì„±ê¸°", layout="wide", page_icon="ğŸ¨")

# íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
BASE_PATH = "./web_result_files"
IMAGE_OUTPUT_DIR = os.path.join(BASE_PATH, "output_images")
AUDIO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_audio")
VIDEO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_video") 

# í…ìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •
GEMINI_TEXT_MODEL_NAME = "gemini-2.5-pro" 

# [ê¸°ë³¸ê°’] ë¬¸ì„œì— ëª…ì‹œëœ ì •í™•í•œ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ
DEFAULT_SUPERTONE_URL = "https://supertoneapi.com"
DEFAULT_VOICE_ID = "ff700760946618e1dcf7bd" 

# ==========================================
# [í•¨ìˆ˜] 0. TTSìš© í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì/ê¸°í˜¸ -> í•œê¸€)
# ==========================================
def num_to_kor(num_str):
    """ìˆ«ì ë¬¸ìì—´ì„ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 1,500 -> ì²œì˜¤ë°±)"""
    try:
        num_str = num_str.replace(',', '')
        if not num_str.isdigit(): return num_str
        
        num = int(num_str)
        if num == 0: return "ì˜"
        
        units = ['', 'ì‹­', 'ë°±', 'ì²œ']
        big_units = ['', 'ë§Œ', 'ì–µ', 'ì¡°', 'ê²½']
        num_chars = ['', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
        
        result = []
        big_idx = 0
        
        while num > 0:
            small_part = num % 10000
            if small_part > 0:
                small_res = []
                small_idx = 0
                while small_part > 0:
                    digit = small_part % 10
                    if digit > 0:
                        unit = units[small_idx]
                        char = num_chars[digit]
                        if digit == 1 and small_idx > 0:
                            char = ""
                        small_res.append(char + unit)
                    small_part //= 10
                    small_idx += 1
                result.append("".join(reversed(small_res)) + big_units[big_idx])
            num //= 10000
            big_idx += 1
            
        return "".join(reversed(result))
    except:
        return num_str

def normalize_text_for_tts(text):
    """TTS ë°œìŒì„ ìœ„í•´ íŠ¹ìˆ˜ë¬¸ìì™€ ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜"""
    text = text.replace("%", " í¼ì„¼íŠ¸")
    
    def replace_decimal(match):
        return f"{match.group(1)} ì  {match.group(2)}"
    text = re.sub(r'(\d+)\.(\d+)', replace_decimal, text)

    def replace_number(match):
        return num_to_kor(match.group())
    
    text = re.sub(r'\d+(?:,\d+)*', replace_number, text)
    
    return text

# ==========================================
# [í•¨ìˆ˜] 1. ëŒ€ë³¸ êµ¬ì¡°í™” ë¡œì§
# ==========================================
def generate_structure(client, full_script):
    """Geminië¥¼ ì´ìš©í•´ ëŒ€ë³¸ êµ¬ì¡°í™”"""
    prompt = f"""
    [Role]
    You are a professional YouTube Content Editor and Scriptwriter.

    [Task]
    Analyze the provided transcript (script).
    Restructure the content into a highly detailed, list-style format suitable for a blog post or a new video plan.
      
    [Output Format]
    1. **Video Theme/Title**: (Extract or suggest a catchy title based on the whole script)
    2. **Intro**: (Hook and background, no music) Approve specific channel names, The intro hooks the overall topic (ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ ê°™ì€ ì¸ì‚¬ ê¸ˆì§€)
    3. **Chapter 1** to **Chapter 8**: (Divide the main content into logical sections. Use detailed bullet points for each chapter.)
    4. **Epilogue**: (Conclusion and Subscribe Like Comments that make you anticipate the next specific content)

    [Constraint]
    - Analyze the entire context deeply.
    - Write the output in **Korean**.
    - Make the content rich and detailed.
    - If the original script has a channel name, remove it.

    [Transcript]
    {full_script}
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 2. ì„¹ì…˜ë³„ ëŒ€ë³¸ ìƒì„± (ìˆ˜ì • ë²„ì „)
# ==========================================
def generate_section(client, section_title, full_structure, duration_type="fixed", custom_instruction=""):
    # 1. ë¶„ëŸ‰ì— ë”°ë¥¸ ê¸€ììˆ˜ ë° ì§€ì¹¨ ì„¤ì •
    if duration_type == "2min":
        target_chars = "ì•½ 1,000ì (ê³µë°± í¬í•¨)"
        detail_level = "í•µì‹¬ ë‚´ìš© ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ë˜, ë„ˆë¬´ ì§§ì§€ ì•Šê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "3min":
        target_chars = "ì•½ 1,500ì (ê³µë°± í¬í•¨)"
        detail_level = "ì¶©ë¶„í•œ ì˜ˆì‹œì™€ ì„¤ëª…ì„ ê³ë“¤ì—¬ ìƒì„¸í•˜ê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "4min":
        target_chars = "ì•½ 2,000ì ì´ìƒ (ê³µë°± í¬í•¨)"
        detail_level = "í˜„ë¯¸ê²½ìœ¼ë¡œ ë“¤ì—¬ë‹¤ë³´ë“¯ ì•„ì£¼ ê¹Šì´ ìˆê³  ë””í…Œì¼í•˜ê²Œ ë¬˜ì‚¬í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
    else: # Intro / Epilogue (Fixed)
        target_chars = "ì•½ 400ë‹¨ì–´ (ì•½ 1,400ì)"
        detail_level = "ì‹œì²­ìë¥¼ ì‚¬ë¡œì¡ëŠ” ê°•ë ¥í•œ í›„í‚¹ê³¼ ì—¬ìš´ì„ ì£¼ëŠ” ë§ˆë¬´ë¦¬ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì•ˆë…• ì¸ì‚¬ëŠ” í•˜ì§€ ì•ŠëŠ”ë‹¤"

    user_guide_prompt = ""
    if custom_instruction:
        user_guide_prompt = f"""
    [User's Special Direction]
    The user has provided specific instructions for the tone/style. You MUST follow this:
    ğŸ‘‰ "{custom_instruction}"
        """

    prompt = f"""
    [Role]
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìœ íŠœë¸Œ ë‹¤íë©˜í„°ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.

    [Task]
    ì „ì²´ ëŒ€ë³¸ êµ¬ì¡° ì¤‘ ì˜¤ì§ **"{section_title}"** ë¶€ë¶„ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
      
    [Context (Overall Structure)]
    {full_structure}
    {user_guide_prompt}

    [Target Section]
    **{section_title}**

    [Length Constraints]
    - **ëª©í‘œ ë¶„ëŸ‰: {target_chars}** - **ì‘ì„± ì§€ì¹¨:** {detail_level}
      
    [Style Guidelines - ë§¤ìš° ì¤‘ìš”]
    1. 'ìŠµë‹ˆë‹¤' ì²´ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤íë©˜í„°ë¦¬ íŠ¹ìœ ì˜ ì§„ì§€í•˜ê³  ëª°ì…ê° ìˆëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    2. ì•ë’¤ ë¬¸ë§¥(ì´ì „ ì±•í„°, ë‹¤ìŒ ì±•í„°)ì„ ê³ ë ¤í•˜ë˜, ì´ íŒŒíŠ¸ì˜ ë‚´ìš©ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.
    3. (ì§€ë¬¸), (íš¨ê³¼ìŒ) ê°™ì€ ì—°ì¶œ ì§€ì‹œì–´ëŠ” ì œì™¸í•˜ê³  **ì˜¤ì§ ë‚˜ë ˆì´ì…˜ ëŒ€ì‚¬ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
    4. ì„œë‘ì— "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤" ê°™ì€ ì¡ë‹´ì„ í•˜ì§€ ë§ê³  ë°”ë¡œ ëŒ€ë³¸ ë‚´ìš©ì„ ì‹œì‘í•˜ì„¸ìš”.
    5. ì˜ë¬¸ ë³‘ê¸°(ê´„í˜¸)ëŠ” í•˜ì§€ ë§ˆì„¸ìš”. ê¹”ë”í•˜ê²Œ í•œê¸€ë§Œ.
    6. ì‰¼í‘œì™€ ì ‘ì†ì–´ ë“±ì„ ì‚¬ìš©í•˜ì—¬, ë¦¬ë“¬ì´ ìˆì§€ë§Œ ë„ˆë¬´ ëŠê¸°ì§€ ì•ŠëŠ” íë¦„ì„ ë§Œë“¤ ê²ƒ.
    
    # [ìˆ˜ì •ë¨] íë¦„ ëŠê¹€ ë°©ì§€ í•µì‹¬ ì§€ì¹¨ --------------------------
    7. **[ê¸ˆì§€ì‚¬í•­]** ê¸€ì˜ ë§ˆì§€ë§‰ì— "ë‹¤ìŒ ì¥ì—ì„œëŠ”...", "ì´ì–´ì„œ...", "ì´ì œ ~ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤" ê°™ì€ **ì˜ˆê³ ì„± ë©˜íŠ¸ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    8. **[ê¸ˆì§€ì‚¬í•­]** "ì§€ê¸ˆê¹Œì§€ ~ë¥¼ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤" ê°™ì€ **ì¤‘ê°„ ì •ë¦¬ ë©˜íŠ¸ë„ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    9. ì´ í…ìŠ¤íŠ¸ë“¤ì€ ë‚˜ì¤‘ì— í•˜ë‚˜ë¡œ í•©ì³ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ **ê·¸ëƒ¥ ì„¤ëª…í•˜ë‹¤ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥(ë§ˆì¹¨í‘œ)ìœ¼ë¡œ ëë‚´ì‹­ì‹œì˜¤.** ë’·ë‚´ìš©ì€ ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë°›ìŠµë‹ˆë‹¤.
    10. ì±•í„° ë²ˆí˜¸ë‚˜ ì†Œì œëª©ì„ ë³¸ë¬¸ì— ë‹¤ì‹œ ì ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ë‚´ìš©ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
    ---------------------------------------------------------

    [Output]
    (ì§€ê¸ˆ ë°”ë¡œ {section_title}ì˜ ì›ê³ ë¥¼ ì‘ì„± ì‹œì‘í•˜ì„¸ìš”)
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(
                max_output_tokens=8192,
                temperature=0.75 
            )
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 3. ì´ë¯¸ì§€ ìƒì„± ê´€ë ¨ ë¡œì§
# ==========================================

def init_folders():
    for path in [IMAGE_OUTPUT_DIR, AUDIO_OUTPUT_DIR, VIDEO_OUTPUT_DIR]:
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)

def split_script_by_time(script, chars_per_chunk=100):
    temp_sentences = script.replace(".", ".|").replace("?", "?|").replace("!", "!|").split("|")
    chunks = []
    current_chunk = ""
    for sentence in temp_sentences:
        sentence = sentence.strip()
        if not sentence: continue
        if len(current_chunk) + len(sentence) < chars_per_chunk:
            current_chunk += " " + sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def parse_numbered_script(script):
    """
    ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ì„ íŒŒì‹±í•˜ì—¬ ì”¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    ì¤„ë°”ê¿ˆì„ ì œê±°í•˜ê³  ë¬¸ì¥ì„ ì¡°í™”ë¡­ê²Œ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    import re

    scenes = []
    lines = script.strip().split('\n')
    current_scene_lines = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # ìƒˆë¡œìš´ ì”¬ ì‹œì‘ì¸ì§€ í™•ì¸ (ìˆ«ì + ì ìœ¼ë¡œ ì‹œì‘)
        match = re.match(r'^(\d+)\.(.*)$', line)
        if match:
            # ì´ì „ ì”¬ì´ ìˆìœ¼ë©´ ì €ì¥
            if current_scene_lines:
                scene_text = ' '.join(current_scene_lines)
                # ì—°ì† ê³µë°± ì œê±°
                scene_text = re.sub(r'\s+', ' ', scene_text).strip()
                if scene_text:
                    scenes.append(scene_text)

            # ìƒˆ ì”¬ ì‹œì‘ (ë²ˆí˜¸ ë’¤ì˜ ë‚´ìš©)
            rest = match.group(2).strip()
            current_scene_lines = [rest] if rest else []
        else:
            # í˜„ì¬ ì”¬ì— ë¼ì¸ ì¶”ê°€
            current_scene_lines.append(line)

    # ë§ˆì§€ë§‰ ì”¬ ì €ì¥
    if current_scene_lines:
        scene_text = ' '.join(current_scene_lines)
        scene_text = re.sub(r'\s+', ' ', scene_text).strip()
        if scene_text:
            scenes.append(scene_text)

    return scenes

def make_filename(scene_num, text_chunk):
    clean_line = text_chunk.replace("\n", " ").strip()
    clean_line = re.sub(r'[\\/:*?"<>|]', "", clean_line)
    words = clean_line.split()
    
    if len(words) <= 6:
        summary = " ".join(words)
    else:
        start_part = " ".join(words[:3])
        end_part = " ".join(words[-3:])
        summary = f"{start_part}...{end_part}"
    
    filename = f"S{scene_num:03d}_{summary}.png"
    return filename

# ==========================================
# [ìˆ˜ì •ë¨] í•¨ìˆ˜: í”„ë¡¬í”„íŠ¸ ìƒì„± (ì»¨ì…‰ ê¸°ë°˜ í†µí•© ë²„ì „)
# ==========================================
def generate_prompt(api_key, index, text_chunk, style_instruction, video_title, target_language="Korean"):
    """[ìˆ˜ì •ë¨] Gems ê³µì‹ + í…ìŠ¤íŠ¸ í†µí•© + ë””í…Œì¼ ê°•í™” ë²„ì „"""
    scene_num = index + 1
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_TEXT_MODEL_NAME}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}

    # 1. ì–¸ì–´ ì„¤ì •
    if target_language == "Korean":
        lang_guide = "í™”ë©´ ì† í•µì‹¬ í‚¤ì›Œë“œëŠ” ë¬´ì¡°ê±´ 'í•œê¸€(Korean)'ë¡œ í‘œê¸°í•˜ì‹­ì‹œì˜¤."
    elif target_language == "English":
        lang_guide = "í™”ë©´ ì† í•µì‹¬ í‚¤ì›Œë“œëŠ” ë¬´ì¡°ê±´ 'ì˜ì–´(English)'ë¡œ í‘œê¸°í•˜ì‹­ì‹œì˜¤."
    elif target_language == "Japanese":
        lang_guide = "í™”ë©´ ì† í•µì‹¬ í‚¤ì›Œë“œëŠ” ë¬´ì¡°ê±´ 'ì¼ë³¸ì–´(Japanese)'ë¡œ í‘œê¸°í•˜ì‹­ì‹œì˜¤."
    else:
        lang_guide = f"í™”ë©´ ì† í•µì‹¬ í‚¤ì›Œë“œëŠ” ë¬´ì¡°ê±´ '{target_language}'ë¡œ í‘œê¸°í•˜ì‹­ì‹œì˜¤."

    # 2. [ì¤‘ìš”] Gems ìŠ¤íƒ€ì¼ ê°•ì œ ê³ ì •ìš© Suffix (ì˜ì–´) - ìŠ¤í‹±ë§¨ ì •ì²´ì„± + í•˜ì–€ ëª¸/íŒ”ë‹¤ë¦¬ + ì–¼êµ´ ëª…í™•íˆ
    style_suffix = ", The style is 2D animation featuring a white circle-faced stickman with a white body and white limbs, rendered with simple lines and flat vivid color planes. **Face must be clearly visible.**"

    # 3. í”„ë¡¬í”„íŠ¸ ì‘ì„± ì§€ì¹¨ (Gems ê³µì‹ + í…ìŠ¤íŠ¸ í†µí•© + ë””í…Œì¼ ê°•í™”)
    full_instruction = f"""
[Role]
You are a '2D Stickman Animation Prompt Director'.

[Video Title]
"{video_title}"

[Style Guide - MUST FOLLOW]
{style_instruction}

[CRITICAL RULE - POSE & FACE DETAILS]
1. **If the character is sitting:** Do NOT just say "sitting". Describe the limbs. (e.g., "Sitting with knees bent", "Legs stretched out on the ruins", "Arms resting on knees").
2. **If the character is looking down:** Do NOT hide the face. Use terms like "Head tilted down but face fully visible to camera", "Chin tucked but expression clear".
3. **Camera:** For emotional scenes (despair, sitting), use **"Medium Shot"** or **"Close-up"** instead of Wide Shot to show the facial expression clearly.

[Prompt Structure Formula]
Write the prompt in **Korean** in this order:

1. **[Camera Angle & Shot]**: ê°ì •ì ì¸ ì¥ë©´(ì ˆë§, ì•‰ì•„ìˆëŠ” í¬ì¦ˆ)ì—ì„œëŠ” "ë¯¸ë””ì—„ ìƒ·" ë˜ëŠ” "í´ë¡œì¦ˆì—…" ì‚¬ìš©
   (ì˜ˆ: ë¡œìš° ì•µê¸€ ë¯¸ë””ì—„ ìƒ·, í´ë¡œì¦ˆì—…, ë¯¸ë””ì—„ ìƒ·)

2. **[Character & Costume]**: "í•˜ì–€ ì›í˜• ì–¼êµ´ê³¼ í•˜ì–€ íŒ”ë‹¤ë¦¬ì˜ ìŠ¤í‹±ë§¨" + ì˜ìƒ. **í‘œì •ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬ (ì˜ˆ: ëˆˆë¬¼, í…… ë¹ˆ ëˆˆ, ì°Œí‘¸ë¦° ëˆˆì¹)**
   (ì˜ˆ: "í•˜ì–€ ëª¸ê³¼ í•˜ì–€ íŒ”ë‹¤ë¦¬ë¥¼ ê°€ì§„ ìŠ¤í‹±ë§¨ì´ ë‚¡ì€ íšŒìƒ‰ ê°€ë””ê±´ì„ ì…ê³  ìˆë‹¤. ëˆˆë¬¼ì´ íë¥´ëŠ” ì ˆë§ì ì¸ í‘œì •.")

3. **[Pose Detail]**: **íŒ”ê³¼ ë‹¤ë¦¬ê°€ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë””ì— ìœ„ì¹˜í•´ ìˆëŠ”ì§€ ë¬˜ì‚¬**
   (ì˜ˆ: "ì–‘ì†ì„ ê¹ì§€ ë¼ê³ ", "ì–´ê¹¨ê°€ ì¶• ì²˜ì ¸ ìˆë‹¤", "ë¬´ë¦ì„ ê°€ìŠ´ ìª½ìœ¼ë¡œ ë‹¹ê²¨ ì•‰ì•„ ìˆë‹¤", "íŒ”ì„ ë¬´ë¦ ìœ„ì— í˜ì—†ì´ ê±¸ì³ ìˆë‹¤")

4. **[Background & Lighting]**: êµ¬ì²´ì ì¸ ìƒ‰ìƒê³¼ ì¡°ëª… ì´ë¦„ìœ¼ë¡œ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬
   (ì˜ˆ: "Golden Amber ì¡°ëª…ì´ ë¹„ì¶”ëŠ” ê³ ê¸‰ ì‚¬ë¬´ì‹¤", "Neon Pinkì™€ Cold Blueê°€ ì–´ìš°ëŸ¬ì§„ ë„ì‹œ ì•¼ê²½")

5. **[Text Object Integration]**: {lang_guide}
   ëŒ€ë³¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 2-3ê°œë¥¼ ì¶”ì¶œí•˜ì—¬ ë„¤ì˜¨ì‚¬ì¸, í™€ë¡œê·¸ë¨, ê·¸ë˜í”¼í‹° ë“±ìœ¼ë¡œ ë°°ì¹˜

[Output Constraints]
- ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥ (ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€)
- ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ì‘ì„±
- ìµœì†Œ 5ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ë¬˜ì‚¬
- ê³ ê°œë¥¼ ìˆ™ì—¬ë„ ì–¼êµ´ì´ ì¹´ë©”ë¼ì— ë³´ì´ê²Œ ë¬˜ì‚¬

[Script Segment]
"{text_chunk}"

[Output]
Write the prompt now:
"""

    payload = {
        "contents": [{"parts": [{"text": full_instruction}]}]
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            try:
                # ìƒì„±ëœ í•œê¸€ í”„ë¡¬í”„íŠ¸ + ìŠ¤íƒ€ì¼ ê³ ì •ìš© ì˜ì–´ Suffix ê²°í•©
                generated_text = response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
                # ë§ˆì¹¨í‘œ ì •ë¦¬ í›„ Suffix ë¶™ì´ê¸°
                generated_text = generated_text.rstrip('.')
                final_prompt = f"{generated_text}{style_suffix}"
            except:
                final_prompt = text_chunk
            return (scene_num, final_prompt)
        elif response.status_code == 429:
            time.sleep(2)
            return (scene_num, f"ì¼ëŸ¬ìŠ¤íŠ¸ ë¬˜ì‚¬: {text_chunk}")
        else:
            return (scene_num, f"Error generating prompt: {response.status_code}")
    except Exception as e:
        return (scene_num, f"Error: {e}")

# ==========================================
# [ìˆ˜ì •ë¨] generate_image: API ì œí•œ(429) ì™„ë²½ ëŒ€ì‘ + ì¬ì‹œë„ ê°•í™”
# ==========================================
def generate_image(client, prompt, filename, output_dir, selected_model_name):
    full_path = os.path.join(output_dir, filename)
    
    # [ìˆ˜ì • 1] ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 10íšŒë¡œ ëŠ˜ë ¤ì„œ ì ˆëŒ€ í¬ê¸°í•˜ì§€ ì•Šê²Œ í•¨
    max_retries = 10
    
    # [ìˆ˜ì • 2] ì•ˆì „ í•„í„° (ê¸°ì¡´ ìœ ì§€)
    safety_settings = [
        types.SafetySetting(
            category="HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HARASSMENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HATE_SPEECH",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold="BLOCK_ONLY_HIGH"
        ),
    ]

    for attempt in range(1, max_retries + 1):
        try:
            response = client.models.generate_content(
                model=selected_model_name,
                contents=[prompt],
                config=types.GenerateContentConfig(
                    image_config=types.ImageConfig(aspect_ratio="16:9"),
                    safety_settings=safety_settings 
                )
            )
            
            if response.parts:
                for part in response.parts:
                    if part.inline_data:
                        img_data = part.inline_data.data
                        image = Image.open(BytesIO(img_data))
                        image.save(full_path)
                        return full_path
            
            # ì‘ë‹µì€ ì™”ìœ¼ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° (í•„í„°ë§ ë“±)
            print(f"âš ï¸ [ì‹œë„ {attempt}/{max_retries}] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ. ì¬ì‹œë„... ({filename})")
            time.sleep(2)
            
        except Exception as e:
            error_msg = str(e)
            # [ìƒì„¸ ì—ëŸ¬ ë¡œê¹… ì¶”ê°€]
            print(f"=" * 50)
            print(f"ğŸ”´ [ì—ëŸ¬ ìƒì„¸] {filename}")
            print(f"   ì‹œë„: {attempt}/{max_retries}")
            print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            print(f"   ì—ëŸ¬ ë©”ì‹œì§€: {error_msg}")
            print(f"=" * 50)

            # [í•µì‹¬ ìˆ˜ì •] 429 (Too Many Requests) ë˜ëŠ” 429 Resource Exhausted ì—ëŸ¬ ë°œìƒ ì‹œ
            if "429" in error_msg or "ResourceExhausted" in error_msg:
                wait_time = 30  # 30ì´ˆ ë™ì•ˆ ë©ˆì·„ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„ (ë¶„ë‹¹ ì œí•œ ì´ˆê¸°í™” ëŒ€ê¸°)
                print(f"ğŸ›‘ [API ì œí•œ ê°ì§€] {filename} - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                time.sleep(wait_time)
            elif "400" in error_msg or "InvalidArgument" in error_msg or "SAFETY" in error_msg.upper():
                # 400 ì—ëŸ¬ ë˜ëŠ” ì•ˆì „ í•„í„° - ìƒì„¸ ë¡œê¹…
                print(f"ğŸš« [ì»¨í…ì¸  ê±°ë¶€] {filename} - í”„ë¡¬í”„íŠ¸ê°€ ê±°ë¶€ë¨. 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(5)
            else:
                # ì¼ë°˜ ì—ëŸ¬ëŠ” 5ì´ˆ ëŒ€ê¸°
                print(f"âš ï¸ [ê¸°íƒ€ ì—ëŸ¬] {filename} - 5ì´ˆ ëŒ€ê¸°")
                time.sleep(5)
            
    # [ìµœì¢… ì‹¤íŒ¨]
    print(f"âŒ [ìµœì¢… ì‹¤íŒ¨] {filename} - ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")
    return None

def create_zip_buffer(source_dir):
    buffer = BytesIO()
    with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                zip_file.write(file_path, os.path.basename(file_path))
    buffer.seek(0)
    return buffer

# ==========================================
# [í•¨ìˆ˜] 4. Supertone TTS ë° ì˜¤ë””ì˜¤ í›„ì²˜ë¦¬ (Noise Cut - Micro Fade)
# ==========================================
def check_connection_and_get_voices(api_key, base_url):
    """ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ëª©ì†Œë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/voices"
    headers = {"x-sup-api-key": api_key}
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            voices = []
            if isinstance(data, dict) and "items" in data:
                voices = data["items"]
            elif isinstance(data, list):
                voices = data
            else:
                return False, [], f"ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. (items í‚¤ ì—†ìŒ: {list(data.keys())})"
            
            return True, voices, "âœ… ì—°ê²° ì„±ê³µ!"
            
        elif response.status_code == 401:
            return False, [], "âŒ API Keyê°€ í‹€ë ¸ìŠµë‹ˆë‹¤ (401)"
        elif response.status_code == 404:
            return False, [], f"âŒ ì£¼ì†Œ(URL) ì˜¤ë¥˜ (404). {base_url} ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        else:
            return False, [], f"âŒ ì„œë²„ ì˜¤ë¥˜ ({response.status_code}): {response.text}"
            
    except Exception as e:
        return False, [], f"âŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {str(e)}"

def generate_supertone_tts(api_key, voice_id, text, scene_num, base_url, speed=1.0, pitch=0):
    """Supertone APIë¥¼ ì‚¬ìš©í•´ TTS ì˜¤ë””ì˜¤ ìƒì„± ë° ì €ì¥"""
    
    # 1. í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì -> í•œê¸€)
    normalized_text = normalize_text_for_tts(text)

    # 2. ë§ˆì¹¨í‘œê°€ ìˆë“  ì—†ë“  ë¬´ì¡°ê±´ ë§ˆì¹¨í‘œ í•˜ë‚˜ ë” ì¶”ê°€í•˜ì—¬ í™•ì‹¤í•œ ëë§ºìŒ ìœ ë„
    normalized_text = normalized_text.strip() + "."

    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/text-to-speech/{voice_id}"
    
    headers = {
        "x-sup-api-key": api_key,
        "Content-Type": "application/json"
    }
    
    safe_text = normalized_text[:500] 
    
    payload = {
        "text": safe_text,
        "language": "ko",
        "model": "sona_speech_1",
        "voice_settings": {
            "speed": float(speed),
            "pitch_shift": int(pitch),
            "pitch_variance": 1
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, stream=True)
        
        if response.status_code == 200:
            filename = f"S{scene_num:03d}_audio.wav"
            full_path = os.path.join(AUDIO_OUTPUT_DIR, filename)
            
            # íŒŒì¼ ì €ì¥
            with open(full_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            
            # [KEY FIX] ë§ˆì´í¬ë¡œ í˜ì´ë“œ (Micro-Fade): ë 30msë§Œ ì‚´ì§ ì¤„ì—¬ì„œ íŠ€ëŠ” ì†Œë¦¬ ì œê±°
            try:
                saved_audio = AudioSegment.from_wav(full_path)
                
                if len(saved_audio) > 100:
                    # 0.03ì´ˆ(30ms)ë§Œ í˜ì´ë“œ ì•„ì›ƒ -> ë§ëì€ ì‚´ë¦¬ê³ , ê¸°ê³„ìŒ 'í‹±' ì†Œë¦¬ë§Œ ì œê±°
                    saved_audio = saved_audio.fade_out(30)
                    saved_audio.export(full_path, format="wav")
            except Exception as e:
                print(f"Audio tail fix error: {e}")

            return full_path
        elif response.status_code == 404:
            return "VOICE_NOT_FOUND"
        else:
            return f"Error ({response.status_code}): {response.text}"
            
    except Exception as e:
        return f"System Error: {e}"

def smart_shorten_silence(file_path, max_allowed_silence_ms=300, min_silence_len=100, silence_thresh=-40):
    try:
        audio = AudioSegment.from_wav(file_path)
        silence_ranges = detect_silence(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh
        )

        if not silence_ranges:
            return True, "ë¬´ìŒ êµ¬ê°„ ì—†ìŒ"

        output_audio = AudioSegment.empty()
        last_pos = 0

        for start, end in silence_ranges:
            output_audio += audio[last_pos:start]
            silence_duration = end - start
            if silence_duration > max_allowed_silence_ms:
                output_audio += AudioSegment.silent(duration=max_allowed_silence_ms)
            else:
                output_audio += audio[start:end]
            last_pos = end

        output_audio += audio[last_pos:]
        output_audio.export(file_path, format="wav")
        return True, "ì„±ê³µ"

    except Exception as e:
        return False, str(e)

def process_single_tts_task(api_key, voice_id, text, scene_num, base_url, speed, pitch, apply_silence_trim):
    audio_res = generate_supertone_tts(
        api_key, voice_id, text, scene_num, base_url, speed, pitch
    )
    if "Error" not in str(audio_res) and "VOICE_NOT_FOUND" not in str(audio_res):
        if apply_silence_trim:
            smart_shorten_silence(audio_res, max_allowed_silence_ms=300)
    return audio_res

# ==========================================
# [í•¨ìˆ˜] 5. ë¹„ë””ì˜¤ ìƒì„± (MoviePy - ê³ í™”ì§ˆ ì„¤ì •)
# ==========================================
def create_video_with_zoom(image_path, audio_path, output_dir, scene_num, is_zoom_in=True):
    """
    ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ í•©ì³ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì¤Œ íš¨ê³¼ ë¹„ë””ì˜¤ ìƒì„±.
    [ê³ í™”ì§ˆ ì„¤ì • ì ìš© ì™„ë£Œ]
    """
    try:
        output_filename = f"S{scene_num:03d}_video_zoom.mp4"
        output_path = os.path.join(output_dir, output_filename)
        
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        
        original_pil = Image.open(image_path).convert("RGB")
        W, H = original_pil.size
        
        if W % 2 != 0: W -= 1
        if H % 2 != 0: H -= 1
        if original_pil.size != (W, H):
            original_pil = original_pil.resize((W, H), Image.LANCZOS)

        max_crop_ratio = 0.85 
        
        def effect(get_frame, t):
            progress = t / duration
            if is_zoom_in:
                current_ratio = 1.0 - (1.0 - max_crop_ratio) * progress
            else:
                current_ratio = max_crop_ratio + (1.0 - max_crop_ratio) * progress
            
            roi_w = W * current_ratio
            roi_h = H * current_ratio
            
            x0 = (W - roi_w) / 2
            y0 = (H - roi_h) / 2
            x1 = x0 + roi_w
            y1 = y0 + roi_h
            
            transformed_img = original_pil.transform(
                (W, H), 
                Image.EXTENT, 
                (x0, y0, x1, y1), 
                Image.BICUBIC 
            )
            return np.array(transformed_img)

        video = ImageClip(np.array(original_pil)).set_duration(duration).set_fps(30)
        video = video.fl(effect)
        video = video.set_audio(audio_clip)
        
        # [KEY FIX] ê³ í™”ì§ˆ ë Œë”ë§ ì„¤ì • (ë¹„íŠ¸ë ˆì´íŠ¸ 8000k, ì˜¤ë””ì˜¤ 192k, preset=slow)
        video.write_videofile(
            output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",        # ì˜ìƒ í™”ì§ˆ ëŒ€í­ í–¥ìƒ
            audio_bitrate="192k",   # ì˜¤ë””ì˜¤ ìŒì§ˆ í–¥ìƒ
            preset="slow",          # ì¸ì½”ë”© í’ˆì§ˆ í–¥ìƒ (ì†ë„ëŠ” ì¡°ê¸ˆ ëŠë ¤ì§)
            logger=None
        )
        
        return output_path
        
    except Exception as e:
        return f"Error: {e}"

def process_single_video_task(item, output_dir, is_zoom_in):
    if item.get('audio_path') and os.path.exists(item['audio_path']):
        return create_video_with_zoom(
            item['path'], 
            item['audio_path'], 
            output_dir, 
            item['scene'], 
            is_zoom_in=is_zoom_in
        )
    return None

def merge_all_videos(video_paths, output_dir):
    try:
        clips = []
        for path in video_paths:
            if path and os.path.exists(path):
                clips.append(VideoFileClip(path))
        
        if not clips:
            return "No clips to merge"

        final_clip = concatenate_videoclips(clips, method="compose")
        final_output_path = os.path.join(output_dir, "FINAL_FULL_VIDEO.mp4")
        
        # [KEY FIX] ë³‘í•© ì‹œì—ë„ ê³ í™”ì§ˆ ìœ ì§€
        final_clip.write_videofile(
            final_output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",
            audio_bitrate="192k",
            preset="slow",
            logger=None
        )
        return final_output_path
    except Exception as e:
        return f"Merge Error: {e}"

# ==========================================
# [UI] ì‚¬ì´ë“œë°” (ìë™ ë¡œê·¸ì¸ + ì¥ë¥´ ì„ íƒ ì ìš©)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")

    # 1. Google API Key ì„¤ì • (ë©€í‹° API ì§€ì›)
    st.subheader("ğŸ”‘ API í‚¤ ì„¤ì •")

    # API í‚¤ ê°œìˆ˜ ì„ íƒ ë“œë¡­ë°•ìŠ¤
    num_api_keys = st.selectbox(
        "API í‚¤ ê°œìˆ˜",
        options=[1, 2, 3, 4],
        index=0,
        help="ì—¬ëŸ¬ API í‚¤ë¥¼ ì‚¬ìš©í•˜ë©´ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë” ë¹ ë¥´ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í‚¤ë‹¹ ë¶„ë‹¹ 20ê°œ)"
    )

    # API í‚¤ ì…ë ¥ í•„ë“œë“¤
    api_keys = []

    # secrets.tomlì—ì„œ ìë™ ë¡œë“œ ì‹œë„
    for i in range(num_api_keys):
        secret_key = f"google_api_key_{i+1}" if i > 0 else "google_api_key"

        if "general" in st.secrets and secret_key in st.secrets["general"]:
            key = st.secrets["general"][secret_key]
            st.success(f"ğŸ”‘ API Key {i+1} ë¡œë“œë¨")
            api_keys.append(key)
        else:
            key = st.text_input(
                f"ğŸ”‘ Google API Key {i+1}" if num_api_keys > 1 else "ğŸ”‘ Google API Key",
                type="password",
                key=f"api_key_{i}",
                help=f"API í‚¤ {i+1}ë²ˆì„ ì…ë ¥í•˜ì„¸ìš”."
            )
            if key:
                api_keys.append(key)

    # í˜¸í™˜ì„±ì„ ìœ„í•´ ì²« ë²ˆì§¸ í‚¤ë¥¼ api_keyë¡œë„ ì €ì¥
    api_key = api_keys[0] if api_keys else ""

    if num_api_keys > 1 and len(api_keys) == num_api_keys:
        st.info(f"âœ… {num_api_keys}ê°œ API í‚¤ ì„¤ì •ë¨ â†’ ë¶„ë‹¹ ìµœëŒ€ {num_api_keys * 20}ê°œ ìƒì„± ê°€ëŠ¥")

    st.markdown("---")
    
    st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ")
    model_choice = st.radio("ì‚¬ìš©í•  AI ëª¨ë¸:", ("Premium (Gemini 3 Pro)", "Fast (Gemini-2.5-pro)"), index=0)
    
    if "Gemini 3 Pro" in model_choice:
        SELECTED_IMAGE_MODEL = "gemini-3-pro-image-preview" 
    else:
        SELECTED_IMAGE_MODEL = "gemini-2.5-pro"

    st.info(f"âœ… ì„ íƒ ëª¨ë¸: `{SELECTED_IMAGE_MODEL}`")
    
    st.markdown("---")
    st.subheader("ğŸ“ ëŒ€ë³¸ ë¶„í•  ì•ˆë‚´")
    st.info("ëŒ€ë³¸ì„ ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• í•´ì„œ ì…ë ¥í•˜ì„¸ìš”. ê° ë²ˆí˜¸ê°€ í•˜ë‚˜ì˜ ì”¬ì´ ë©ë‹ˆë‹¤.") 
    
    st.markdown("---")

    # [NEW] ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ì–¸ì–´ ì„ íƒ
    st.subheader("ğŸŒ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì–¸ì–´")
    target_language = st.selectbox(
        "ì´ë¯¸ì§€ ì†ì— ë“¤ì–´ê°ˆ ê¸€ì ì–¸ì–´:",
        ("Korean", "English", "Japanese"),
        index=0,
        help="ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ì—°ì¶œë  ë•Œ ì–´ë–¤ ì–¸ì–´ë¡œ ì ì„ì§€ ì„ íƒí•©ë‹ˆë‹¤."
    )

    st.markdown("---")

    # ==========================================
    # [NEW] ì»¨ì…‰ë³„ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ
    # ==========================================
    # [ìˆ˜ì •ë¨] Gems ìŠ¤íƒ€ì¼ + í…ìŠ¤íŠ¸ í†µí•© ë²„ì „
    STYLE_PRESETS = {
        "ê²½ì œí•™": """
[Core Identity - ì ˆëŒ€ ê·œì¹™]
- Character: MUST be a "White circle-faced stickman"
- **Body & Limbs: ëª¸, íŒ”, ë‹¤ë¦¬ ì „ì²´ê°€ ë°˜ë“œì‹œ ìˆœìˆ˜í•œ í•˜ì–€ìƒ‰ì´ì–´ì•¼ í•¨. ê²€ì€ìƒ‰ ìŠ¤í‹±ë§¨ ê¸ˆì§€.**
- Face: ì‹¬í”Œí•œ í•˜ì–€ ì›í˜• ì–¼êµ´ì— 2D ìŠ¤íƒ€ì¼ í‘œì •
- Style: 2D ì• ë‹ˆë©”ì´ì…˜, ì‹¬í”Œí•œ ë¼ì¸, ì„ ëª…í•œ í”Œë« ì»¬ëŸ¬

[Costume & Role Rule - ì˜ìƒ ê·œì¹™]
- ì ˆëŒ€ ì¼ë°˜ì ì¸ ì‚¬ëŒìœ¼ë¡œ ê·¸ë¦¬ì§€ ë§ ê²ƒ. í•˜ì–€ ëª¸ ìœ„ì— ì—­í• ì— ë§ëŠ” "ì½”ìŠ¤íŠ¬" ì…íˆê¸°
- CEO: ë„¤ì´ë¹„ ì •ì¥, ë¹¨ê°„ ë„¥íƒ€ì´ / ê°€ë‚œí•œ ì‚¬ëŒ: ë‚¡ì€ íšŒìƒ‰ ê°€ë””ê±´
- ì§ì¥ì¸: ì™€ì´ì…”ì¸ , ë¸”ë¼ìš°ìŠ¤ / ë¶€ì: ê¸ˆìƒ‰ ì•¡ì„¸ì„œë¦¬
- ìì˜ì—…ì: ì»¬ëŸ¬í’€í•œ ì•ì¹˜ë§ˆ / í•™ìƒ: êµë³µ

[Background & Lighting - ë°°ê²½/ì¡°ëª…]
- êµ¬ì²´ì ì¸ ì¡°ëª… ì´ë¦„ ì‚¬ìš©: "Golden Amber", "Neon Pink", "Cold Blue", "Dramatic Spotlight"
- ë°°ê²½ì€ "Vivid architectural atmosphere" (ë„¤ì˜¨ ë„ì‹œ, ë¬´ë„ˆì§€ëŠ” íí—ˆ, ë°ì€ ì‚¬ë¬´ì‹¤ ë“±)

[Text Integration - í…ìŠ¤íŠ¸ í†µí•© (í•µì‹¬)]
- ëŒ€ë³¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í•œêµ­ì–´ í‚¤ì›Œë“œ 2-3ê°œë¥¼ ì¥ë©´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
- ì˜ˆì‹œ: ê±´ë¬¼ì˜ ë„¤ì˜¨ì‚¬ì¸, ê³µì¤‘ì— ë– ìˆëŠ” í™€ë¡œê·¸ë¨, ë²½ì— ì“°ì¸ ê¸€ì”¨, ê°„íŒ
- í…ìŠ¤íŠ¸ëŠ” ì½ê¸° ì‰½ê³  ë°°ê²½ê³¼ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ë¡œ
""",
        "ì—­ì‚¬": """
[Core Identity - ì ˆëŒ€ ê·œì¹™]
- Character: MUST be a "White circle-faced stickman"
- **Body & Limbs: ëª¸, íŒ”, ë‹¤ë¦¬ ì „ì²´ê°€ ë°˜ë“œì‹œ ìˆœìˆ˜í•œ í•˜ì–€ìƒ‰ì´ì–´ì•¼ í•¨. ê²€ì€ìƒ‰ ìŠ¤í‹±ë§¨ ê¸ˆì§€.**
- Face: ì‹¬í”Œí•œ í•˜ì–€ ì›í˜• ì–¼êµ´ì— 2D ìŠ¤íƒ€ì¼ í‘œì •
- Style: 2D ì• ë‹ˆë©”ì´ì…˜, ì‹¬í”Œí•œ ë¼ì¸, ì„ ëª…í•œ í”Œë« ì»¬ëŸ¬

[Costume & Role Rule - ì—­ì‚¬ ì˜ìƒ]
- ì ˆëŒ€ ì¼ë°˜ì ì¸ ì‚¬ëŒìœ¼ë¡œ ê·¸ë¦¬ì§€ ë§ ê²ƒ. í•˜ì–€ ëª¸ ìœ„ì— ì‹œëŒ€ì— ë§ëŠ” "ì½”ìŠ¤íŠ¬" ì…íˆê¸°
- ì¡°ì„ : í•œë³µ, ê°“ / ë¡œë§ˆ: í† ê°€, ê°‘ì˜· / ì¤‘ì„¸: ê°‘ì˜·, ì™•ê´€, ë“œë ˆìŠ¤
- ì™•ì¡±: ê¸ˆìƒ‰ ì¥ì‹, ì™•ê´€ / ë†ë¯¼: ì†Œë°•í•œ ì˜· / ì „ì‚¬: ë¬´ê¸°ì™€ ê°‘ì˜·

[Background & Lighting - ë°°ê²½/ì¡°ëª…]
- êµ¬ì²´ì ì¸ ì¡°ëª… ì´ë¦„ ì‚¬ìš©: "Candlelight Warm", "Royal Gold", "Battle Red", "Dawn Light"
- ë°°ê²½ì€ ì‹œëŒ€ì  ë¶„ìœ„ê¸° (ê¶ê¶, ì „ìŸí„°, ê³ ëŒ€ ë„ì‹œ, ì‹œê³¨ ë§ˆì„ ë“±)

[Text Integration - í…ìŠ¤íŠ¸ í†µí•© (í•µì‹¬)]
- ëŒ€ë³¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í•œêµ­ì–´ í‚¤ì›Œë“œ 2-3ê°œë¥¼ ì¥ë©´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
- ì˜ˆì‹œ: ê¹ƒë°œì— ì“°ì¸ ê¸€ì, ë‘ë£¨ë§ˆë¦¬ ë¬¸ì„œ, ì„ë¹„ì— ìƒˆê²¨ì§„ ê¸€, í˜„ìˆ˜ë§‰
- í…ìŠ¤íŠ¸ëŠ” ì‹œëŒ€ì— ë§ëŠ” ì„œì²´ ìŠ¤íƒ€ì¼ë¡œ
""",
        "ê³¼í•™": """
[Core Identity - ì ˆëŒ€ ê·œì¹™]
- Character: MUST be a "White circle-faced stickman"
- **Body & Limbs: ëª¸, íŒ”, ë‹¤ë¦¬ ì „ì²´ê°€ ë°˜ë“œì‹œ ìˆœìˆ˜í•œ í•˜ì–€ìƒ‰ì´ì–´ì•¼ í•¨. ê²€ì€ìƒ‰ ìŠ¤í‹±ë§¨ ê¸ˆì§€.**
- Face: ì‹¬í”Œí•œ í•˜ì–€ ì›í˜• ì–¼êµ´ì— 2D ìŠ¤íƒ€ì¼ í‘œì •
- Style: 2D ì• ë‹ˆë©”ì´ì…˜, ì‹¬í”Œí•œ ë¼ì¸, ì„ ëª…í•œ í”Œë« ì»¬ëŸ¬

[Costume & Role Rule - ê³¼í•™ ì˜ìƒ]
- ì ˆëŒ€ ì¼ë°˜ì ì¸ ì‚¬ëŒìœ¼ë¡œ ê·¸ë¦¬ì§€ ë§ ê²ƒ. í•˜ì–€ ëª¸ ìœ„ì— ë¶„ì•¼ì— ë§ëŠ” "ì½”ìŠ¤íŠ¬" ì…íˆê¸°
- ê³¼í•™ì: í° ê°€ìš´, ë³´ì•ˆê²½ / ì˜ì‚¬: ìˆ˜ìˆ ë³µ, ì²­ì§„ê¸°
- ìš°ì£¼ë¹„í–‰ì‚¬: ìš°ì£¼ë³µ / ì—”ì§€ë‹ˆì–´: ì‘ì—…ë³µ, ì•ˆì „ëª¨
- ë¡œë´‡ê³µí•™ì: ê¸°ìˆ  ì¥ê°‘ / í”„ë¡œê·¸ë˜ë¨¸: ìºì£¼ì–¼ í›„ë“œ

[Background & Lighting - ë°°ê²½/ì¡°ëª…]
- êµ¬ì²´ì ì¸ ì¡°ëª… ì´ë¦„ ì‚¬ìš©: "Lab White", "Neon Cyber", "Space Purple", "Hologram Blue"
- ë°°ê²½ì€ ê³¼í•™ì  ë¶„ìœ„ê¸° (ì‹¤í—˜ì‹¤, ìš°ì£¼, ë°ì´í„°ì„¼í„°, ë¯¸ë˜ ë„ì‹œ ë“±)

[Text Integration - í…ìŠ¤íŠ¸ í†µí•© (í•µì‹¬)]
- ëŒ€ë³¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í•œêµ­ì–´ í‚¤ì›Œë“œ 2-3ê°œë¥¼ ì¥ë©´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
- ì˜ˆì‹œ: í™€ë¡œê·¸ë¨ ë””ìŠ¤í”Œë ˆì´, ëª¨ë‹ˆí„° í™”ë©´, ê³µì¤‘ì— ëœ¬ ë°ì´í„°, ì‹¤í—˜ ì¥ë¹„ ë¼ë²¨
- í…ìŠ¤íŠ¸ëŠ” ë””ì§€í„¸/ë¯¸ë˜ì  ìŠ¤íƒ€ì¼ë¡œ
""",
        "ì»¤ìŠ¤í…€ (ì§ì ‘ ì…ë ¥)": """
[Core Identity - ì ˆëŒ€ ê·œì¹™]
- Character: MUST be a "White circle-faced stickman"
- **Body & Limbs: ëª¸, íŒ”, ë‹¤ë¦¬ ì „ì²´ê°€ ë°˜ë“œì‹œ ìˆœìˆ˜í•œ í•˜ì–€ìƒ‰ì´ì–´ì•¼ í•¨. ê²€ì€ìƒ‰ ìŠ¤í‹±ë§¨ ê¸ˆì§€.**
- Face: ì‹¬í”Œí•œ í•˜ì–€ ì›í˜• ì–¼êµ´ì— 2D ìŠ¤íƒ€ì¼ í‘œì •
- Style: 2D ì• ë‹ˆë©”ì´ì…˜, ì‹¬í”Œí•œ ë¼ì¸, ì„ ëª…í•œ í”Œë« ì»¬ëŸ¬

[Costume & Role Rule - ì˜ìƒ ê·œì¹™]
- ì ˆëŒ€ ì¼ë°˜ì ì¸ ì‚¬ëŒìœ¼ë¡œ ê·¸ë¦¬ì§€ ë§ ê²ƒ. í•˜ì–€ ëª¸ ìœ„ì— ì—­í• ì— ë§ëŠ” "ì½”ìŠ¤íŠ¬" ì…íˆê¸°
- ê° ìºë¦­í„°ì˜ ì§ì—…/ì—­í• ì— ë§ëŠ” ì»¬ëŸ¬í’€í•˜ê³  íŠ¹ì§•ì ì¸ ì˜ìƒ

[Background & Lighting - ë°°ê²½/ì¡°ëª…]
- êµ¬ì²´ì ì¸ ì¡°ëª… ì´ë¦„ ì‚¬ìš©: "Golden Amber", "Neon Pink", "Cold Blue", "Dramatic Spotlight"
- ë°°ê²½ì€ "Vivid architectural atmosphere" (ìƒí™©ì— ë§ëŠ” ìƒìƒí•œ ë°°ê²½)

[Text Integration - í…ìŠ¤íŠ¸ í†µí•© (í•µì‹¬)]
- ëŒ€ë³¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í•œêµ­ì–´ í‚¤ì›Œë“œ 2-3ê°œë¥¼ ì¥ë©´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
- ì˜ˆì‹œ: ë„¤ì˜¨ì‚¬ì¸, ê°„íŒ, í™€ë¡œê·¸ë¨, ë²½ë©´ ê¸€ì”¨, ë°°ë„ˆ
- í…ìŠ¤íŠ¸ëŠ” ì½ê¸° ì‰½ê³  ë°°ê²½ê³¼ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ë¡œ
"""
    }

    st.subheader("ğŸ¨ ì»¨ì…‰ ì„ íƒ")

    # ì»¨ì…‰ ì„ íƒ ë“œë¡­ë°•ìŠ¤
    selected_style_version = st.selectbox(
        "ì»¨ì…‰ í”„ë¦¬ì…‹",
        list(STYLE_PRESETS.keys()),
        index=0,
        help="ì»¨ì…‰ë³„ë¡œ ìµœì í™”ëœ ìŠ¤íƒ€ì¼ì´ ì ìš©ë©ë‹ˆë‹¤."
    )

    # ì„ íƒëœ í”„ë¦¬ì…‹ ê°€ì ¸ì˜¤ê¸°
    default_style = STYLE_PRESETS[selected_style_version]

    style_instruction = st.text_area("AIì—ê²Œ ì§€ì‹œí•  ê·¸ë¦¼ ìŠ¤íƒ€ì¼", value=default_style.strip(), height=150)
    st.markdown("---")

    max_workers = st.slider("ì‘ì—… ì†ë„(ë³‘ë ¬ ìˆ˜)", 1, 10, 5)

    # [TTS ë¹„í™œì„±í™”] Supertone TTS ì„¤ì • ì œê±°ë¨ - ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹„í™œì„±í™”
    supertone_api_key = ""
    supertone_base_url = DEFAULT_SUPERTONE_URL
    selected_voice_id = ""
    tts_speed = 1.0
    tts_pitch = 0

# ==========================================
# [ìˆ˜ì •ëœ UI] ë©”ì¸ í™”ë©´: ì´ë¯¸ì§€ ìƒì„±
# ==========================================
st.divider()
st.title("ğŸ–¼ï¸ ì”¬ë³„ ì´ë¯¸ì§€ ìƒì„±")
st.caption(f"ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ì„ ë„£ìœ¼ë©´ ê° ì”¬ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. | ğŸ¨ Model: {SELECTED_IMAGE_MODEL}")

st.subheader("ğŸ“Œ ì „ì²´ ì˜ìƒ í…Œë§ˆ(ì œëª©) ì„¤ì •")
st.caption("ì´ë¯¸ì§€ ìƒì„± ì‹œ ì´ ì œëª©ì´ 'ì „ì²´ì ì¸ ë¶„ìœ„ê¸° ê¸°ì¤€'ì´ ë©ë‹ˆë‹¤.")

if 'video_title' not in st.session_state:
    st.session_state['video_title'] = ""
if 'title_candidates' not in st.session_state:
    st.session_state['title_candidates'] = []

col_title_input, col_title_btn = st.columns([4, 1])

# [ìˆ˜ì •ë¨] ë²„íŠ¼ ë¡œì§: ì œëª© ì…ë ¥ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ
with col_title_btn:
    st.write("")
    st.write("")
    if st.button("ğŸ’¡ ì œëª© 5ê°œ ì¶”ì²œ", help="ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.", use_container_width=True):
        current_user_title = st.session_state.get('video_title', "").strip()

        if not api_key:
            st.error("API Key í•„ìš”")
        elif not current_user_title:
            st.warning("âš ï¸ ë¨¼ì € 'ì£¼ì œ'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            client = genai.Client(api_key=api_key)
            with st.spinner("AIê°€ ìµœì ì˜ ì œëª©ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
                title_prompt = f"""
                [Role] You are a YouTube viral marketing expert.
                [Target Topic]
                "{current_user_title}"
                [Task]
                Generate 5 click-bait YouTube video titles based on the Target Topic above.
                ì‚¬ìš©ìê°€ ì…ë ¥í•œê±°ë‘ ìµœëŒ€í•œ ë¹„ìŠ·í•œ ì œëª©ìœ¼ë¡œ ì¶”ì²œ, 'ëª°ë½'ì´ ë“¤ì–´ê°„ ê²½ìš° ë§¨ ë’¤ì— ëª°ë½ìœ¼ë¡œ ëë‚˜ê²Œ í•œë‹¤.

                [Output Format]
                - Output ONLY the list of 5 titles.
                - No numbering (1., 2.), just 5 lines of text.
                - Language: Korean
                """

                try:
                    resp = client.models.generate_content(
                        model=GEMINI_TEXT_MODEL_NAME,
                        contents=title_prompt
                    )
                    candidates = [line.strip() for line in resp.text.split('\n') if line.strip()]
                    clean_candidates = []
                    import re
                    for c in candidates:
                        clean = re.sub(r'^\d+\.\s*', '', c).replace('*', '').replace('"', '').strip()
                        if clean: clean_candidates.append(clean)

                    st.session_state['title_candidates'] = clean_candidates[:5]
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

with col_title_input:
    st.text_input(
        "ì˜ìƒ ì œëª© (ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìš°ì¸¡ ë²„íŠ¼ìœ¼ë¡œ ì¶”ì²œë°›ìœ¼ì„¸ìš”)",
        key="video_title", 
        placeholder="ì œëª© í˜¹ì€ ë§Œë“¤ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¶€ìë“¤ì˜ ìŠµê´€)"
    )

if st.session_state['title_candidates']:
    st.info("ğŸ‘‡ AIê°€ ì¶”ì²œí•œ ì œëª©ì…ë‹ˆë‹¤. í´ë¦­í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤.")

    def apply_title(new_title):
        st.session_state['video_title'] = new_title
        st.session_state['title_candidates'] = [] 

    for idx, title in enumerate(st.session_state['title_candidates']):
        col_c1, col_c2 = st.columns([4, 1])
        with col_c1:
            st.markdown(f"**{idx+1}. {title}**")
        with col_c2:
            st.button(
                "âœ… ì„ íƒ", 
                key=f"sel_title_{idx}", 
                on_click=apply_title, 
                args=(title,), 
                use_container_width=True
            )
    
    if st.button("âŒ ëª©ë¡ ë‹«ê¸°"):
        st.session_state['title_candidates'] = []

if 'section_scripts' in st.session_state and st.session_state['section_scripts']:
    intro_text_acc = ""
    main_text_acc = ""
    for title_key, text in st.session_state['section_scripts'].items():
        if "Intro" in title_key or "ë„ì…ë¶€" in title_key:
            intro_text_acc += text + "\n\n"
        else:
            main_text_acc += text + "\n\n"
            
    st.write("ğŸ‘‡ **ìƒì„±ëœ ëŒ€ë³¸ ê°€ì ¸ì˜¤ê¸° (í´ë¦­ ì‹œ ì•„ë˜ ì…ë ¥ì°½ì— ì±„ì›Œì§‘ë‹ˆë‹¤)**")
    
    col_get1, col_get2 = st.columns(2)
    if "image_gen_input" not in st.session_state:
        st.session_state["image_gen_input"] = ""

    with col_get1:
        if st.button("ğŸ“¥ ì¸íŠ¸ë¡œ(Intro)ë§Œ ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = intro_text_acc.strip()
            st.rerun()
    with col_get2:
        if st.button("ğŸ“¥ ë³¸ë¡ (Chapters) + ê²°ë¡ (Epilogue) ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = main_text_acc.strip()
            st.rerun()

script_input = st.text_area(
    "ğŸ“œ ë²ˆí˜¸ë¡œ ë¶„í• ëœ ëŒ€ë³¸ ì…ë ¥ (1. 2. 3. í˜•íƒœ)",
    height=300,
    placeholder="""ì˜ˆì‹œ:
1.í•˜ì§€ë§Œ ì˜ì›í•  ê²ƒ ê°™ì•˜ë˜
ì´ ê±°ëŒ€í•œ ì œêµ­ì€ ì–´ëŠ ìˆœê°„ë¶€í„°
ê±°ë¦¬ì— í•˜ë‚˜ë‘˜ì”© ê°„íŒì„ ë‚´ë¦¬ê¸° ì‹œì‘í•˜ë”ë‹ˆ
ë§ˆì¹˜ ì‹ ê¸°ë£¨ì²˜ëŸ¼ ì‚¬ë¼ì ¸ë²„ë ¸ìŠµë‹ˆë‹¤

2.ì˜¤ë°± ê°œê°€ ë„˜ëŠ” ë§¤ì¥ì´
ìˆœì‹ê°„ì— ì¦ë°œí•´ ë²„ë¦° ì§„ì§œ ì´ìœ ëŠ”,
ì™¸ë¶€ì˜ ì ì´ ì•„ë‹Œ ë‚´ë¶€ì˜ ê°€ì¡±,
ë°”ë¡œ ë¶€ë¶€ì˜ ì „ìŸ ë•Œë¬¸ì´ì—ˆìŠµë‹ˆë‹¤

3.í•œë•Œ ëŒ€í•œë¯¼êµ­ ìš”ì‹ì—… í”„ëœì°¨ì´ì¦ˆì˜ ì‹ í™”ì˜€ìœ¼ë‚˜
ì§€ê¸ˆì€ ì˜¤ë„ˆ ë¦¬ìŠ¤í¬ì˜ ê°€ì¥ ë”ì°í•œ êµê³¼ì„œë¡œ ë‚¨ê²Œ ëœ
ë¹„ìš´ì˜ ë¸Œëœë“œ...""",
    key="image_gen_input"
)

if 'generated_results' not in st.session_state:
    st.session_state['generated_results'] = []
if 'is_processing' not in st.session_state:
    st.session_state['is_processing'] = False

# [KEY FIX] ë²„íŠ¼ í´ë¦­ ì‹œ ê²°ê³¼ë¬¼ ì´ˆê¸°í™” í•¨ìˆ˜ ì¶”ê°€
def clear_generated_results():
    st.session_state['generated_results'] = []

start_btn = st.button("ğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘", type="primary", width="stretch", on_click=clear_generated_results)

if start_btn:
    if not api_key:
        st.error("âš ï¸ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not script_input:
        st.warning("âš ï¸ ëŒ€ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # [FIX] ê¸°ì¡´ ê²°ê³¼ í™•ì‹¤íˆ ë‚ ë¦¬ê¸°
        st.session_state['generated_results'] = [] 
        st.session_state['is_processing'] = True
        
        # [FIX] ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚­ì œ (ì°Œêº¼ê¸° ì œê±°)
        if os.path.exists(IMAGE_OUTPUT_DIR):
            shutil.rmtree(IMAGE_OUTPUT_DIR) # í´ë” í†µì§¸ë¡œ ì‚­ì œ
        init_folders() # ë‹¤ì‹œ ê¹¨ë—í•œ í´ë” ìƒì„±
        
        # [ë©€í‹° API ì§€ì›] ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        clients = []
        for key in api_keys:
            clients.append(genai.Client(api_key=key))

        # í˜¸í™˜ì„±ì„ ìœ„í•´ ì²« ë²ˆì§¸ í´ë¼ì´ì–¸íŠ¸ë¥¼ clientë¡œë„ ì €ì¥
        client = clients[0] if clients else genai.Client(api_key=api_key)

        status_box = st.status("ì‘ì—… ì§„í–‰ ì¤‘...", expanded=True)
        progress_bar = st.progress(0)

        # 1. ëŒ€ë³¸ ë¶„í•  (ë²ˆí˜¸ ê¸°ë°˜)
        status_box.write(f"âœ‚ï¸ ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ íŒŒì‹± ì¤‘...")
        chunks = parse_numbered_script(script_input)
        total_scenes = len(chunks)

        if total_scenes == 0:
            status_box.update(label="âš ï¸ ë²ˆí˜¸ë¡œ ë¶„í• ëœ ì”¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì˜ˆ: 1.ë‚´ìš© 2.ë‚´ìš©)", state="error")
            st.stop()

        status_box.write(f"âœ… {total_scenes}ê°œ ì”¬ìœ¼ë¡œ íŒŒì‹± ì™„ë£Œ.")

        current_video_title = st.session_state.get('video_title', "").strip()
        if not current_video_title:
            current_video_title = "ì „ë°˜ì ì¸ ëŒ€ë³¸ ë¶„ìœ„ê¸°ì— ì–´ìš¸ë¦¬ëŠ” ë°°ê²½ (Context based on the script)"

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± (ë³‘ë ¬)
        status_box.write(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì¤‘ ({GEMINI_TEXT_MODEL_NAME})...")
        prompts = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []

            for i, chunk in enumerate(chunks):
                futures.append(executor.submit(
                    generate_prompt,
                    api_key,
                    i,
                    chunk,
                    style_instruction,
                    current_video_title,
                    target_language
                ))

            for i, future in enumerate(as_completed(futures)):
                prompts.append(future.result())
                progress_bar.progress((i + 1) / (total_scenes * 2))

        prompts.sort(key=lambda x: x[0])

        # 3. ì´ë¯¸ì§€ ìƒì„± (ë©€í‹° API ë³‘ë ¬ ì²˜ë¦¬)
        num_clients = len(clients)
        total_rate_limit = num_clients * 20  # ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜ (í‚¤ë‹¹ 20ê°œ)

        if num_clients > 1:
            status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL}) - {num_clients}ê°œ API ë³‘ë ¬ ì²˜ë¦¬ (ë¶„ë‹¹ ìµœëŒ€ {total_rate_limit}ê°œ)")
        else:
            status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL})... (API ë³´í˜¸ë¥¼ ìœ„í•´ ì²œì²œíˆ ì§„í–‰ë©ë‹ˆë‹¤)")

        results = []

        # [ë©€í‹° API] API í‚¤ ê°œìˆ˜ì— ë”°ë¼ worker ìˆ˜ì™€ ëŒ€ê¸° ì‹œê°„ ì¡°ì ˆ
        # í‚¤ 1ê°œ: 3ì´ˆ ê°„ê²© (ë¶„ë‹¹ 20ê°œ)
        # í‚¤ 2ê°œ: 1.5ì´ˆ ê°„ê²© (ë¶„ë‹¹ 40ê°œ)
        # í‚¤ 3ê°œ: 1ì´ˆ ê°„ê²© (ë¶„ë‹¹ 60ê°œ)
        # í‚¤ 4ê°œ: 0.75ì´ˆ ê°„ê²© (ë¶„ë‹¹ 80ê°œ)
        sleep_interval = 3.0 / num_clients
        adjusted_workers = min(max_workers, num_clients * 5)  # API í‚¤ë‹¹ 5ê°œ worker

        with ThreadPoolExecutor(max_workers=adjusted_workers) as executor:
            future_to_meta = {}
            request_count = 0

            for s_num, prompt_text in prompts:
                idx = s_num - 1
                orig_text = chunks[idx]
                fname = make_filename(s_num, orig_text)

                # [ë¼ìš´ë“œ ë¡œë¹ˆ] í´ë¼ì´ì–¸íŠ¸ ìˆœí™˜ ë°°ì •
                current_client = clients[request_count % num_clients]

                # [ì†ë„ ì¡°ì ˆ] API í‚¤ ê°œìˆ˜ì— ë§ì¶° ëŒ€ê¸°
                time.sleep(sleep_interval)

                # [80ê°œ ì œí•œ] ë©€í‹° API ì‚¬ìš© ì‹œ 80ê°œë§ˆë‹¤ 1ë¶„ ëŒ€ê¸°
                if num_clients > 1 and request_count > 0 and request_count % total_rate_limit == 0:
                    status_box.write(f"â³ API ì œí•œ ë³´í˜¸: {request_count}ê°œ ì™„ë£Œ, 60ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(60)

                future = executor.submit(generate_image, current_client, prompt_text, fname, IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL)
                future_to_meta[future] = (s_num, fname, orig_text, prompt_text)
                request_count += 1
            
            # ê²°ê³¼ ìˆ˜ì§‘
            completed_cnt = 0
            for future in as_completed(future_to_meta):
                s_num, fname, orig_text, p_text = future_to_meta[future]
                path = future.result()
                
                # [í•µì‹¬] ì‹¤íŒ¨(None)í•˜ë”ë¼ë„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ë„£ì–´ì„œ ìˆœì„œê°€ ë°€ë¦¬ì§€ ì•Šê²Œ í•¨ (ì›í•œë‹¤ë©´ ì—ëŸ¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥)
                if path:
                    results.append({
                        "scene": s_num,
                        "path": path,
                        "filename": fname,
                        "script": orig_text,
                        "prompt": p_text,
                        "audio_path": None,
                        "video_path": None 
                    })
                else:
                    # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë„˜ì–´ê°€ê±°ë‚˜, ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì„ ìˆ˜ë„ ìˆìŒ
                    st.error(f"Scene {s_num} ì´ë¯¸ì§€ ìƒì„± ìµœì¢… ì‹¤íŒ¨.")

                completed_cnt += 1
                progress_bar.progress(0.5 + (completed_cnt / total_scenes * 0.5))
        
        results.sort(key=lambda x: x['scene'])
        st.session_state['generated_results'] = results
        
        status_box.update(label="âœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", state="complete", expanded=False)
        st.session_state['is_processing'] = False
        
# ==========================================
# [ìˆ˜ì •ë¨] ê²°ê³¼ì°½ ë° ê°œë³„ ì¬ìƒì„± ê¸°ëŠ¥ ì¶”ê°€
# ==========================================
if st.session_state['generated_results']:
    st.divider()
    st.header(f"ğŸ“¸ ê²°ê³¼ë¬¼ ({len(st.session_state['generated_results'])}ì¥)")
    
    # ------------------------------------------------
    # 1. ì¼ê´„ ì‘ì—… ë²„íŠ¼ ì˜ì—­
    # ------------------------------------------------
    st.write("---")
    st.subheader("âš¡ ì›í´ë¦­ ì¼ê´„ ìƒì„± ì‘ì—…")
    
    c_btn1, c_btn2, c_btn3, c_btn4 = st.columns(4)
    
    with c_btn1:
        zip_data = create_zip_buffer(IMAGE_OUTPUT_DIR)
        st.download_button("ğŸ“¦ ì „ì²´ ì´ë¯¸ì§€ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_data, file_name="all_images.zip", mime="application/zip", use_container_width=True)

    # TTS ì „ì²´ ìƒì„±
    with c_btn2:
        tts_batch_mode = st.selectbox("TTS ìƒì„± ëª¨ë“œ", ["ì›ë³¸ ìŒì„± ìƒì„±", "ë¬´ìŒ ì¡°ì ˆ ìŒì„± (ìµœëŒ€ 0.3ì´ˆ)"], help="ë¬´ìŒ ì¡°ì ˆ ì„ íƒ ì‹œ ê³µë°± ìë™ ì¶•ì†Œ")
        if st.button("ğŸ”Š TTS ì¼ê´„ ìƒì„±", use_container_width=True):
            if not supertone_api_key or not selected_voice_id:
                st.error("ì‚¬ì´ë“œë°”ì—ì„œ API Keyì™€ ëª©ì†Œë¦¬ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            else:
                # ì˜¤ë””ì˜¤ ë³€ê²½ ì‹œ í†µí•©ë³¸ ì‚­ì œ
                final_merged_file = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
                if os.path.exists(final_merged_file):
                    try: os.remove(final_merged_file)
                    except: pass

                status_box = st.status("ğŸ™ï¸ TTS ì¼ê´„ ìƒì„± ì¤‘...", expanded=True)
                progress_bar = status_box.progress(0)
                
                apply_trim = (tts_batch_mode == "ë¬´ìŒ ì¡°ì ˆ ìŒì„± (ìµœëŒ€ 0.3ì´ˆ)")
                total_files = len(st.session_state['generated_results'])
                completed_cnt = 0
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_idx = {}
                    for i, item in enumerate(st.session_state['generated_results']):
                        future = executor.submit(
                            process_single_tts_task, supertone_api_key, selected_voice_id, 
                            item['script'], item['scene'], supertone_base_url, 
                            tts_speed, tts_pitch, apply_trim
                        )
                        future_to_idx[future] = i
                    
                    for future in as_completed(future_to_idx):
                        idx = future_to_idx[future]
                        try:
                            result_path = future.result()
                            if "Error" not in str(result_path) and "VOICE_NOT_FOUND" not in str(result_path):
                                st.session_state['generated_results'][idx]['audio_path'] = result_path
                                st.session_state['generated_results'][idx]['video_path'] = None # ë¹„ë””ì˜¤ ë¦¬ì…‹
                            else:
                                st.write(f"âš ï¸ Scene {idx+1} ì˜¤ë¥˜: {result_path}")
                        except Exception as e:
                            st.write(f"âš ï¸ Scene {idx+1} ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                        
                        completed_cnt += 1
                        progress_bar.progress(completed_cnt / total_files)
                
                status_box.update(label="âœ… TTS ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
                time.sleep(1)
                st.rerun()

    # ë¹„ë””ì˜¤ ì „ì²´ ìƒì„±
    with c_btn3:
        has_audio = any(item.get('audio_path') for item in st.session_state['generated_results'])
        if st.button("ğŸ¬ ë¹„ë””ì˜¤ ì „ì²´ ì¼ê´„ ìƒì„±", disabled=not has_audio, use_container_width=True):
            final_merged_file = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
            if os.path.exists(final_merged_file):
                try: os.remove(final_merged_file)
                except: pass
            
            status_box = st.status("ğŸ¬ ë¹„ë””ì˜¤ ë Œë”ë§ ì¤‘...", expanded=True)
            progress_bar = status_box.progress(0)
            
            total_files = len(st.session_state['generated_results'])
            completed_cnt = 0
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_idx = {}
                for i, item in enumerate(st.session_state['generated_results']):
                    is_zoom_in = (i % 2 == 0)
                    future = executor.submit(process_single_video_task, item, VIDEO_OUTPUT_DIR, is_zoom_in)
                    future_to_idx[future] = i
                
                for future in as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        vid_path = future.result()
                        if vid_path and "Error" not in vid_path:
                            st.session_state['generated_results'][idx]['video_path'] = vid_path
                        elif vid_path:
                            st.write(f"âš ï¸ Scene {idx+1} ë Œë”ë§ ì˜¤ë¥˜: {vid_path}")
                    except Exception as e:
                        st.write(f"âš ï¸ Scene {idx+1} ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                    
                    completed_cnt += 1
                    progress_bar.progress(completed_cnt / total_files)
            
            status_box.update(label="âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
            time.sleep(1)
            st.rerun()

    # ì „ì²´ ë³‘í•©
    with c_btn4:
        video_paths = [item.get('video_path') for item in st.session_state['generated_results'] if item.get('video_path')]
        final_path = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
        
        if video_paths:
            if st.button("ğŸï¸ ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸° (ìƒˆë¡œê³ ì¹¨)", use_container_width=True):
                with st.spinner("ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘..."):
                    if os.path.exists(final_path):
                        try: os.remove(final_path)
                        except: pass
                        
                    merged_result = merge_all_videos(video_paths, VIDEO_OUTPUT_DIR)
                    if "Error" in merged_result:
                        st.error(merged_result)
                    else:
                        st.success("ë³‘í•© ì™„ë£Œ!")
                        st.rerun()

            if os.path.exists(final_path):
                 with open(final_path, "rb") as f:
                    st.download_button("ğŸ’¾ ì „ì²´ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (MP4)", data=f, file_name="final_video.mp4", mime="video/mp4", use_container_width=True)
        else:
            st.button("ğŸï¸ ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸°", disabled=True, use_container_width=True)

    if not supertone_api_key or not selected_voice_id:
        st.warning("ğŸ™ï¸ Supertone TTS ì‚¬ìš©ì„ ìœ„í•´ API ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

    # ------------------------------------------------
    # 2. ê°œë³„ ë¦¬ìŠ¤íŠ¸ ë° [ì¬ìƒì„±] ê¸°ëŠ¥
    # ------------------------------------------------
    for index, item in enumerate(st.session_state['generated_results']):
        with st.container(border=True):
            cols = st.columns([1, 2])
            
            # [ì™¼ìª½] ì´ë¯¸ì§€ ë° ì¬ìƒì„± ë²„íŠ¼
            with cols[0]:
                try: st.image(item['path'], use_container_width=True)
                except: st.error("ì´ë¯¸ì§€ ì—†ìŒ")
                
                # [NEW] ì´ë¯¸ì§€ ê°œë³„ ì¬ìƒì„± ë²„íŠ¼
                if st.button(f"ğŸ”„ ì´ ì¥ë©´ë§Œ ì´ë¯¸ì§€ ë‹¤ì‹œ ìƒì„±", key=f"regen_img_{index}", use_container_width=True):
                    if not api_key:
                        st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        with st.spinner(f"Scene {item['scene']} ë‹¤ì‹œ ê·¸ë¦¬ëŠ” ì¤‘..."):
                            client = genai.Client(api_key=api_key)
                            
                            # 1. í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ìƒì„± (í˜„ì¬ ëŒ€ë³¸ê³¼ ìŠ¤íƒ€ì¼ ë°˜ì˜)
                            current_title = st.session_state.get('video_title', '')
                            # ëŒ€ë³¸ì´ ìˆ˜ì •ë˜ì—ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ item['script'] ì‚¬ìš©
                            _, new_prompt = generate_prompt(
                                api_key, index, item['script'], style_instruction,
                                current_title, target_language
                            )
                            
                            # 2. ì´ë¯¸ì§€ ìƒì„±
                            new_path = generate_image(
                                client, new_prompt, item['filename'], 
                                IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL
                            )
                            
                            if new_path:
                                # 3. ê²°ê³¼ ì—…ë°ì´íŠ¸
                                st.session_state['generated_results'][index]['path'] = new_path
                                st.session_state['generated_results'][index]['prompt'] = new_prompt
                                # ì´ë¯¸ì§€ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ê¸°ì¡´ ë¹„ë””ì˜¤ëŠ” ë¬´íš¨í™”
                                st.session_state['generated_results'][index]['video_path'] = None
                                st.success("ì´ë¯¸ì§€ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                time.sleep(0.5)
                                st.rerun()
                            else:
                                st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            # [ì˜¤ë¥¸ìª½] ì •ë³´ ë° ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì»¨íŠ¸ë¡¤
            with cols[1]:
                st.subheader(f"Scene {item['scene']:02d}")
                st.caption(f"íŒŒì¼ëª…: {item['filename']}")
                
                # ëŒ€ë³¸ ìˆ˜ì • ê°€ëŠ¥í•˜ê²Œ í• ì§€? (í˜„ì¬ëŠ” displayë§Œ)
                st.write(f"**ëŒ€ë³¸:** {item['script']}")
                
                st.markdown("---")
                audio_col1, audio_col2 = st.columns([1, 3])
                
                # ì˜¤ë””ì˜¤ ë¡œì§
                if item.get('audio_path') and os.path.exists(item['audio_path']):
                    with audio_col1:
                        st.audio(item['audio_path'])
                        if st.button("ğŸ”„ ì˜¤ë””ì˜¤ ì¬ìƒì„±", key=f"re_tts_{item['scene']}"):
                             item['audio_path'] = None
                             item['video_path'] = None 
                             st.rerun()
                    
                    with audio_col2:
                        if item.get('video_path') and os.path.exists(item['video_path']):
                            st.video(item['video_path'])
                            with open(item['video_path'], "rb") as vf:
                                st.download_button("â¬‡ï¸ ë¹„ë””ì˜¤ ì €ì¥", data=vf, file_name=f"scene_{item['scene']}.mp4", mime="video/mp4", key=f"down_vid_{item['scene']}")
                        else:
                            is_zoom_in_mode = (index % 2 == 0)
                            button_label = f"ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ({'ì¤Œì¸' if is_zoom_in_mode else 'ì¤Œì•„ì›ƒ'})"

                            if st.button(button_label, key=f"gen_vid_{item['scene']}"):
                                with st.spinner("ë Œë”ë§ ì¤‘..."):
                                    vid_path = create_video_with_zoom(
                                        item['path'], item['audio_path'], VIDEO_OUTPUT_DIR, 
                                        item['scene'], is_zoom_in=is_zoom_in_mode
                                    )
                                    if "Error" in vid_path:
                                        st.error(vid_path)
                                    else:
                                        st.session_state['generated_results'][index]['video_path'] = vid_path
                                        st.rerun()
                else:
                    with audio_col1:
                        if st.button("ğŸ”Š TTS ìƒì„±", key=f"gen_tts_{item['scene']}"):
                            if not supertone_api_key or not selected_voice_id:
                                st.error("ì„¤ì • í•„ìš”")
                            else:
                                with st.spinner("ì˜¤ë””ì˜¤ ìƒì„± ì¤‘..."):
                                    audio_result = generate_supertone_tts(
                                        supertone_api_key, selected_voice_id, 
                                        item['script'], item['scene'], supertone_base_url, 
                                        speed=tts_speed, pitch=tts_pitch
                                    )
                                    if "Error" not in str(audio_result) and "VOICE_NOT_FOUND" != audio_result:
                                        st.session_state['generated_results'][index]['audio_path'] = audio_result
                                        st.rerun()
                                    else:
                                        st.error(audio_result)

                with st.expander("í”„ë¡¬í”„íŠ¸ í™•ì¸"):
                    st.text(item['prompt'])
                try:
                    with open(item['path'], "rb") as file:
                        st.download_button("â¬‡ï¸ ì´ë¯¸ì§€ ì €ì¥", data=file, file_name=item['filename'], mime="image/png", key=f"btn_down_{item['scene']}")
                except: pass



