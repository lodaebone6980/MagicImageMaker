import streamlit as st
import requests
import json
import time
import os
import re
import shutil
import zipfile
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from PIL import Image
from google import genai
from google.genai import types

# [NEW] ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from pydub import AudioSegment
from pydub.silence import detect_silence

# [NEW] ë™ì˜ìƒ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° íš¨ê³¼ ì¶”ê°€
try:
    # VideoFileClip, concatenate_videoclips ì¶”ê°€ (ì˜ìƒ ë³‘í•©ìš©)
    from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, VideoFileClip, concatenate_videoclips
    import numpy as np 
except ImportError:
    st.error("âš ï¸ 'moviepy' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì— 'pip install moviepy numpy'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ì´ë¯¸ì§€ ìƒì„±ê¸°", layout="wide", page_icon="ğŸ¨")

# íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
BASE_PATH = "./web_result_files"
IMAGE_OUTPUT_DIR = os.path.join(BASE_PATH, "output_images")
AUDIO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_audio")
VIDEO_OUTPUT_DIR = os.path.join(BASE_PATH, "output_video") 

# í…ìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •
GEMINI_TEXT_MODEL_NAME = "gemini-2.5-pro" 

# [ê¸°ë³¸ê°’] ë¬¸ì„œì— ëª…ì‹œëœ ì •í™•í•œ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ
DEFAULT_SUPERTONE_URL = "https://supertoneapi.com"
DEFAULT_VOICE_ID = "ff700760946618e1dcf7bd" 

# ==========================================
# [í•¨ìˆ˜] 0. TTSìš© í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì/ê¸°í˜¸ -> í•œê¸€)
# ==========================================
def num_to_kor(num_str):
    """ìˆ«ì ë¬¸ìì—´ì„ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 1,500 -> ì²œì˜¤ë°±)"""
    try:
        num_str = num_str.replace(',', '')
        if not num_str.isdigit(): return num_str
        
        num = int(num_str)
        if num == 0: return "ì˜"
        
        units = ['', 'ì‹­', 'ë°±', 'ì²œ']
        big_units = ['', 'ë§Œ', 'ì–µ', 'ì¡°', 'ê²½']
        num_chars = ['', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
        
        result = []
        big_idx = 0
        
        while num > 0:
            small_part = num % 10000
            if small_part > 0:
                small_res = []
                small_idx = 0
                while small_part > 0:
                    digit = small_part % 10
                    if digit > 0:
                        unit = units[small_idx]
                        char = num_chars[digit]
                        if digit == 1 and small_idx > 0:
                            char = ""
                        small_res.append(char + unit)
                    small_part //= 10
                    small_idx += 1
                result.append("".join(reversed(small_res)) + big_units[big_idx])
            num //= 10000
            big_idx += 1
            
        return "".join(reversed(result))
    except:
        return num_str

def normalize_text_for_tts(text):
    """TTS ë°œìŒì„ ìœ„í•´ íŠ¹ìˆ˜ë¬¸ìì™€ ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜"""
    text = text.replace("%", " í¼ì„¼íŠ¸")
    
    def replace_decimal(match):
        return f"{match.group(1)} ì  {match.group(2)}"
    text = re.sub(r'(\d+)\.(\d+)', replace_decimal, text)

    def replace_number(match):
        return num_to_kor(match.group())
    
    text = re.sub(r'\d+(?:,\d+)*', replace_number, text)
    
    return text

# ==========================================
# [í•¨ìˆ˜] 1. ëŒ€ë³¸ êµ¬ì¡°í™” ë¡œì§
# ==========================================
def generate_structure(client, full_script):
    """Geminië¥¼ ì´ìš©í•´ ëŒ€ë³¸ êµ¬ì¡°í™”"""
    prompt = f"""
    [Role]
    You are a professional YouTube Content Editor and Scriptwriter.

    [Task]
    Analyze the provided transcript (script).
    Restructure the content into a highly detailed, list-style format suitable for a blog post or a new video plan.
      
    [Output Format]
    1. **Video Theme/Title**: (Extract or suggest a catchy title based on the whole script)
    2. **Intro**: (Hook and background, no music) Approve specific channel names, The intro hooks the overall topic (ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ ê°™ì€ ì¸ì‚¬ ê¸ˆì§€)
    3. **Chapter 1** to **Chapter 8**: (Divide the main content into logical sections. Use detailed bullet points for each chapter.)
    4. **Epilogue**: (Conclusion and Subscribe Like Comments that make you anticipate the next specific content)

    [Constraint]
    - Analyze the entire context deeply.
    - Write the output in **Korean**.
    - Make the content rich and detailed.
    - If the original script has a channel name, remove it.

    [Transcript]
    {full_script}
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 2. ì„¹ì…˜ë³„ ëŒ€ë³¸ ìƒì„± (ìˆ˜ì • ë²„ì „)
# ==========================================
def generate_section(client, section_title, full_structure, duration_type="fixed", custom_instruction=""):
    # 1. ë¶„ëŸ‰ì— ë”°ë¥¸ ê¸€ììˆ˜ ë° ì§€ì¹¨ ì„¤ì •
    if duration_type == "2min":
        target_chars = "ì•½ 1,000ì (ê³µë°± í¬í•¨)"
        detail_level = "í•µì‹¬ ë‚´ìš© ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ë˜, ë„ˆë¬´ ì§§ì§€ ì•Šê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "3min":
        target_chars = "ì•½ 1,500ì (ê³µë°± í¬í•¨)"
        detail_level = "ì¶©ë¶„í•œ ì˜ˆì‹œì™€ ì„¤ëª…ì„ ê³ë“¤ì—¬ ìƒì„¸í•˜ê²Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."
    elif duration_type == "4min":
        target_chars = "ì•½ 2,000ì ì´ìƒ (ê³µë°± í¬í•¨)"
        detail_level = "í˜„ë¯¸ê²½ìœ¼ë¡œ ë“¤ì—¬ë‹¤ë³´ë“¯ ì•„ì£¼ ê¹Šì´ ìˆê³  ë””í…Œì¼í•˜ê²Œ ë¬˜ì‚¬í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
    else: # Intro / Epilogue (Fixed)
        target_chars = "ì•½ 400ë‹¨ì–´ (ì•½ 1,400ì)"
        detail_level = "ì‹œì²­ìë¥¼ ì‚¬ë¡œì¡ëŠ” ê°•ë ¥í•œ í›„í‚¹ê³¼ ì—¬ìš´ì„ ì£¼ëŠ” ë§ˆë¬´ë¦¬ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì•ˆë…• ì¸ì‚¬ëŠ” í•˜ì§€ ì•ŠëŠ”ë‹¤"

    user_guide_prompt = ""
    if custom_instruction:
        user_guide_prompt = f"""
    [User's Special Direction]
    The user has provided specific instructions for the tone/style. You MUST follow this:
    ğŸ‘‰ "{custom_instruction}"
        """

    prompt = f"""
    [Role]
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìœ íŠœë¸Œ ë‹¤íë©˜í„°ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.

    [Task]
    ì „ì²´ ëŒ€ë³¸ êµ¬ì¡° ì¤‘ ì˜¤ì§ **"{section_title}"** ë¶€ë¶„ë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
      
    [Context (Overall Structure)]
    {full_structure}
    {user_guide_prompt}

    [Target Section]
    **{section_title}**

    [Length Constraints]
    - **ëª©í‘œ ë¶„ëŸ‰: {target_chars}** - **ì‘ì„± ì§€ì¹¨:** {detail_level}
      
    [Style Guidelines - ë§¤ìš° ì¤‘ìš”]
    1. 'ìŠµë‹ˆë‹¤' ì²´ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤íë©˜í„°ë¦¬ íŠ¹ìœ ì˜ ì§„ì§€í•˜ê³  ëª°ì…ê° ìˆëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    2. ì•ë’¤ ë¬¸ë§¥(ì´ì „ ì±•í„°, ë‹¤ìŒ ì±•í„°)ì„ ê³ ë ¤í•˜ë˜, ì´ íŒŒíŠ¸ì˜ ë‚´ìš©ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.
    3. (ì§€ë¬¸), (íš¨ê³¼ìŒ) ê°™ì€ ì—°ì¶œ ì§€ì‹œì–´ëŠ” ì œì™¸í•˜ê³  **ì˜¤ì§ ë‚˜ë ˆì´ì…˜ ëŒ€ì‚¬ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.
    4. ì„œë‘ì— "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤" ê°™ì€ ì¡ë‹´ì„ í•˜ì§€ ë§ê³  ë°”ë¡œ ëŒ€ë³¸ ë‚´ìš©ì„ ì‹œì‘í•˜ì„¸ìš”.
    5. ì˜ë¬¸ ë³‘ê¸°(ê´„í˜¸)ëŠ” í•˜ì§€ ë§ˆì„¸ìš”. ê¹”ë”í•˜ê²Œ í•œê¸€ë§Œ.
    6. ì‰¼í‘œì™€ ì ‘ì†ì–´ ë“±ì„ ì‚¬ìš©í•˜ì—¬, ë¦¬ë“¬ì´ ìˆì§€ë§Œ ë„ˆë¬´ ëŠê¸°ì§€ ì•ŠëŠ” íë¦„ì„ ë§Œë“¤ ê²ƒ.
    
    # [ìˆ˜ì •ë¨] íë¦„ ëŠê¹€ ë°©ì§€ í•µì‹¬ ì§€ì¹¨ --------------------------
    7. **[ê¸ˆì§€ì‚¬í•­]** ê¸€ì˜ ë§ˆì§€ë§‰ì— "ë‹¤ìŒ ì¥ì—ì„œëŠ”...", "ì´ì–´ì„œ...", "ì´ì œ ~ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤" ê°™ì€ **ì˜ˆê³ ì„± ë©˜íŠ¸ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    8. **[ê¸ˆì§€ì‚¬í•­]** "ì§€ê¸ˆê¹Œì§€ ~ë¥¼ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤" ê°™ì€ **ì¤‘ê°„ ì •ë¦¬ ë©˜íŠ¸ë„ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.**
    9. ì´ í…ìŠ¤íŠ¸ë“¤ì€ ë‚˜ì¤‘ì— í•˜ë‚˜ë¡œ í•©ì³ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ **ê·¸ëƒ¥ ì„¤ëª…í•˜ë‹¤ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥(ë§ˆì¹¨í‘œ)ìœ¼ë¡œ ëë‚´ì‹­ì‹œì˜¤.** ë’·ë‚´ìš©ì€ ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ë°›ìŠµë‹ˆë‹¤.
    10. ì±•í„° ë²ˆí˜¸ë‚˜ ì†Œì œëª©ì„ ë³¸ë¬¸ì— ë‹¤ì‹œ ì ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ë‚´ìš©ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
    ---------------------------------------------------------

    [Output]
    (ì§€ê¸ˆ ë°”ë¡œ {section_title}ì˜ ì›ê³ ë¥¼ ì‘ì„± ì‹œì‘í•˜ì„¸ìš”)
    """
    
    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(
                max_output_tokens=8192,
                temperature=0.75 
            )
        )
        return response.text
    except Exception as e:
        return f"Error: {e}"

# ==========================================
# [í•¨ìˆ˜] 3. ì´ë¯¸ì§€ ìƒì„± ê´€ë ¨ ë¡œì§
# ==========================================

def init_folders():
    for path in [IMAGE_OUTPUT_DIR, AUDIO_OUTPUT_DIR, VIDEO_OUTPUT_DIR]:
        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)

def split_script_by_time(script, chars_per_chunk=100):
    temp_sentences = script.replace(".", ".|").replace("?", "?|").replace("!", "!|").split("|")
    chunks = []
    current_chunk = ""
    for sentence in temp_sentences:
        sentence = sentence.strip()
        if not sentence: continue
        if len(current_chunk) + len(sentence) < chars_per_chunk:
            current_chunk += " " + sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def parse_numbered_script(script):
    """
    ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ì„ íŒŒì‹±í•˜ì—¬ ì”¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    ì¤„ë°”ê¿ˆì„ ì œê±°í•˜ê³  ë¬¸ì¥ì„ ì¡°í™”ë¡­ê²Œ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    import re

    scenes = []
    lines = script.strip().split('\n')
    current_scene_lines = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # ìƒˆë¡œìš´ ì”¬ ì‹œì‘ì¸ì§€ í™•ì¸ (ìˆ«ì + ì ìœ¼ë¡œ ì‹œì‘)
        match = re.match(r'^(\d+)\.(.*)$', line)
        if match:
            # ì´ì „ ì”¬ì´ ìˆìœ¼ë©´ ì €ì¥
            if current_scene_lines:
                scene_text = ' '.join(current_scene_lines)
                # ì—°ì† ê³µë°± ì œê±°
                scene_text = re.sub(r'\s+', ' ', scene_text).strip()
                if scene_text:
                    scenes.append(scene_text)

            # ìƒˆ ì”¬ ì‹œì‘ (ë²ˆí˜¸ ë’¤ì˜ ë‚´ìš©)
            rest = match.group(2).strip()
            current_scene_lines = [rest] if rest else []
        else:
            # í˜„ì¬ ì”¬ì— ë¼ì¸ ì¶”ê°€
            current_scene_lines.append(line)

    # ë§ˆì§€ë§‰ ì”¬ ì €ì¥
    if current_scene_lines:
        scene_text = ' '.join(current_scene_lines)
        scene_text = re.sub(r'\s+', ' ', scene_text).strip()
        if scene_text:
            scenes.append(scene_text)

    return scenes

# ==========================================
# [UPGRADE] í•¨ìˆ˜: AI ê¸°ë°˜ ëŒ€ë³¸ ë§¥ë½ ë¶„í• 
# ==========================================
def split_text_automatically(client, full_text, target_chars=200):
    """
    Geminië¥¼ ì´ìš©í•´ ë¬¸ë§¥(Context)ì„ íŒŒì•…í•˜ê³ ,
    ì‹œê°ì  ì¥ë©´ ì „í™˜ì´ í•„ìš”í•œ ì§€ì ë§ˆë‹¤ ëŒ€ë³¸ì„ ë¶„í• í•©ë‹ˆë‹¤.
    (ê¸°ì¤€ì€ ì•½ 150~200ìì´ì§€ë§Œ, ë¬¸ë§¥ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤)
    """
    prompt = f"""
    [Role]
    You are a professional Video Editor and Storyboard Artist.

    [Task]
    Split the provided [Script] into multiple "Scenes" for image generation.

    [Rules]
    1. **Context First:** Read the entire context. Split the text where the visual scene, topic, or mood changes.
    2. **Length Guideline:** Aim for each scene to be roughly **{target_chars} characters** (approx. 20-40 seconds).
       - However, DO NOT break a sentence in the middle.
       - If a topic is long, split it into logical parts.
       - If a topic is short but distinct, keep it as a separate scene.
    3. **Output Format:** Return ONLY a raw JSON list of strings. No markdown, no "```json".
       - Example: ["First scene text...", "Second scene text...", "Third scene text..."]

    [Script]
    {full_text}
    """

    try:
        response = client.models.generate_content(
            model=GEMINI_TEXT_MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"  # JSON ê°•ì œ ì¶œë ¥
            )
        )

        # JSON íŒŒì‹±
        scenes = json.loads(response.text)

        # ë§Œì•½ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´(í˜¹ì‹œ ëª¨ë¥¼ ì—ëŸ¬ ëŒ€ë¹„) ê°•ì œ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
        if isinstance(scenes, list):
            return [s.strip() for s in scenes if s.strip()]
        else:
            # êµ¬ì¡°ê°€ ë‹¤ë¥´ë©´ ë‹¨ìˆœ ì¤„ë°”ê¿ˆ ë¶„í• ë¡œ ëŒ€ì²´ (Fallback)
            return [s.strip() for s in full_text.split('\n') if s.strip()]

    except Exception as e:
        print(f"AI Split Error: {e}")
        # API ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ì¡´ì˜ ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜ ë¶„í• ë¡œ ëŒ€ì²´ (ì•ˆì „ì¥ì¹˜)
        import re
        sentences = re.split(r'(?<=[.?!])\s+', full_text.strip())
        scenes = []
        current_chunk = ""
        for sentence in sentences:
            if not sentence.strip(): continue
            if len(current_chunk) + len(sentence) > target_chars:
                if current_chunk: scenes.append(current_chunk.strip())
                current_chunk = sentence
            else:
                current_chunk += " " + sentence
        if current_chunk: scenes.append(current_chunk.strip())
        return scenes

def make_filename(scene_num, text_chunk):
    clean_line = text_chunk.replace("\n", " ").strip()
    clean_line = re.sub(r'[\\/:*?"<>|]', "", clean_line)
    words = clean_line.split()
    
    if len(words) <= 6:
        summary = " ".join(words)
    else:
        start_part = " ".join(words[:3])
        end_part = " ".join(words[-3:])
        summary = f"{start_part}...{end_part}"
    
    filename = f"S{scene_num:03d}_{summary}.png"
    return filename

# ==========================================
# [ë§ˆìŠ¤í„° ì—…ê·¸ë ˆì´ë“œ] í•¨ìˆ˜: í”„ë¡¬í”„íŠ¸ ìƒì„± (í’€ì°©ì¥ + í…ìŠ¤íŠ¸ ê°€ë…ì„± + ì •í™•í•œ ë‹¨ì–´)
# ==========================================
def generate_prompt(api_key, index, text_chunk, style_instruction, video_title, target_language="Korean"):
    """[ë§ˆìŠ¤í„° ì—…ê·¸ë ˆì´ë“œ] í’€ì°©ì¥ ìºë¦­í„° + í…ìŠ¤íŠ¸ ê°€ë…ì„± ê·¹ëŒ€í™” + ì •í™•í•œ ë‹¨ì–´ ì‚¬ìš©"""
    scene_num = index + 1
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_TEXT_MODEL_NAME}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}

    # 1. ì–¸ì–´ ì„¤ì •
    lang_guide = f"í™”ë©´ ì† ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ë°˜ë“œì‹œ '{target_language}'(ìœ¼)ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì˜ì–´ ë°œìŒì„ ê·¸ëŒ€ë¡œ ì˜®ê¸´ ë‹¨ì–´(ì˜ˆ: JJANGMYEON)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , í•´ë‹¹ ì–¸ì–´ì˜ í‘œì¤€ ë‹¨ì–´(ì˜ˆ: ì§œì¥ë©´)ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤."

    # 2. ê³ ì • ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ (ìƒí•˜ì˜ ì˜ìƒ + í…ìŠ¤íŠ¸ ì™¸ê³½ì„ )
    # [ë³€ê²½] ì˜ìƒì€ ìƒì˜(Top)ì™€ í•˜ì˜(Pants)ë¥¼ ëª¨ë‘ ëª…ì‹œ, í…ìŠ¤íŠ¸ëŠ” ë°°ê²½ê³¼ ë¶„ë¦¬ëœ ë°•ìŠ¤ë‚˜ ë‘êº¼ìš´ í…Œë‘ë¦¬ ê°•ì¡°
    style_suffix = (
        ", 2D flat animation style. The white stickman MUST be fully dressed, "
        "**wearing both a colorful top (shirt/suit) and long pants (trousers)**. "
        "Single unified scene, NO split screens. "
        "**Text must be placed inside a high-contrast speech bubble or on a clear signboard with a thick black outline** "
        "to ensure it is not buried by the background. High-key studio lighting, vivid colors."
    )

    # 3. í”„ë¡¬í”„íŠ¸ ì§€ì¹¨ (ì •í™•ì„± + êµ¬ë„ + ì˜ìƒ)
    full_instruction = f"""
[Role]
ë‹¹ì‹ ì€ ì‹œê°ì  ê°€ë…ì„±ê³¼ ìºë¦­í„°ì˜ ì™„ì„±ë„ë¥¼ ì¤‘ì‹œí•˜ëŠ” 'ì¸í¬ê·¸ë˜í”½ ì „ë¬¸ ê°ë…'ì…ë‹ˆë‹¤.

[Style Guide]
{style_instruction}

[Visual Task: í•µì‹¬ ìˆ˜ì¹™]
1. **ì •í™•í•œ ë‹¨ì–´ ì‚¬ìš©:** ëŒ€ë³¸ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ì—¬ '{target_language}' í‘œì¤€ ë‹¨ì–´ë§Œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°í•©ì–´(ì˜ˆ: ì¶©êµ­ì§‘)ë‚˜ ì˜ë¬¸ í‘œê¸°(ì˜ˆ: JJANGMYEON)ë¥¼ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤. ì¤‘êµ­ì§‘ì€ 'ì¤‘ì‹ë‹¹' í˜¹ì€ 'ì¤‘êµ­ì§‘'ìœ¼ë¡œ ì •í™•íˆ í‘œê¸°í•˜ì‹­ì‹œì˜¤.
2. **ìºë¦­í„° ì˜ìƒ (Full Outfit):** í•˜ì–€ ìŠ¤í‹±ë§¨ì€ ë°˜ë“œì‹œ **ìƒì˜(ì…”ì¸ /ìì¼“)ì™€ í•˜ì˜(ë°”ì§€)**ë¥¼ ëª¨ë‘ ì…ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë§¨ëª¸ì— ë„¥íƒ€ì´ë§Œ ë§¤ê±°ë‚˜ ìƒì˜ë§Œ ì…ëŠ” ì—°ì¶œì„ ì—„ê²©íˆ ê¸ˆì§€í•©ë‹ˆë‹¤. ì˜ìƒì€ ë°°ê²½ê³¼ ëŒ€ë¹„ë˜ëŠ” ì„ ëª…í•œ ìœ ìƒ‰(ì»¬ëŸ¬)ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
3. **í…ìŠ¤íŠ¸ ì‹œì¸ì„± (Text Readability):** {lang_guide}
   - í…ìŠ¤íŠ¸ëŠ” ë°°ê²½ ì´ë¯¸ì§€ì™€ ì§ì ‘ ê²¹ì¹˜ì§€ ì•Šë„ë¡ **'ê¹¨ë—í•œ ë§í’ì„ '**ì´ë‚˜ **'ë³„ë„ì˜ ì „ê´‘íŒ/í‘œì§€íŒ'** ì•ˆì— ë°°ì¹˜í•˜ì‹­ì‹œì˜¤.
   - ê¸€ìì˜ ì™¸ê³½ì„ (Outline) í”½ì…€ì„ ë§¤ìš° ë†’ì—¬ ë°°ê²½ê³¼ í™•ì‹¤íˆ ë¶„ë¦¬ë˜ê²Œ í•˜ì‹­ì‹œì˜¤.
4. **êµ¬ë„ì˜ ë‹¤ì–‘í™”:** ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ 'ì™€ì´ë“œ/ë¯¸ë””ì—„/í´ë¡œì¦ˆì—…' ì¤‘ ìµœì ì˜ êµ¬ë„ë¥¼ ìŠ¤ìŠ¤ë¡œ ì„ íƒí•˜ì‹­ì‹œì˜¤. ë‹¨, í™”ë©´ ë¶„í• (Split screen)ì€ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

[ê²½ì œì  ìƒí™© ì—°ì¶œ]
- ê°€ê²© ìƒìŠ¹ì´ë‚˜ ìœ„ê¸° ìƒí™©ì„ ê·¸ë¦´ ë•Œ 'ì–´ë‘ 'ì„ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤. ëŒ€ì‹  'ë°ì€ ì¡°ëª… ì•„ë˜ ë•€ì„ í˜ë¦¬ëŠ” ìºë¦­í„°', 'ë¶€ì„œì§€ëŠ” í™©ê¸ˆìƒ‰ ì‚¬ë¬¼', 'ìš°ìƒí–¥í•˜ëŠ” ë¹¨ê°„ìƒ‰ í™”ì‚´í‘œ' ë“±ì„ í™œìš©í•˜ì‹­ì‹œì˜¤.

[ì˜ìƒ ì£¼ì œ] "{video_title}"
[ëŒ€ë³¸ ì¡°ê°] "{text_chunk}"

[Output í˜•ì‹]
- êµ¬ë„ ì„¤ëª…ì´ë‚˜ ì¡ë‹´ ì—†ì´ **ì´ë¯¸ì§€ ìƒì„±ìš© í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
"""

    payload = {
        "contents": [{"parts": [{"text": full_instruction}]}]
    }

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            try:
                generated_text = response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
                # ë§ˆì¹¨í‘œ ì •ë¦¬ í›„ ê³ ì • ìŠ¤íƒ€ì¼ Suffix ê²°í•©
                final_prompt = f"{generated_text.rstrip('.')}{style_suffix}"
            except:
                final_prompt = text_chunk + style_suffix
            return (scene_num, final_prompt)
        else:
            return (scene_num, f"Error: {response.status_code}")
    except Exception as e:
        return (scene_num, f"Error: {e}")

# ==========================================
# [ìˆ˜ì •ë¨] generate_image: API ì œí•œ(429) ì™„ë²½ ëŒ€ì‘ + ì¬ì‹œë„ ê°•í™”
# ==========================================
def generate_image(client, prompt, filename, output_dir, selected_model_name):
    full_path = os.path.join(output_dir, filename)
    
    # [ìˆ˜ì • 1] ì¬ì‹œë„ íšŸìˆ˜ë¥¼ 10íšŒë¡œ ëŠ˜ë ¤ì„œ ì ˆëŒ€ í¬ê¸°í•˜ì§€ ì•Šê²Œ í•¨
    max_retries = 10
    
    # [ìˆ˜ì • 2] ì•ˆì „ í•„í„° (ê¸°ì¡´ ìœ ì§€)
    safety_settings = [
        types.SafetySetting(
            category="HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HARASSMENT",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_HATE_SPEECH",
            threshold="BLOCK_ONLY_HIGH"
        ),
        types.SafetySetting(
            category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold="BLOCK_ONLY_HIGH"
        ),
    ]

    for attempt in range(1, max_retries + 1):
        try:
            response = client.models.generate_content(
                model=selected_model_name,
                contents=[prompt],
                config=types.GenerateContentConfig(
                    image_config=types.ImageConfig(aspect_ratio="16:9"),
                    safety_settings=safety_settings 
                )
            )
            
            if response.parts:
                for part in response.parts:
                    if part.inline_data:
                        img_data = part.inline_data.data
                        image = Image.open(BytesIO(img_data))
                        image.save(full_path)
                        return full_path
            
            # ì‘ë‹µì€ ì™”ìœ¼ë‚˜ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° (í•„í„°ë§ ë“±)
            print(f"âš ï¸ [ì‹œë„ {attempt}/{max_retries}] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ. ì¬ì‹œë„... ({filename})")
            time.sleep(2)
            
        except Exception as e:
            error_msg = str(e)
            # [ìƒì„¸ ì—ëŸ¬ ë¡œê¹… ì¶”ê°€]
            print(f"=" * 50)
            print(f"ğŸ”´ [ì—ëŸ¬ ìƒì„¸] {filename}")
            print(f"   ì‹œë„: {attempt}/{max_retries}")
            print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            print(f"   ì—ëŸ¬ ë©”ì‹œì§€: {error_msg}")
            print(f"=" * 50)

            # [í•µì‹¬ ìˆ˜ì •] 429 (Too Many Requests) ë˜ëŠ” 429 Resource Exhausted ì—ëŸ¬ ë°œìƒ ì‹œ
            if "429" in error_msg or "ResourceExhausted" in error_msg:
                wait_time = 30  # 30ì´ˆ ë™ì•ˆ ë©ˆì·„ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„ (ë¶„ë‹¹ ì œí•œ ì´ˆê¸°í™” ëŒ€ê¸°)
                print(f"ğŸ›‘ [API ì œí•œ ê°ì§€] {filename} - {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                time.sleep(wait_time)
            elif "400" in error_msg or "InvalidArgument" in error_msg or "SAFETY" in error_msg.upper():
                # 400 ì—ëŸ¬ ë˜ëŠ” ì•ˆì „ í•„í„° - ìƒì„¸ ë¡œê¹…
                print(f"ğŸš« [ì»¨í…ì¸  ê±°ë¶€] {filename} - í”„ë¡¬í”„íŠ¸ê°€ ê±°ë¶€ë¨. 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(5)
            else:
                # ì¼ë°˜ ì—ëŸ¬ëŠ” 5ì´ˆ ëŒ€ê¸°
                print(f"âš ï¸ [ê¸°íƒ€ ì—ëŸ¬] {filename} - 5ì´ˆ ëŒ€ê¸°")
                time.sleep(5)
            
    # [ìµœì¢… ì‹¤íŒ¨]
    print(f"âŒ [ìµœì¢… ì‹¤íŒ¨] {filename} - ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")
    return None

def create_zip_buffer(source_dir):
    buffer = BytesIO()
    with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for root, dirs, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                zip_file.write(file_path, os.path.basename(file_path))
    buffer.seek(0)
    return buffer

# ==========================================
# [í•¨ìˆ˜] 4. Supertone TTS ë° ì˜¤ë””ì˜¤ í›„ì²˜ë¦¬ (Noise Cut - Micro Fade)
# ==========================================
def check_connection_and_get_voices(api_key, base_url):
    """ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ëª©ì†Œë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/voices"
    headers = {"x-sup-api-key": api_key}
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            voices = []
            if isinstance(data, dict) and "items" in data:
                voices = data["items"]
            elif isinstance(data, list):
                voices = data
            else:
                return False, [], f"ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. (items í‚¤ ì—†ìŒ: {list(data.keys())})"
            
            return True, voices, "âœ… ì—°ê²° ì„±ê³µ!"
            
        elif response.status_code == 401:
            return False, [], "âŒ API Keyê°€ í‹€ë ¸ìŠµë‹ˆë‹¤ (401)"
        elif response.status_code == 404:
            return False, [], f"âŒ ì£¼ì†Œ(URL) ì˜¤ë¥˜ (404). {base_url} ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        else:
            return False, [], f"âŒ ì„œë²„ ì˜¤ë¥˜ ({response.status_code}): {response.text}"
            
    except Exception as e:
        return False, [], f"âŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {str(e)}"

def generate_supertone_tts(api_key, voice_id, text, scene_num, base_url, speed=1.0, pitch=0):
    """Supertone APIë¥¼ ì‚¬ìš©í•´ TTS ì˜¤ë””ì˜¤ ìƒì„± ë° ì €ì¥"""
    
    # 1. í…ìŠ¤íŠ¸ ì •ê·œí™” (ìˆ«ì -> í•œê¸€)
    normalized_text = normalize_text_for_tts(text)

    # 2. ë§ˆì¹¨í‘œê°€ ìˆë“  ì—†ë“  ë¬´ì¡°ê±´ ë§ˆì¹¨í‘œ í•˜ë‚˜ ë” ì¶”ê°€í•˜ì—¬ í™•ì‹¤í•œ ëë§ºìŒ ìœ ë„
    normalized_text = normalized_text.strip() + "."

    base_url = base_url.rstrip('/')
    url = f"{base_url}/v1/text-to-speech/{voice_id}"
    
    headers = {
        "x-sup-api-key": api_key,
        "Content-Type": "application/json"
    }
    
    safe_text = normalized_text[:500] 
    
    payload = {
        "text": safe_text,
        "language": "ko",
        "model": "sona_speech_1",
        "voice_settings": {
            "speed": float(speed),
            "pitch_shift": int(pitch),
            "pitch_variance": 1
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, stream=True)
        
        if response.status_code == 200:
            filename = f"S{scene_num:03d}_audio.wav"
            full_path = os.path.join(AUDIO_OUTPUT_DIR, filename)
            
            # íŒŒì¼ ì €ì¥
            with open(full_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            
            # [KEY FIX] ë§ˆì´í¬ë¡œ í˜ì´ë“œ (Micro-Fade): ë 30msë§Œ ì‚´ì§ ì¤„ì—¬ì„œ íŠ€ëŠ” ì†Œë¦¬ ì œê±°
            try:
                saved_audio = AudioSegment.from_wav(full_path)
                
                if len(saved_audio) > 100:
                    # 0.03ì´ˆ(30ms)ë§Œ í˜ì´ë“œ ì•„ì›ƒ -> ë§ëì€ ì‚´ë¦¬ê³ , ê¸°ê³„ìŒ 'í‹±' ì†Œë¦¬ë§Œ ì œê±°
                    saved_audio = saved_audio.fade_out(30)
                    saved_audio.export(full_path, format="wav")
            except Exception as e:
                print(f"Audio tail fix error: {e}")

            return full_path
        elif response.status_code == 404:
            return "VOICE_NOT_FOUND"
        else:
            return f"Error ({response.status_code}): {response.text}"
            
    except Exception as e:
        return f"System Error: {e}"

def smart_shorten_silence(file_path, max_allowed_silence_ms=300, min_silence_len=100, silence_thresh=-40):
    try:
        audio = AudioSegment.from_wav(file_path)
        silence_ranges = detect_silence(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh
        )

        if not silence_ranges:
            return True, "ë¬´ìŒ êµ¬ê°„ ì—†ìŒ"

        output_audio = AudioSegment.empty()
        last_pos = 0

        for start, end in silence_ranges:
            output_audio += audio[last_pos:start]
            silence_duration = end - start
            if silence_duration > max_allowed_silence_ms:
                output_audio += AudioSegment.silent(duration=max_allowed_silence_ms)
            else:
                output_audio += audio[start:end]
            last_pos = end

        output_audio += audio[last_pos:]
        output_audio.export(file_path, format="wav")
        return True, "ì„±ê³µ"

    except Exception as e:
        return False, str(e)

def process_single_tts_task(api_key, voice_id, text, scene_num, base_url, speed, pitch, apply_silence_trim):
    audio_res = generate_supertone_tts(
        api_key, voice_id, text, scene_num, base_url, speed, pitch
    )
    if "Error" not in str(audio_res) and "VOICE_NOT_FOUND" not in str(audio_res):
        if apply_silence_trim:
            smart_shorten_silence(audio_res, max_allowed_silence_ms=300)
    return audio_res

# ==========================================
# [í•¨ìˆ˜] 5. ë¹„ë””ì˜¤ ìƒì„± (MoviePy - ê³ í™”ì§ˆ ì„¤ì •)
# ==========================================
def create_video_with_zoom(image_path, audio_path, output_dir, scene_num, is_zoom_in=True):
    """
    ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ í•©ì³ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì¤Œ íš¨ê³¼ ë¹„ë””ì˜¤ ìƒì„±.
    [ê³ í™”ì§ˆ ì„¤ì • ì ìš© ì™„ë£Œ]
    """
    try:
        output_filename = f"S{scene_num:03d}_video_zoom.mp4"
        output_path = os.path.join(output_dir, output_filename)
        
        audio_clip = AudioFileClip(audio_path)
        duration = audio_clip.duration
        
        original_pil = Image.open(image_path).convert("RGB")
        W, H = original_pil.size
        
        if W % 2 != 0: W -= 1
        if H % 2 != 0: H -= 1
        if original_pil.size != (W, H):
            original_pil = original_pil.resize((W, H), Image.LANCZOS)

        max_crop_ratio = 0.85 
        
        def effect(get_frame, t):
            progress = t / duration
            if is_zoom_in:
                current_ratio = 1.0 - (1.0 - max_crop_ratio) * progress
            else:
                current_ratio = max_crop_ratio + (1.0 - max_crop_ratio) * progress
            
            roi_w = W * current_ratio
            roi_h = H * current_ratio
            
            x0 = (W - roi_w) / 2
            y0 = (H - roi_h) / 2
            x1 = x0 + roi_w
            y1 = y0 + roi_h
            
            transformed_img = original_pil.transform(
                (W, H), 
                Image.EXTENT, 
                (x0, y0, x1, y1), 
                Image.BICUBIC 
            )
            return np.array(transformed_img)

        video = ImageClip(np.array(original_pil)).set_duration(duration).set_fps(30)
        video = video.fl(effect)
        video = video.set_audio(audio_clip)
        
        # [KEY FIX] ê³ í™”ì§ˆ ë Œë”ë§ ì„¤ì • (ë¹„íŠ¸ë ˆì´íŠ¸ 8000k, ì˜¤ë””ì˜¤ 192k, preset=slow)
        video.write_videofile(
            output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",        # ì˜ìƒ í™”ì§ˆ ëŒ€í­ í–¥ìƒ
            audio_bitrate="192k",   # ì˜¤ë””ì˜¤ ìŒì§ˆ í–¥ìƒ
            preset="slow",          # ì¸ì½”ë”© í’ˆì§ˆ í–¥ìƒ (ì†ë„ëŠ” ì¡°ê¸ˆ ëŠë ¤ì§)
            logger=None
        )
        
        return output_path
        
    except Exception as e:
        return f"Error: {e}"

def process_single_video_task(item, output_dir, is_zoom_in):
    if item.get('audio_path') and os.path.exists(item['audio_path']):
        return create_video_with_zoom(
            item['path'], 
            item['audio_path'], 
            output_dir, 
            item['scene'], 
            is_zoom_in=is_zoom_in
        )
    return None

def merge_all_videos(video_paths, output_dir):
    try:
        clips = []
        for path in video_paths:
            if path and os.path.exists(path):
                clips.append(VideoFileClip(path))
        
        if not clips:
            return "No clips to merge"

        final_clip = concatenate_videoclips(clips, method="compose")
        final_output_path = os.path.join(output_dir, "FINAL_FULL_VIDEO.mp4")
        
        # [KEY FIX] ë³‘í•© ì‹œì—ë„ ê³ í™”ì§ˆ ìœ ì§€
        final_clip.write_videofile(
            final_output_path, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k",
            audio_bitrate="192k",
            preset="slow",
            logger=None
        )
        return final_output_path
    except Exception as e:
        return f"Merge Error: {e}"

# ==========================================
# [UI] ì‚¬ì´ë“œë°” (ìë™ ë¡œê·¸ì¸ + ì¥ë¥´ ì„ íƒ ì ìš©)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ í™˜ê²½ ì„¤ì •")

    # 1. Google API Key ì„¤ì • (ë©€í‹° API ì§€ì›)
    st.subheader("ğŸ”‘ API í‚¤ ì„¤ì •")

    # API í‚¤ ê°œìˆ˜ ì„ íƒ ë“œë¡­ë°•ìŠ¤
    num_api_keys = st.selectbox(
        "API í‚¤ ê°œìˆ˜",
        options=[1, 2, 3, 4],
        index=0,
        help="ì—¬ëŸ¬ API í‚¤ë¥¼ ì‚¬ìš©í•˜ë©´ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë” ë¹ ë¥´ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í‚¤ë‹¹ ë¶„ë‹¹ 20ê°œ)"
    )

    # API í‚¤ ì…ë ¥ í•„ë“œë“¤
    api_keys = []

    # secrets.tomlì—ì„œ ìë™ ë¡œë“œ ì‹œë„
    for i in range(num_api_keys):
        secret_key = f"google_api_key_{i+1}" if i > 0 else "google_api_key"

        if "general" in st.secrets and secret_key in st.secrets["general"]:
            key = st.secrets["general"][secret_key]
            st.success(f"ğŸ”‘ API Key {i+1} ë¡œë“œë¨")
            api_keys.append(key)
        else:
            key = st.text_input(
                f"ğŸ”‘ Google API Key {i+1}" if num_api_keys > 1 else "ğŸ”‘ Google API Key",
                type="password",
                key=f"api_key_{i}",
                help=f"API í‚¤ {i+1}ë²ˆì„ ì…ë ¥í•˜ì„¸ìš”."
            )
            if key:
                api_keys.append(key)

    # í˜¸í™˜ì„±ì„ ìœ„í•´ ì²« ë²ˆì§¸ í‚¤ë¥¼ api_keyë¡œë„ ì €ì¥
    api_key = api_keys[0] if api_keys else ""

    if num_api_keys > 1 and len(api_keys) == num_api_keys:
        st.info(f"âœ… {num_api_keys}ê°œ API í‚¤ ì„¤ì •ë¨ â†’ ë¶„ë‹¹ ìµœëŒ€ {num_api_keys * 20}ê°œ ìƒì„± ê°€ëŠ¥")

    st.markdown("---")
    
    st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ëª¨ë¸ ì„ íƒ")
    model_choice = st.radio("ì‚¬ìš©í•  AI ëª¨ë¸:", ("Premium (Gemini 3 Pro)", "Fast (Gemini-2.5-pro)"), index=0)
    
    if "Gemini 3 Pro" in model_choice:
        SELECTED_IMAGE_MODEL = "gemini-3-pro-image-preview" 
    else:
        SELECTED_IMAGE_MODEL = "gemini-2.5-pro"

    st.info(f"âœ… ì„ íƒ ëª¨ë¸: `{SELECTED_IMAGE_MODEL}`")
    
    st.markdown("---")
    st.subheader("ğŸ“ ëŒ€ë³¸ ë¶„í•  ì•ˆë‚´")
    st.info("ëŒ€ë³¸ì„ ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• í•´ì„œ ì…ë ¥í•˜ì„¸ìš”. ê° ë²ˆí˜¸ê°€ í•˜ë‚˜ì˜ ì”¬ì´ ë©ë‹ˆë‹¤.") 
    
    st.markdown("---")

    # [NEW] ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ì–¸ì–´ ì„ íƒ
    st.subheader("ğŸŒ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì–¸ì–´")
    target_language = st.selectbox(
        "ì´ë¯¸ì§€ ì†ì— ë“¤ì–´ê°ˆ ê¸€ì ì–¸ì–´:",
        ("Korean", "English", "Japanese"),
        index=0,
        help="ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ì—°ì¶œë  ë•Œ ì–´ë–¤ ì–¸ì–´ë¡œ ì ì„ì§€ ì„ íƒí•©ë‹ˆë‹¤."
    )

    st.markdown("---")

    # ==========================================
    # [NEW] ì»¨ì…‰ë³„ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ì‹œìŠ¤í…œ
    # ==========================================
    # [ìˆ˜ì •ë¨] Gems ìŠ¤íƒ€ì¼ + Context-Aware Visual Guide
    STYLE_PRESETS = {
        "ê²½ì œí•™": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Success/Business:* "Bright White Studio", "Sunny Day", "Warm Golden Light".
    - *Crisis/Sadness:* "Grey Cloudy Daylight", "Dim Indoor Light" (NOT pitch black), "Cold Blue Tint" (keep it bright enough to see).
    - *News:* "Bright TV Studio Lighting".

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: Business/Partnership (e.g., M&A, Deals)**
   - **Background:** Bright conference room, stage with handshake, modern office.
   - **Extras:** A few other stickmen (reporters, investors) in the background.
   - **Text Integration:** Place text on **podiums**, **company flags**, **shirt labels**, or **large presentation screens**.

2. **Scenario: Economic Crisis/Failure (e.g., Collapse, Despair)**
   - **Background:** Grey cloudy city, dim office, rainy street (NOT pitch black).
   - **Extras:** Usually solo, or with a few sad figures in the distance.
   - **Text Integration:** Place text on **broken neon signs**, **cracked walls**, **graffiti**, or **scattered papers**.

3. **Scenario: Market/Public Reaction (e.g., Trends, Opinions)**
   - **Background:** Public spaces like streets, stock market floors, or online communities.
   - **Extras:** **Crowd of anonymous stickmen** showing reactions (angry, confused, cheering).
   - **Text Integration:** Text on **protest signs**, **thought bubbles above crowds**, **stock ticker boards**.

4. **Scenario: News/Announcement**
   - **Background:** Cozy living room with TV, or a bright news studio desk.
   - **Extras:** None (focus on TV) or a news anchor.
   - **Text Integration:** Text inside a **"Breaking News" banner on a TV screen**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on TV Screen, Presentation Slide, Labels on Shirt, Neon Sign with clean border.

[Costume & Role]
- CEO: ë„¤ì´ë¹„ ì •ì¥, ë¹¨ê°„ ë„¥íƒ€ì´ / ê°€ë‚œí•œ ì‚¬ëŒ: ë‚¡ì€ íšŒìƒ‰ ê°€ë””ê±´
- ì§ì¥ì¸: ì™€ì´ì…”ì¸ , ë¸”ë¼ìš°ìŠ¤ / ë¶€ì: ê¸ˆìƒ‰ ì•¡ì„¸ì„œë¦¬

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
""",
        "ì—­ì‚¬": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Victory/Coronation:* "Bright Golden Sunlight", "Warm Throne Room Light".
    - *Battle/War:* "Smoky but Visible Daylight", "Orange Firelight" (NOT pitch black).
    - *Tragedy:* "Grey Cloudy Sky", "Dim Candlelight" (keep it bright enough to see).

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: War/Battle**
   - **Background:** Smoky battlefield with visible sky, siege walls, army camps.
   - **Extras:** **Army of stickmen soldiers** in the background, fallen warriors.
   - **Text Integration:** Text on **war flags**, **shield emblems**, **banners**.

2. **Scenario: Royal/Palace**
   - **Background:** Bright throne room with golden decorations, sunny royal garden.
   - **Extras:** Servants, guards, nobles in the background.
   - **Text Integration:** Text on **royal seals**, **scrolls**, **throne inscriptions**.

3. **Scenario: Revolution/Uprising**
   - **Background:** Town square at dusk (visible), palace gates with torchlight.
   - **Extras:** **Angry crowd of stickmen** with torches and pitchforks.
   - **Text Integration:** Text on **protest banners**, **wanted posters**, **graffiti on walls**.

4. **Scenario: Historical Event/Moment**
   - **Background:** Iconic historical setting with clear lighting (signing ceremony, coronation).
   - **Extras:** Witnesses, historians, important figures.
   - **Text Integration:** Text on **documents**, **stone tablets**, **flags**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on Banners, Royal Seals, Stone Tablets, War Flags.

[Costume & Role - ì—­ì‚¬ ì˜ìƒ]
- ì¡°ì„ : í•œë³µ, ê°“ / ë¡œë§ˆ: í† ê°€, ê°‘ì˜· / ì¤‘ì„¸: ê°‘ì˜·, ì™•ê´€, ë“œë ˆìŠ¤
- ì™•ì¡±: ê¸ˆìƒ‰ ì¥ì‹, ì™•ê´€ / ë†ë¯¼: ì†Œë°•í•œ ì˜· / ì „ì‚¬: ë¬´ê¸°ì™€ ê°‘ì˜·

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
""",
        "ê³¼í•™": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Lab/Research:* "Bright White Lab Lighting", "Clean Fluorescent Light".
    - *Space:* "Starry but Visible Space", "Bright Spaceship Interior" (NOT pitch black void).
    - *Disaster:* "Red Warning Lights with Visible Background", "Smoky but Lit Lab".

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: Discovery/Breakthrough**
   - **Background:** Bright clean laboratory, research facility, eureka moment setting.
   - **Extras:** Research team stickmen celebrating or observing.
   - **Text Integration:** Text on **computer monitors**, **hologram displays**, **scientific charts**.

2. **Scenario: Space/Exploration**
   - **Background:** Starry cosmos with visible elements, bright spaceship interior, alien planet with clear sky.
   - **Extras:** Astronaut crew, mission control stickmen on screens.
   - **Text Integration:** Text on **spaceship consoles**, **mission patches**, **floating HUD**.

3. **Scenario: Disaster/Failure**
   - **Background:** Lab with warning lights (visible), malfunctioning equipment, smoky but lit scene.
   - **Extras:** Panicking scientists, evacuation scenes.
   - **Text Integration:** Text on **warning signs**, **error screens**, **scattered papers**.

4. **Scenario: Future/Technology**
   - **Background:** Bright futuristic city, glowing cyber world, well-lit high-tech facility.
   - **Extras:** Robots, AI interfaces, holographic beings.
   - **Text Integration:** Text as **hologram UI**, **laser projections**, **digital billboards**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on Computer Monitors, Hologram UI, Digital Billboards, Warning Signs.

[Costume & Role - ê³¼í•™ ì˜ìƒ]
- ê³¼í•™ì: í° ê°€ìš´, ë³´ì•ˆê²½ / ì˜ì‚¬: ìˆ˜ìˆ ë³µ, ì²­ì§„ê¸°
- ìš°ì£¼ë¹„í–‰ì‚¬: ìš°ì£¼ë³µ / ì—”ì§€ë‹ˆì–´: ì‘ì—…ë³µ, ì•ˆì „ëª¨

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
""",
        "ì»¤ìŠ¤í…€ (ì§ì ‘ ì…ë ¥)": """
[Core Identity]
- Character: "White circle-faced stickman" with PURE WHITE body and limbs.
- Face Style: Minimalist white round head with eyes and mouth.
- **Critical Rule:** Character MUST have EYES and MOUTH.

[Lighting & Background Guide - BRIGHT & CLEAR]
- **General Tone:** ALWAYS use **Bright, Clear, and Visible** lighting.
- **Avoid:** Pitch black darkness, heavy shadows, or muddy colors.
- **Scenario Lighting:**
    - *Positive/Success:* "Bright White Studio", "Sunny Day", "Warm Golden Light".
    - *Negative/Sad:* "Grey Cloudy Daylight", "Dim Indoor Light" (NOT pitch black).
    - *News:* "Bright TV Studio Lighting".

[Context-Aware Visual Guide (Crucial)]
1. **Scenario: Business/Partnership**
   - **Background:** Bright conference room, stage, modern office.
   - **Extras:** Other stickmen (reporters, investors) in the background.
   - **Text Integration:** Text on **podiums**, **flags**, **shirt labels**, **screens**.

2. **Scenario: Crisis/Failure**
   - **Background:** Grey cloudy scene, dim office, rainy street (NOT pitch black).
   - **Extras:** Solo, or with sad figures in the distance.
   - **Text Integration:** Text on **broken signs**, **cracked walls**, **graffiti**.

3. **Scenario: Public Reaction**
   - **Background:** Bright public spaces, streets, gathering places.
   - **Extras:** **Crowd of stickmen** showing reactions.
   - **Text Integration:** Text on **signs**, **thought bubbles**, **ticker boards**.

4. **Scenario: News/Announcement**
   - **Background:** Bright living room with TV, or well-lit news studio.
   - **Extras:** None or news anchor.
   - **Text Integration:** Text on **TV screen banner**.

[Text Object Integration (Limit 2-3 Keywords)]
- **QUANTITY RULE:** Strictly limit text to **2-3 CORE KEYWORDS** per scene. Do not use long sentences or too many tags.
- **Readability:** Text must have a **CLEAN OUTLINE**.
- **Placement:** Text on TV Screen, Signs, Banners, Shirt Labels.

[Costume & Role]
- ê° ìºë¦­í„°ì˜ ì§ì—…/ì—­í• ì— ë§ëŠ” ì»¬ëŸ¬í’€í•˜ê³  íŠ¹ì§•ì ì¸ ì˜ìƒ

[Face Expression Guide]
- Use simple cartoon eyes and mouths to clearly show emotions.
"""
    }

    st.subheader("ğŸ¨ ì»¨ì…‰ ì„ íƒ")

    # ì»¨ì…‰ ì„ íƒ ë“œë¡­ë°•ìŠ¤
    selected_style_version = st.selectbox(
        "ì»¨ì…‰ í”„ë¦¬ì…‹",
        list(STYLE_PRESETS.keys()),
        index=0,
        help="ì»¨ì…‰ë³„ë¡œ ìµœì í™”ëœ ìŠ¤íƒ€ì¼ì´ ì ìš©ë©ë‹ˆë‹¤."
    )

    # ì„ íƒëœ í”„ë¦¬ì…‹ ê°€ì ¸ì˜¤ê¸°
    default_style = STYLE_PRESETS[selected_style_version]

    style_instruction = st.text_area("AIì—ê²Œ ì§€ì‹œí•  ê·¸ë¦¼ ìŠ¤íƒ€ì¼", value=default_style.strip(), height=150)
    st.markdown("---")

    max_workers = st.slider("ì‘ì—… ì†ë„(ë³‘ë ¬ ìˆ˜)", 1, 10, 5)

    # [TTS ë¹„í™œì„±í™”] Supertone TTS ì„¤ì • ì œê±°ë¨ - ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹„í™œì„±í™”
    supertone_api_key = ""
    supertone_base_url = DEFAULT_SUPERTONE_URL
    selected_voice_id = ""
    tts_speed = 1.0
    tts_pitch = 0

# ==========================================
# [ìˆ˜ì •ëœ UI] ë©”ì¸ í™”ë©´: ì´ë¯¸ì§€ ìƒì„±
# ==========================================
st.divider()
st.title("ğŸ–¼ï¸ ì”¬ë³„ ì´ë¯¸ì§€ ìƒì„±")
st.caption(f"ë²ˆí˜¸(1. 2. 3.)ë¡œ ë¶„í• ëœ ëŒ€ë³¸ì„ ë„£ìœ¼ë©´ ê° ì”¬ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. | ğŸ¨ Model: {SELECTED_IMAGE_MODEL}")

st.subheader("ğŸ“Œ ì „ì²´ ì˜ìƒ í…Œë§ˆ(ì œëª©) ì„¤ì •")
st.caption("ì´ë¯¸ì§€ ìƒì„± ì‹œ ì´ ì œëª©ì´ 'ì „ì²´ì ì¸ ë¶„ìœ„ê¸° ê¸°ì¤€'ì´ ë©ë‹ˆë‹¤.")

if 'video_title' not in st.session_state:
    st.session_state['video_title'] = ""
if 'title_candidates' not in st.session_state:
    st.session_state['title_candidates'] = []

col_title_input, col_title_btn = st.columns([4, 1])

# [ìˆ˜ì •ë¨] ë²„íŠ¼ ë¡œì§: ì œëª© ì…ë ¥ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ
with col_title_btn:
    st.write("")
    st.write("")
    if st.button("ğŸ’¡ ì œëª© 5ê°œ ì¶”ì²œ", help="ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.", use_container_width=True):
        current_user_title = st.session_state.get('video_title', "").strip()

        if not api_key:
            st.error("API Key í•„ìš”")
        elif not current_user_title:
            st.warning("âš ï¸ ë¨¼ì € 'ì£¼ì œ'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            client = genai.Client(api_key=api_key)
            with st.spinner("AIê°€ ìµœì ì˜ ì œëª©ì„ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
                title_prompt = f"""
                [Role] You are a YouTube viral marketing expert.
                [Target Topic]
                "{current_user_title}"
                [Task]
                Generate 5 click-bait YouTube video titles based on the Target Topic above.
                ì‚¬ìš©ìê°€ ì…ë ¥í•œê±°ë‘ ìµœëŒ€í•œ ë¹„ìŠ·í•œ ì œëª©ìœ¼ë¡œ ì¶”ì²œ, 'ëª°ë½'ì´ ë“¤ì–´ê°„ ê²½ìš° ë§¨ ë’¤ì— ëª°ë½ìœ¼ë¡œ ëë‚˜ê²Œ í•œë‹¤.

                [Output Format]
                - Output ONLY the list of 5 titles.
                - No numbering (1., 2.), just 5 lines of text.
                - Language: Korean
                """

                try:
                    resp = client.models.generate_content(
                        model=GEMINI_TEXT_MODEL_NAME,
                        contents=title_prompt
                    )
                    candidates = [line.strip() for line in resp.text.split('\n') if line.strip()]
                    clean_candidates = []
                    import re
                    for c in candidates:
                        clean = re.sub(r'^\d+\.\s*', '', c).replace('*', '').replace('"', '').strip()
                        if clean: clean_candidates.append(clean)

                    st.session_state['title_candidates'] = clean_candidates[:5]
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

with col_title_input:
    st.text_input(
        "ì˜ìƒ ì œëª© (ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìš°ì¸¡ ë²„íŠ¼ìœ¼ë¡œ ì¶”ì²œë°›ìœ¼ì„¸ìš”)",
        key="video_title", 
        placeholder="ì œëª© í˜¹ì€ ë§Œë“¤ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¶€ìë“¤ì˜ ìŠµê´€)"
    )

if st.session_state['title_candidates']:
    st.info("ğŸ‘‡ AIê°€ ì¶”ì²œí•œ ì œëª©ì…ë‹ˆë‹¤. í´ë¦­í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤.")

    def apply_title(new_title):
        st.session_state['video_title'] = new_title
        st.session_state['title_candidates'] = [] 

    for idx, title in enumerate(st.session_state['title_candidates']):
        col_c1, col_c2 = st.columns([4, 1])
        with col_c1:
            st.markdown(f"**{idx+1}. {title}**")
        with col_c2:
            st.button(
                "âœ… ì„ íƒ", 
                key=f"sel_title_{idx}", 
                on_click=apply_title, 
                args=(title,), 
                use_container_width=True
            )
    
    if st.button("âŒ ëª©ë¡ ë‹«ê¸°"):
        st.session_state['title_candidates'] = []

if 'section_scripts' in st.session_state and st.session_state['section_scripts']:
    intro_text_acc = ""
    main_text_acc = ""
    for title_key, text in st.session_state['section_scripts'].items():
        if "Intro" in title_key or "ë„ì…ë¶€" in title_key:
            intro_text_acc += text + "\n\n"
        else:
            main_text_acc += text + "\n\n"
            
    st.write("ğŸ‘‡ **ìƒì„±ëœ ëŒ€ë³¸ ê°€ì ¸ì˜¤ê¸° (í´ë¦­ ì‹œ ì•„ë˜ ì…ë ¥ì°½ì— ì±„ì›Œì§‘ë‹ˆë‹¤)**")
    
    col_get1, col_get2 = st.columns(2)
    if "image_gen_input" not in st.session_state:
        st.session_state["image_gen_input"] = ""

    with col_get1:
        if st.button("ğŸ“¥ ì¸íŠ¸ë¡œ(Intro)ë§Œ ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = intro_text_acc.strip()
            st.rerun()
    with col_get2:
        if st.button("ğŸ“¥ ë³¸ë¡ (Chapters) + ê²°ë¡ (Epilogue) ê°€ì ¸ì˜¤ê¸°", use_container_width=True):
            st.session_state["image_gen_input"] = main_text_acc.strip()
            st.rerun()

# ==========================================
# [UI] ë©”ì¸ í™”ë©´: ëŒ€ë³¸ ì…ë ¥ ë° AI ì”¬ ë¶„í• 
# ==========================================
st.divider()
st.subheader("ğŸ“œ ëŒ€ë³¸ ì…ë ¥ (AI ìë™ ë¶„í• )")
st.caption("ëŒ€ë³¸ ì „ì²´ë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”. AIê°€ ë¬¸ë§¥ì— ë§ì¶° ìë™ìœ¼ë¡œ ì”¬ì„ ë‚˜ëˆ ì¤ë‹ˆë‹¤.")

col_input_opt, col_input_txt = st.columns([1, 3])

with col_input_opt:
    st.info("â±ï¸ ì”¬ ë¶„í•  ì„¤ì •")
    scene_duration = st.slider(
        "í•œ ì”¬ë‹¹ ëª©í‘œ ê¸€ììˆ˜",
        min_value=100,
        max_value=300,
        value=200,
        step=10,
        help="AIê°€ ë¬¸ë§¥ì„ íŒŒì•…í•˜ì—¬ ì´ ê¸¸ì´ ê·¼ì²˜ì—ì„œ ì”¬ì„ ë‚˜ëˆ•ë‹ˆë‹¤. ë¬¸ì¥ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•ŠìŠµë‹ˆë‹¤."
    )
    st.caption(f"ì•½ {scene_duration}ì = ì•½ {scene_duration // 6}ì´ˆ ë¶„ëŸ‰")

with col_input_txt:
    script_input = st.text_area(
        "ì „ì²´ ëŒ€ë³¸ ë¶™ì—¬ë„£ê¸°",
        height=300,
        placeholder="ëŒ€ë³¸ì„ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”. AIê°€ ë¬¸ë§¥ì„ íŒŒì•…í•´ ìë™ìœ¼ë¡œ ì”¬ì„ ë‚˜ëˆ•ë‹ˆë‹¤.\n\nì˜ˆì‹œ:\nì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ ê²½ì œ ìœ„ê¸°ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ë³´ë ¤ í•©ë‹ˆë‹¤. ìµœê·¼ ë‰´ìŠ¤ë¥¼ ë³´ë©´ ë§ì€ ê¸°ì—…ë“¤ì´ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ìœ„ê¸° ì†ì—ì„œë„ ê¸°íšŒë¥¼ ì°¾ëŠ” ì‚¬ëŒë“¤ì´ ìˆì£ . ì´ëŸ° ìƒí™©ì—ì„œ ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?",
        key="image_gen_input"
    )

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'generated_results' not in st.session_state:
    st.session_state['generated_results'] = []
if 'is_processing' not in st.session_state:
    st.session_state['is_processing'] = False
if 'split_scenes' not in st.session_state:
    st.session_state['split_scenes'] = []

# ==========================================
# [NEW] ì”¬ ë¶„í•  ë¯¸ë¦¬ë³´ê¸° (ì´ë¯¸ì§€ ìƒì„± ì „ í™•ì¸)
# ==========================================
col_split_btn, col_gen_btn = st.columns(2)

with col_split_btn:
    split_btn = st.button("âœ‚ï¸ ì”¬ ë¶„í•  ë¯¸ë¦¬ë³´ê¸°", type="secondary", use_container_width=True)

with col_gen_btn:
    def clear_generated_results():
        st.session_state['generated_results'] = []
    start_btn = st.button("ğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘", type="primary", use_container_width=True, on_click=clear_generated_results)

# [ì”¬ ë¶„í•  ë¯¸ë¦¬ë³´ê¸° ì²˜ë¦¬]
if split_btn:
    if not api_key:
        st.error("âš ï¸ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not script_input:
        st.warning("âš ï¸ ëŒ€ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ğŸ§  AIê°€ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì”¬ì„ ë‚˜ëˆ„ëŠ” ì¤‘..."):
            preview_client = genai.Client(api_key=api_key)
            st.session_state['split_scenes'] = split_text_automatically(preview_client, script_input, target_chars=scene_duration)
        st.success(f"âœ… ì´ {len(st.session_state['split_scenes'])}ê°œ ì”¬ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

# [ë¶„í• ëœ ì”¬ í‘œì‹œ]
if st.session_state.get('split_scenes'):
    st.subheader("ğŸ¬ ì”¬ ë¶„í•  ê²°ê³¼ (ë¯¸ë¦¬ë³´ê¸°)")
    for idx, scene_text in enumerate(st.session_state['split_scenes']):
        with st.expander(f"Scene {idx + 1} ({len(scene_text)}ì)", expanded=False):
            st.text_area(
                f"ì”¬ {idx + 1} ëŒ€ë³¸",
                value=scene_text,
                height=100,
                key=f"scene_preview_{idx}",
                disabled=True
            )

st.divider()

# [ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬]
if start_btn:
    if not api_key:
        st.error("âš ï¸ Google API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif not script_input:
        st.warning("âš ï¸ ëŒ€ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # ê¸°ì¡´ ê²°ê³¼ ì´ˆê¸°í™”
        st.session_state['generated_results'] = []
        st.session_state['is_processing'] = True

        # ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚­ì œ
        if os.path.exists(IMAGE_OUTPUT_DIR):
            shutil.rmtree(IMAGE_OUTPUT_DIR)
        init_folders()

        # [ë©€í‹° API ì§€ì›] ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        clients = []
        for key in api_keys:
            clients.append(genai.Client(api_key=key))

        # ë©”ì¸ í´ë¼ì´ì–¸íŠ¸ (AI ë¶„í• ìš©)
        client = clients[0] if clients else genai.Client(api_key=api_key)

        status_box = st.status("ì‘ì—… ì§„í–‰ ì¤‘...", expanded=True)
        progress_bar = st.progress(0)

        # -------------------------------------------------------
        # [í•µì‹¬] AIê°€ ë¬¸ë§¥ì„ íŒŒì•…í•˜ì—¬ ì”¬ ë¶„í• 
        # -------------------------------------------------------
        status_box.write(f"ğŸ§  AIê°€ ëŒ€ë³¸ ì „ì²´ ë§¥ë½ì„ ì½ê³  ì”¬ì„ ë‚˜ëˆ„ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ê¸°ì¤€: ì•½ {scene_duration}ì)")

        # [ë³€ê²½ì ] client ì¸ì ì¶”ê°€
        chunks = split_text_automatically(client, script_input, target_chars=scene_duration)
        total_scenes = len(chunks)

        if total_scenes == 0:
            status_box.update(label="âš ï¸ ë¶„í•  ì‹¤íŒ¨.", state="error")
            st.stop()

        status_box.write(f"âœ… AI ë¶„ì„ ì™„ë£Œ: ì´ {total_scenes}ê°œì˜ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë¶„í• ëœ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ” ë¶„í• ëœ ì”¬ ë‚´ìš© í™•ì¸í•˜ê¸°", expanded=False):
            for idx, chunk in enumerate(chunks):
                st.caption(f"**Scene {idx+1}** ({len(chunk)}ì): {chunk[:80]}...")

        # [ë§¥ë½ ì£¼ì…] ì˜ìƒ ì œëª©ì´ ì—†ë‹¤ë©´ ì²« ë¬¸ì¥ìœ¼ë¡œ ëŒ€ì²´
        current_video_title = st.session_state.get('video_title', "").strip()
        if not current_video_title:
            current_video_title = f"Context: {script_input[:200]}..."

        # -------------------------------------------------------
        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± (ë³‘ë ¬) - ê¸°ì¡´ ë¡œì§ ìœ ì§€
        # -------------------------------------------------------
        status_box.write(f"ğŸ“ ì”¬ë³„ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì¤‘ ({GEMINI_TEXT_MODEL_NAME})...")
        prompts = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []

            for i, chunk in enumerate(chunks):
                futures.append(executor.submit(
                    generate_prompt,
                    api_key,
                    i,
                    chunk,
                    style_instruction,
                    current_video_title,
                    target_language
                ))

            for i, future in enumerate(as_completed(futures)):
                prompts.append(future.result())
                progress_bar.progress((i + 1) / (total_scenes * 2))

        prompts.sort(key=lambda x: x[0])

        # 3. ì´ë¯¸ì§€ ìƒì„± (ë©€í‹° API ë³‘ë ¬ ì²˜ë¦¬)
        num_clients = len(clients)
        total_rate_limit = num_clients * 20  # ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜ (í‚¤ë‹¹ 20ê°œ)

        if num_clients > 1:
            status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL}) - {num_clients}ê°œ API ë³‘ë ¬ ì²˜ë¦¬ (ë¶„ë‹¹ ìµœëŒ€ {total_rate_limit}ê°œ)")
        else:
            status_box.write(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ({SELECTED_IMAGE_MODEL})... (API ë³´í˜¸ë¥¼ ìœ„í•´ ì²œì²œíˆ ì§„í–‰ë©ë‹ˆë‹¤)")

        results = []

        # [ë©€í‹° API] API í‚¤ ê°œìˆ˜ì— ë”°ë¼ worker ìˆ˜ì™€ ëŒ€ê¸° ì‹œê°„ ì¡°ì ˆ (ì•ˆì •ì„± ê°•í™”)
        # í‚¤ 1ê°œ: 4ì´ˆ ê°„ê²© (ë¶„ë‹¹ 15ê°œ, ì•ˆì „ ë§ˆì§„)
        # í‚¤ 2ê°œ: 3ì´ˆ ê°„ê²© (ë¶„ë‹¹ 20ê°œ x 2 = 40ê°œ ê°€ëŠ¥í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ)
        # í‚¤ 3ê°œ: 2ì´ˆ ê°„ê²©
        # í‚¤ 4ê°œ: 1.5ì´ˆ ê°„ê²©
        sleep_interval = max(4.0 / num_clients, 1.5)  # ìµœì†Œ 1.5ì´ˆ ë³´ì¥
        adjusted_workers = min(max_workers, num_clients * 3)  # API í‚¤ë‹¹ 3ê°œ workerë¡œ ì¶•ì†Œ

        with ThreadPoolExecutor(max_workers=adjusted_workers) as executor:
            future_to_meta = {}
            request_count = 0

            for s_num, prompt_text in prompts:
                idx = s_num - 1
                orig_text = chunks[idx]
                fname = make_filename(s_num, orig_text)

                # [ë¼ìš´ë“œ ë¡œë¹ˆ] í´ë¼ì´ì–¸íŠ¸ ìˆœí™˜ ë°°ì •
                current_client = clients[request_count % num_clients]

                # [ì†ë„ ì¡°ì ˆ] API í‚¤ ê°œìˆ˜ì— ë§ì¶° ëŒ€ê¸°
                time.sleep(sleep_interval)

                # [80ê°œ ì œí•œ] ë©€í‹° API ì‚¬ìš© ì‹œ 80ê°œë§ˆë‹¤ 1ë¶„ ëŒ€ê¸°
                if num_clients > 1 and request_count > 0 and request_count % total_rate_limit == 0:
                    status_box.write(f"â³ API ì œí•œ ë³´í˜¸: {request_count}ê°œ ì™„ë£Œ, 60ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(60)

                future = executor.submit(generate_image, current_client, prompt_text, fname, IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL)
                future_to_meta[future] = (s_num, fname, orig_text, prompt_text)
                request_count += 1
            
            # ê²°ê³¼ ìˆ˜ì§‘
            completed_cnt = 0
            for future in as_completed(future_to_meta):
                s_num, fname, orig_text, p_text = future_to_meta[future]
                path = future.result()
                
                # [í•µì‹¬] ì‹¤íŒ¨(None)í•˜ë”ë¼ë„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì—ëŠ” ë„£ì–´ì„œ ìˆœì„œê°€ ë°€ë¦¬ì§€ ì•Šê²Œ í•¨ (ì›í•œë‹¤ë©´ ì—ëŸ¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥)
                if path:
                    results.append({
                        "scene": s_num,
                        "path": path,
                        "filename": fname,
                        "script": orig_text,
                        "prompt": p_text,
                        "audio_path": None,
                        "video_path": None 
                    })
                else:
                    # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë„˜ì–´ê°€ê±°ë‚˜, ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì„ ìˆ˜ë„ ìˆìŒ
                    st.error(f"Scene {s_num} ì´ë¯¸ì§€ ìƒì„± ìµœì¢… ì‹¤íŒ¨.")

                completed_cnt += 1
                progress_bar.progress(0.5 + (completed_cnt / total_scenes * 0.5))
        
        results.sort(key=lambda x: x['scene'])
        st.session_state['generated_results'] = results
        
        status_box.update(label="âœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", state="complete", expanded=False)
        st.session_state['is_processing'] = False
        
# ==========================================
# [ìˆ˜ì •ë¨] ê²°ê³¼ì°½ ë° ê°œë³„ ì¬ìƒì„± ê¸°ëŠ¥ ì¶”ê°€
# ==========================================
if st.session_state['generated_results']:
    st.divider()
    st.header(f"ğŸ“¸ ê²°ê³¼ë¬¼ ({len(st.session_state['generated_results'])}ì¥)")
    
    # ------------------------------------------------
    # 1. ì¼ê´„ ì‘ì—… ë²„íŠ¼ ì˜ì—­
    # ------------------------------------------------
    st.write("---")
    st.subheader("âš¡ ì›í´ë¦­ ì¼ê´„ ìƒì„± ì‘ì—…")
    
    c_btn1, c_btn2, c_btn3, c_btn4 = st.columns(4)
    
    with c_btn1:
        zip_data = create_zip_buffer(IMAGE_OUTPUT_DIR)
        st.download_button("ğŸ“¦ ì „ì²´ ì´ë¯¸ì§€ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_data, file_name="all_images.zip", mime="application/zip", use_container_width=True)

    # TTS ì „ì²´ ìƒì„±
    with c_btn2:
        tts_batch_mode = st.selectbox("TTS ìƒì„± ëª¨ë“œ", ["ì›ë³¸ ìŒì„± ìƒì„±", "ë¬´ìŒ ì¡°ì ˆ ìŒì„± (ìµœëŒ€ 0.3ì´ˆ)"], help="ë¬´ìŒ ì¡°ì ˆ ì„ íƒ ì‹œ ê³µë°± ìë™ ì¶•ì†Œ")
        if st.button("ğŸ”Š TTS ì¼ê´„ ìƒì„±", use_container_width=True):
            if not supertone_api_key or not selected_voice_id:
                st.error("ì‚¬ì´ë“œë°”ì—ì„œ API Keyì™€ ëª©ì†Œë¦¬ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            else:
                # ì˜¤ë””ì˜¤ ë³€ê²½ ì‹œ í†µí•©ë³¸ ì‚­ì œ
                final_merged_file = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
                if os.path.exists(final_merged_file):
                    try: os.remove(final_merged_file)
                    except: pass

                status_box = st.status("ğŸ™ï¸ TTS ì¼ê´„ ìƒì„± ì¤‘...", expanded=True)
                progress_bar = status_box.progress(0)
                
                apply_trim = (tts_batch_mode == "ë¬´ìŒ ì¡°ì ˆ ìŒì„± (ìµœëŒ€ 0.3ì´ˆ)")
                total_files = len(st.session_state['generated_results'])
                completed_cnt = 0
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_idx = {}
                    for i, item in enumerate(st.session_state['generated_results']):
                        future = executor.submit(
                            process_single_tts_task, supertone_api_key, selected_voice_id, 
                            item['script'], item['scene'], supertone_base_url, 
                            tts_speed, tts_pitch, apply_trim
                        )
                        future_to_idx[future] = i
                    
                    for future in as_completed(future_to_idx):
                        idx = future_to_idx[future]
                        try:
                            result_path = future.result()
                            if "Error" not in str(result_path) and "VOICE_NOT_FOUND" not in str(result_path):
                                st.session_state['generated_results'][idx]['audio_path'] = result_path
                                st.session_state['generated_results'][idx]['video_path'] = None # ë¹„ë””ì˜¤ ë¦¬ì…‹
                            else:
                                st.write(f"âš ï¸ Scene {idx+1} ì˜¤ë¥˜: {result_path}")
                        except Exception as e:
                            st.write(f"âš ï¸ Scene {idx+1} ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                        
                        completed_cnt += 1
                        progress_bar.progress(completed_cnt / total_files)
                
                status_box.update(label="âœ… TTS ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
                time.sleep(1)
                st.rerun()

    # ë¹„ë””ì˜¤ ì „ì²´ ìƒì„±
    with c_btn3:
        has_audio = any(item.get('audio_path') for item in st.session_state['generated_results'])
        if st.button("ğŸ¬ ë¹„ë””ì˜¤ ì „ì²´ ì¼ê´„ ìƒì„±", disabled=not has_audio, use_container_width=True):
            final_merged_file = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
            if os.path.exists(final_merged_file):
                try: os.remove(final_merged_file)
                except: pass
            
            status_box = st.status("ğŸ¬ ë¹„ë””ì˜¤ ë Œë”ë§ ì¤‘...", expanded=True)
            progress_bar = status_box.progress(0)
            
            total_files = len(st.session_state['generated_results'])
            completed_cnt = 0
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_idx = {}
                for i, item in enumerate(st.session_state['generated_results']):
                    is_zoom_in = (i % 2 == 0)
                    future = executor.submit(process_single_video_task, item, VIDEO_OUTPUT_DIR, is_zoom_in)
                    future_to_idx[future] = i
                
                for future in as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        vid_path = future.result()
                        if vid_path and "Error" not in vid_path:
                            st.session_state['generated_results'][idx]['video_path'] = vid_path
                        elif vid_path:
                            st.write(f"âš ï¸ Scene {idx+1} ë Œë”ë§ ì˜¤ë¥˜: {vid_path}")
                    except Exception as e:
                        st.write(f"âš ï¸ Scene {idx+1} ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
                    
                    completed_cnt += 1
                    progress_bar.progress(completed_cnt / total_files)
            
            status_box.update(label="âœ… ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!", state="complete", expanded=False)
            time.sleep(1)
            st.rerun()

    # ì „ì²´ ë³‘í•©
    with c_btn4:
        video_paths = [item.get('video_path') for item in st.session_state['generated_results'] if item.get('video_path')]
        final_path = os.path.join(VIDEO_OUTPUT_DIR, "FINAL_FULL_VIDEO.mp4")
        
        if video_paths:
            if st.button("ğŸï¸ ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸° (ìƒˆë¡œê³ ì¹¨)", use_container_width=True):
                with st.spinner("ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ì¤‘..."):
                    if os.path.exists(final_path):
                        try: os.remove(final_path)
                        except: pass
                        
                    merged_result = merge_all_videos(video_paths, VIDEO_OUTPUT_DIR)
                    if "Error" in merged_result:
                        st.error(merged_result)
                    else:
                        st.success("ë³‘í•© ì™„ë£Œ!")
                        st.rerun()

            if os.path.exists(final_path):
                 with open(final_path, "rb") as f:
                    st.download_button("ğŸ’¾ ì „ì²´ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (MP4)", data=f, file_name="final_video.mp4", mime="video/mp4", use_container_width=True)
        else:
            st.button("ğŸï¸ ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸°", disabled=True, use_container_width=True)

    if not supertone_api_key or not selected_voice_id:
        st.warning("ğŸ™ï¸ Supertone TTS ì‚¬ìš©ì„ ìœ„í•´ API ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

    # ------------------------------------------------
    # 2. ê°œë³„ ë¦¬ìŠ¤íŠ¸ ë° [ì¬ìƒì„±] ê¸°ëŠ¥
    # ------------------------------------------------
    for index, item in enumerate(st.session_state['generated_results']):
        with st.container(border=True):
            cols = st.columns([1, 2])
            
            # [ì™¼ìª½] ì´ë¯¸ì§€ ë° ì¬ìƒì„± ë²„íŠ¼
            with cols[0]:
                try: st.image(item['path'], use_container_width=True)
                except: st.error("ì´ë¯¸ì§€ ì—†ìŒ")
                
                # [NEW] ì´ë¯¸ì§€ ê°œë³„ ì¬ìƒì„± ë²„íŠ¼
                if st.button(f"ğŸ”„ ì´ ì¥ë©´ë§Œ ì´ë¯¸ì§€ ë‹¤ì‹œ ìƒì„±", key=f"regen_img_{index}", use_container_width=True):
                    if not api_key:
                        st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        with st.spinner(f"Scene {item['scene']} ë‹¤ì‹œ ê·¸ë¦¬ëŠ” ì¤‘..."):
                            client = genai.Client(api_key=api_key)
                            
                            # 1. í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ìƒì„± (í˜„ì¬ ëŒ€ë³¸ê³¼ ìŠ¤íƒ€ì¼ ë°˜ì˜)
                            current_title = st.session_state.get('video_title', '')
                            # ëŒ€ë³¸ì´ ìˆ˜ì •ë˜ì—ˆì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ item['script'] ì‚¬ìš©
                            _, new_prompt = generate_prompt(
                                api_key, index, item['script'], style_instruction,
                                current_title, target_language
                            )
                            
                            # 2. ì´ë¯¸ì§€ ìƒì„±
                            new_path = generate_image(
                                client, new_prompt, item['filename'], 
                                IMAGE_OUTPUT_DIR, SELECTED_IMAGE_MODEL
                            )
                            
                            if new_path:
                                # 3. ê²°ê³¼ ì—…ë°ì´íŠ¸
                                st.session_state['generated_results'][index]['path'] = new_path
                                st.session_state['generated_results'][index]['prompt'] = new_prompt
                                # ì´ë¯¸ì§€ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ê¸°ì¡´ ë¹„ë””ì˜¤ëŠ” ë¬´íš¨í™”
                                st.session_state['generated_results'][index]['video_path'] = None
                                st.success("ì´ë¯¸ì§€ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                time.sleep(0.5)
                                st.rerun()
                            else:
                                st.error("ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            # [ì˜¤ë¥¸ìª½] ì •ë³´ ë° ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì»¨íŠ¸ë¡¤
            with cols[1]:
                st.subheader(f"Scene {item['scene']:02d}")
                st.caption(f"íŒŒì¼ëª…: {item['filename']}")
                
                # ëŒ€ë³¸ ìˆ˜ì • ê°€ëŠ¥í•˜ê²Œ í• ì§€? (í˜„ì¬ëŠ” displayë§Œ)
                st.write(f"**ëŒ€ë³¸:** {item['script']}")
                
                st.markdown("---")
                audio_col1, audio_col2 = st.columns([1, 3])
                
                # ì˜¤ë””ì˜¤ ë¡œì§
                if item.get('audio_path') and os.path.exists(item['audio_path']):
                    with audio_col1:
                        st.audio(item['audio_path'])
                        if st.button("ğŸ”„ ì˜¤ë””ì˜¤ ì¬ìƒì„±", key=f"re_tts_{item['scene']}"):
                             item['audio_path'] = None
                             item['video_path'] = None 
                             st.rerun()
                    
                    with audio_col2:
                        if item.get('video_path') and os.path.exists(item['video_path']):
                            st.video(item['video_path'])
                            with open(item['video_path'], "rb") as vf:
                                st.download_button("â¬‡ï¸ ë¹„ë””ì˜¤ ì €ì¥", data=vf, file_name=f"scene_{item['scene']}.mp4", mime="video/mp4", key=f"down_vid_{item['scene']}")
                        else:
                            is_zoom_in_mode = (index % 2 == 0)
                            button_label = f"ğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ({'ì¤Œì¸' if is_zoom_in_mode else 'ì¤Œì•„ì›ƒ'})"

                            if st.button(button_label, key=f"gen_vid_{item['scene']}"):
                                with st.spinner("ë Œë”ë§ ì¤‘..."):
                                    vid_path = create_video_with_zoom(
                                        item['path'], item['audio_path'], VIDEO_OUTPUT_DIR, 
                                        item['scene'], is_zoom_in=is_zoom_in_mode
                                    )
                                    if "Error" in vid_path:
                                        st.error(vid_path)
                                    else:
                                        st.session_state['generated_results'][index]['video_path'] = vid_path
                                        st.rerun()
                else:
                    with audio_col1:
                        if st.button("ğŸ”Š TTS ìƒì„±", key=f"gen_tts_{item['scene']}"):
                            if not supertone_api_key or not selected_voice_id:
                                st.error("ì„¤ì • í•„ìš”")
                            else:
                                with st.spinner("ì˜¤ë””ì˜¤ ìƒì„± ì¤‘..."):
                                    audio_result = generate_supertone_tts(
                                        supertone_api_key, selected_voice_id, 
                                        item['script'], item['scene'], supertone_base_url, 
                                        speed=tts_speed, pitch=tts_pitch
                                    )
                                    if "Error" not in str(audio_result) and "VOICE_NOT_FOUND" != audio_result:
                                        st.session_state['generated_results'][index]['audio_path'] = audio_result
                                        st.rerun()
                                    else:
                                        st.error(audio_result)

                with st.expander("í”„ë¡¬í”„íŠ¸ í™•ì¸"):
                    st.text(item['prompt'])
                try:
                    with open(item['path'], "rb") as file:
                        st.download_button("â¬‡ï¸ ì´ë¯¸ì§€ ì €ì¥", data=file, file_name=item['filename'], mime="image/png", key=f"btn_down_{item['scene']}")
                except: pass



